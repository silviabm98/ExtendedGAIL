{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 13 11:40:05 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.147.05   Driver Version: 525.147.05   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   59C    P8    18W / 100W |     54MiB /  6144MiB |     41%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2204      G   /usr/lib/xorg/Xorg                 53MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "#########################################################################\n",
    "## COMPROBAR GPU ASIGNADA EN COLABORATORY\n",
    "#########################################################################\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gymnasium in /home/usuario/.local/lib/python3.10/site-packages (0.28.1)\n",
      "Requirement already satisfied: jax-jumpy>=1.0.0 in /home/usuario/.local/lib/python3.10/site-packages (from gymnasium) (1.0.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /home/usuario/.local/lib/python3.10/site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/usuario/.local/lib/python3.10/site-packages (from gymnasium) (1.24.3)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/usuario/.local/lib/python3.10/site-packages (from gymnasium) (4.5.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/usuario/.local/lib/python3.10/site-packages (from gymnasium) (2.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: stable_baselines3 in /home/usuario/.local/lib/python3.10/site-packages (2.0.0)\n",
      "Requirement already satisfied: matplotlib in /home/usuario/.local/lib/python3.10/site-packages (from stable_baselines3) (3.7.2)\n",
      "Requirement already satisfied: pandas in /home/usuario/.local/lib/python3.10/site-packages (from stable_baselines3) (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/usuario/.local/lib/python3.10/site-packages (from stable_baselines3) (1.24.3)\n",
      "Requirement already satisfied: gymnasium==0.28.1 in /home/usuario/.local/lib/python3.10/site-packages (from stable_baselines3) (0.28.1)\n",
      "Requirement already satisfied: torch>=1.11 in /home/usuario/.local/lib/python3.10/site-packages (from stable_baselines3) (2.0.1)\n",
      "Requirement already satisfied: cloudpickle in /home/usuario/.local/lib/python3.10/site-packages (from stable_baselines3) (2.2.1)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /home/usuario/.local/lib/python3.10/site-packages (from gymnasium==0.28.1->stable_baselines3) (0.0.4)\n",
      "Requirement already satisfied: jax-jumpy>=1.0.0 in /home/usuario/.local/lib/python3.10/site-packages (from gymnasium==0.28.1->stable_baselines3) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/usuario/.local/lib/python3.10/site-packages (from gymnasium==0.28.1->stable_baselines3) (4.5.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/usuario/.local/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (11.7.91)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/usuario/.local/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (11.10.3.66)\n",
      "Requirement already satisfied: jinja2 in /home/usuario/.local/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/usuario/.local/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/usuario/.local/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/usuario/.local/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/usuario/.local/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (11.4.0.1)\n",
      "Requirement already satisfied: filelock in /home/usuario/.local/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (3.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/usuario/.local/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (11.7.101)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/usuario/.local/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (2.0.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/usuario/.local/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/usuario/.local/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/usuario/.local/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/usuario/.local/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (11.7.4.91)\n",
      "Requirement already satisfied: sympy in /home/usuario/.local/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (1.12)\n",
      "Requirement already satisfied: networkx in /home/usuario/.local/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (3.1)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11->stable_baselines3) (59.6.0)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11->stable_baselines3) (0.37.1)\n",
      "Requirement already satisfied: cmake in /home/usuario/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.11->stable_baselines3) (3.26.4)\n",
      "Requirement already satisfied: lit in /home/usuario/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.11->stable_baselines3) (16.0.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/usuario/.local/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/usuario/.local/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib->stable_baselines3) (2.4.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/usuario/.local/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (4.40.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/usuario/.local/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib->stable_baselines3) (9.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/usuario/.local/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (23.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/usuario/.local/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (1.1.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->stable_baselines3) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/usuario/.local/lib/python3.10/site-packages (from jinja2->torch>=1.11->stable_baselines3) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/usuario/.local/lib/python3.10/site-packages (from sympy->torch>=1.11->stable_baselines3) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install stable_baselines3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-13 11:40:07.488393: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-13 11:40:07.489787: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-13 11:40:07.514509: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-13 11:40:07.515416: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-13 11:40:08.187659: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#########################################################################\n",
    "## LIBRERIAS NECESARIAS\n",
    "#########################################################################\n",
    "import tensorflow as tf\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from tensorflow.keras.layers import concatenate\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import layers\n",
    "import copy\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "\n",
    "import os\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "## Variables globales (hiperparámetros)\n",
    "###########################################################################\n",
    "EPOCHS=1 \n",
    "BATCH_SIZE=90\n",
    "\n",
    "EPISODES=10\n",
    "EPISODES_EVALUATE_G=50\n",
    "\n",
    "TOTAL_TIMESTEPS_PPO_GENERATOR=50000\n",
    "LEARNING_RATE=0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gym CartPole-v1\n",
    "\n",
    "Un péndulo está unido mediante una articulación no accionada a un carro que se desplaza a lo largo de una pista sin fricción. El péndulo se coloca verticalmente sobre el carro y el objetivo es equilibrar el poste aplicando fuerzas en dirección izquierda y derecha sobre el carro.\n",
    "\n",
    "**Espacio de Acciones**: Espacio discreto de tamaño (2)\n",
    "\n",
    "* Acción 0: Empujar el carro hacia la izquierda\n",
    "* Acción 1: Empujar el carro hacia la derecha\n",
    "\n",
    "**Espacio de Observaciones**: Espacio continuuo de tamaño (4,)\n",
    "\n",
    "* La observación es un ndarray con forma (4,) con los valores correspondientes a las siguientes posiciones y velocidades:\n",
    "    * Num     |     Observación |     Min |    Max\n",
    "\n",
    "    * 0    Posición del Carro                 - 4.8                            4.8\n",
    "\n",
    "    *  1    Velocidad del Carro                 -Inf                            Inf\n",
    "\n",
    "    * 2    Ángulo del Poste              ~ -0.418 rad (-24°)          ~ 0.418 rad (24°)\n",
    "\n",
    "    * 3    Velocidad Angular del Poste         -Inf                            Inf\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Definimos el entorno\n",
    "env= gym.make('CartPole-v1')\n",
    "\n",
    "# Obtenemos el espacio de estados y acciones del entorno\n",
    "ob_space=env.observation_space\n",
    "ac_space=env.action_space\n",
    "\n",
    "# Mostramos el número de acciones del entorno\n",
    "print(env.action_space.n)\n",
    "# Mostramos el número de observaciones del entorno\n",
    "print(ob_space.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red neuronal del Discriminador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator_net\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (Dense)              (None, None, 10)          70        \n",
      "                                                                 \n",
      " layer2 (Dense)              (None, None, 10)          110       \n",
      "                                                                 \n",
      " layer3 (Dense)              (None, None, 10)          110       \n",
      "                                                                 \n",
      " prob (Dense)                (None, None, 1)           11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301 (1.18 KB)\n",
      "Trainable params: 301 (1.18 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-13 11:40:10.478389: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2024-06-13 11:40:10.478416: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: usuario-ASUS-TUF-Gaming-F15-FX507ZM-TUF507ZM\n",
      "2024-06-13 11:40:10.478420: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: usuario-ASUS-TUF-Gaming-F15-FX507ZM-TUF507ZM\n",
      "2024-06-13 11:40:10.478511: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 525.147.5\n",
      "2024-06-13 11:40:10.478521: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 525.147.5\n",
      "2024-06-13 11:40:10.478524: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 525.147.5\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "# Red neuronal del Discriminador\n",
    "################################################################################################################################################\n",
    "\n",
    "# Input: secuencias [s,a] reales o sintéticas, de longitud ob_space.shape[0] + ac_space.n.\n",
    "# Output: probabilidad de que la secuencia sea real, valor perteneciente al intervalo [0,1]\n",
    "discriminator_net=keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(None, ob_space.shape[0] + ac_space.n)),\n",
    "        layers.Dense(units=10,activation=tf.nn.relu, name='layer1'),\n",
    "        layers.Dense(units=10,activation=tf.nn.relu, name='layer2'),\n",
    "        layers.Dense(units=10, activation=tf.nn.relu, name='layer3'),\n",
    "        layers.Dense(units=1, activation=tf.sigmoid, name='prob'),\n",
    "\n",
    "    ],\n",
    "    name=\"discriminator_net\"\n",
    "\n",
    ")\n",
    "discriminator_net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de pérdida del Discriminador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################\n",
    "# Función de pérdida del Discriminador\n",
    "#########################################################################################################\n",
    "\n",
    "# prob1=> output de la red neuronal del Discriminador cuando recibe como entrada una secuencia REAL [s,a, s', r] de la base de datos\n",
    "# prob2=> output de la red neuronal del Discriminador cuando recibe como entrada una secuencia FALSA [s,a, s', r]\n",
    "def loss_fn_D(prob1, prob2):\n",
    "\n",
    "    # Esperanza del logaritmo de la D(x)=salida de la red neuronal cuando x=entrada REAL\n",
    "    loss_expert = tf.reduce_mean(tf.math.log(tf.clip_by_value(prob1, 0.01, 1)))\n",
    "\n",
    "    # Esperanza del logaritmo de 1-D(x) donde D(x)=salida de la red neuronal cuando x=entrada FALSA\n",
    "    loss_agent = tf.reduce_mean(tf.math.log(tf.clip_by_value(1 - prob2, 0.01,1)))\n",
    "\n",
    "    loss_expert = tf.cast(loss_expert, dtype=tf.float32)\n",
    "    loss_agent = tf.cast(loss_agent, dtype=tf.float32)\n",
    "\n",
    "    loss = loss_expert + loss_agent\n",
    "\n",
    "    loss = -loss\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clase del Discriminador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################\n",
    "# Clase DISCRIMINADOR\n",
    "########################################################################################\n",
    "class Discriminator:\n",
    "    def __init__(self, env, discriminator_net, expert_s, expert_a, agent_s, agent_a):\n",
    "        # -Red neuronal del Discriminador\n",
    "        self.discriminator_net=discriminator_net\n",
    "        # -Experto: [s,a]\n",
    "        self.expert_s=expert_s\n",
    "        self.expert_a=expert_a\n",
    "        expert_a_one_hot=tf.one_hot(self.expert_a,depth=env.action_space.n)\n",
    "        # Añadimos ruido para estabilizar el entrenamiento\n",
    "        expert_a_one_hot+= tf.random.normal(tf.shape(expert_a_one_hot), mean=0.2, stddev=0.1, dtype=tf.float32)/1.2\n",
    "        self.expert_s_a=tf.concat([self.expert_s,expert_a_one_hot],axis=1)\n",
    "\n",
    "        # -Agente:  [s,a]\n",
    "        self.agent_s=agent_s\n",
    "        self.agent_a=agent_a\n",
    "        agent_a_one_hot=tf.one_hot(self.agent_a,depth=env.action_space.n)\n",
    "        agent_a_one_hot+= tf.random.normal(tf.shape(agent_a_one_hot), mean=0.2, stddev=0.1, dtype=tf.float32)/1.2\n",
    "        self.agent_s_a=tf.concat([self.agent_s,agent_a_one_hot],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "        # Calculamos la salida de la red para [s,a] del experto y del agente ya que lo necesitamos para reward\n",
    "\n",
    "        # -Salida de la red neuronal Discriminador para [s,a] expertos(verdaderos)\n",
    "        self.prob_expert=self.discriminator_net(self.expert_s_a)\n",
    "\n",
    "        # -Salida  de la red neuronal Discrimiinador para [s,a] Agente(falsos)\n",
    "        self.prob_agent=self.discriminator_net(self.agent_s_a)\n",
    "\n",
    "        #-Recompensa obtenida cuando el Agente realiza [s,a] falsas\n",
    "        self.rewards=tf.math.log(tf.clip_by_value(self.prob_agent,1e-10,1)) #log(P(expert|s,a)) cuando mas grande es mejor el agente\n",
    "\n",
    "\n",
    "    def getNet(self):\n",
    "        return self.discriminator_net\n",
    "\n",
    "    def getAgent_S_A(self):\n",
    "        return self.agent_s_a\n",
    "\n",
    "    def getExpert_S_A(self):\n",
    "        return self.expert_s_a\n",
    "\n",
    "    def getProb(self):\n",
    "        return self.prob_expert, self.prob_agent\n",
    "\n",
    "    def getRewards(self):\n",
    "        return self.rewards\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes neuronales del Generador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator_net_Act\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (Dense)              (None, None, 6)           30        \n",
      "                                                                 \n",
      " layer2 (Dense)              (None, None, 6)           42        \n",
      "                                                                 \n",
      " layer3 (Dense)              (None, None, 4)           28        \n",
      "                                                                 \n",
      " layer4 (Dense)              (None, None, 2)           10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 110 (440.00 Byte)\n",
      "Trainable params: 110 (440.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#####################################################################################################\n",
    "# Red neuronal del Generador donde se producen acciones\n",
    "####################################################################################################\n",
    "\n",
    "# Input: estados, listas de tamaño 4, s=[s1,s2,s3,s4]\n",
    "# Output: acciones, listas de tamaño 2, a=[a1,a2]\n",
    "generator_net_Act=keras.Sequential(\n",
    "    [\n",
    "            keras.Input(shape=(None,ob_space.shape[0])),\n",
    "            layers.Dense(units=6, activation=tf.tanh,name='layer1'),\n",
    "            layers.Dense(units=6, activation=tf.tanh, name='layer2'),\n",
    "            layers.Dense(units=4, activation=tf.tanh, name='layer3'),\n",
    "            layers.Dense(units=2, activation=tf.nn.softmax, name='layer4')\n",
    "\n",
    "        ],\n",
    "    name=\"generator_net_Act\"\n",
    ")\n",
    "\n",
    "generator_net_Act.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator_v_preds\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (Dense)              (None, None, 6)           30        \n",
      "                                                                 \n",
      " layer2 (Dense)              (None, None, 6)           42        \n",
      "                                                                 \n",
      " layer3 (Dense)              (None, None, 1)           7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79 (316.00 Byte)\n",
      "Trainable params: 79 (316.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#############################################################################################################\n",
    "# Red neuronal del Generador donde se producen v_pred\n",
    "#############################################################################################################\n",
    "\n",
    "# Input: estados, listas de tamaño 4, s=[s0,s1,s2,s3]\n",
    "# Output: v_pred, listas de tamaño 1, v_pred\n",
    "generator_net_v_preds=keras.Sequential(\n",
    "    [\n",
    "            keras.Input(shape=(None,ob_space.shape[0])),\n",
    "            layers.Dense(units=6, activation=tf.tanh,name='layer1'),\n",
    "            layers.Dense(units=6, activation=tf.tanh, name='layer2'),\n",
    "            layers.Dense(units=1, activation=None, name='layer3'),\n",
    "        ],\n",
    "    name=\"generator_v_preds\"\n",
    ")\n",
    "\n",
    "generator_net_v_preds.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de pérdida del Generador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################################\n",
    "# Función de pérdida del Generador: función objetivo de PPO \"clipped surrogated\"\n",
    "#################################################################################################################\n",
    "def loss_fn_ppo(v_preds,act_probs,act_probs_old,gaes,clip_value=0.2,entcoeff=0.01):\n",
    "    \"\"\" \n",
    "    ratios = tf.exp(tf.math.log(tf.clip_by_value(act_probs, 1e-10, 1.0))\n",
    "                    - tf.math.log(tf.clip_by_value(act_probs_old, 1e-10, 1.0)))\n",
    "\n",
    "    clipped_ratios = tf.clip_by_value(ratios,clip_value_min=1 -clip_value,clip_value_max=1 +clip_value)\n",
    "\n",
    "    # L^{clip}_t (θ)\n",
    "    loss_clip = tf.minimum( tf.multiply(gaes, ratios), tf.multiply(gaes, clipped_ratios))\n",
    "    loss_clip = tf.reduce_mean(loss_clip)\n",
    "\n",
    "    pol_surr = -loss_clip  # ---YA LA  TENIAMOS\n",
    "\n",
    "    #--------------- NUEVO---------\n",
    "    \n",
    "    # c_1* L^{VF}_t (θ)  is a squared-error loss\n",
    "    # Empirical return\n",
    "    vf_loss = tf.reduce_mean(tf.square(v_preds))\n",
    "\n",
    "\n",
    "    # c_2 * S[πθ](st) where S  denotes an entropy bonus\n",
    "    # --Calcular la distribución de probabilidad normalizada\n",
    "    normalized_distribution = act_probs / tf.reduce_sum(act_probs)\n",
    "    \n",
    "    # --Calcular la entropía\n",
    "    ent = -tf.reduce_sum(normalized_distribution * tf.math.log(normalized_distribution))\n",
    "\n",
    "    meanent = tf.reduce_mean(ent)\n",
    "    pol_entpen = (-entcoeff) * meanent\n",
    "\n",
    "    total_loss = pol_surr + pol_entpen + vf_loss\n",
    "    tf.summary.scalar('total', total_loss)\n",
    "\n",
    "    return total_loss\"\"\" \n",
    "\n",
    "    ratios = tf.exp(tf.math.log(tf.clip_by_value(act_probs, 1e-10, 1.0))\n",
    "                    - tf.math.log(tf.clip_by_value(act_probs_old, 1e-10, 1.0)))\n",
    "\n",
    "    clipped_ratios = tf.clip_by_value(ratios,clip_value_min=1 -clip_value,clip_value_max=1 +clip_value)\n",
    "    loss_clip = tf.minimum( tf.multiply(gaes, ratios), tf.multiply(gaes, clipped_ratios))\n",
    "    loss_clip = tf.reduce_mean(loss_clip)\n",
    "\n",
    "    loss = -loss_clip\n",
    "    tf.summary.scalar('total', loss)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clase del Generador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################################################\n",
    "# Clase del GENERADOR: política con su optimizador PPO\n",
    "################################################################################################################\n",
    "\n",
    "# Observesé que cada generador implementa una política distinta, por tanto, se ha decidido llamar a la clase Policy_net en lugar de generator\n",
    "class Policy_net:\n",
    "  def __init__(self, name: str, env, obs):\n",
    "        \"\"\"\n",
    "        env: gym env\n",
    "        obs:\n",
    "        \"\"\"\n",
    "        # -Entorno\n",
    "        self.env=env\n",
    "\n",
    "        env.reset()\n",
    "\n",
    "        # -Modelo PPO: algoritmo de Optimización de Política Proximal\n",
    "        self.model=PPO(policy=\"MlpPolicy\", env=env, verbose=0)\n",
    "\n",
    "\n",
    "        self.model.learn(total_timesteps=TOTAL_TIMESTEPS_PPO_GENERATOR)\n",
    "\n",
    "        # -Observación inicial a partir de la cual se crean las acciones iniciales haciendo uso de las redes neuronales del generador\n",
    "        self.obs=np.reshape(np.array(obs),(1,ob_space.shape[0]))\n",
    "\n",
    "        # Utilizamos las dos redes neuronales que hemos creado : generator_net_Act y generator_net_v_preds\n",
    "        # V_pred=>recompensa media de que un agente ejecute una acción\n",
    "\n",
    "        # -Acción inicial generada con red neuronal y v_pred con red neuronal\n",
    "        self.act_probs =generator_net_Act(self.obs)\n",
    "        self.v_preds = generator_net_v_preds(self.obs)\n",
    "\n",
    "        # -Accion estocástica inicial\n",
    "        self.act_stochastic = tf.random.categorical(tf.math.log(self.act_probs), num_samples=1)\n",
    "\n",
    "        # -Acción determinística inicial\n",
    "        self.act_deterministic = tf.argmax(self.act_probs, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "  # Para cada estado obs me dice la acción que el agente va a ejecutar sobre el entorno junto con v_pred\n",
    "  # La elección de la acción puede ser estocástica o determinística\n",
    "  def act(self, stochastic=True):\n",
    "      if stochastic:\n",
    "          return self.act_stochastic, self.v_preds\n",
    "      else:\n",
    "          return self.act_deterministic, self.v_preds\n",
    "\n",
    "  def get_action_prob(self):\n",
    "      return self.act_probs\n",
    "\n",
    "  def get_v_preds(self):\n",
    "      return self.v_preds\n",
    "\n",
    "  def get_obs(self):\n",
    "      return self.obs\n",
    "\n",
    "  def get_model(self):\n",
    "      return self.model\n",
    "\n",
    "  def get_trainable_variables(self):\n",
    "      return self.model.get_parameters()\n",
    "\n",
    "  # Generar [s,a] falsos\n",
    "  def generate_fakes(self):\n",
    "\n",
    "      ob_space = env.observation_space\n",
    "      reward = 0\n",
    "      success_num = 0\n",
    "\n",
    "      # Por cada episodio\n",
    "      for iteration in range(EPISODES):\n",
    "          # Inicializo todas las variables\n",
    "          observations = []\n",
    "          actions = []\n",
    "          rewards = []\n",
    "          run_policy_steps = 0\n",
    "\n",
    "          truncated=False\n",
    "          terminated=False\n",
    "\n",
    "\n",
    "          #La primera acción de cada episodio se crea con la red neuronal\n",
    "\n",
    "          obs,_=env.reset()\n",
    "\n",
    "          Old_Policy = Policy_net('old_policy', env, obs=obs)\n",
    "\n",
    "          act, v_pred = Old_Policy.act(stochastic=True)\n",
    "\n",
    "          #Convertir de tensor a array\n",
    "          if type(act)=='Tensor':\n",
    "              # Crear una sesión de TensorFlow\n",
    "              sess = tf.compat.v1.Session()\n",
    "\n",
    "              # Evaluar el tensor dentro de la sesión y obtener el resultado como un objeto NumPy ndarray\n",
    "              act = sess.run(act)\n",
    "\n",
    "              # Cerrar la sesión\n",
    "              sess.close()\n",
    "\n",
    "          if isinstance(act, tf.Tensor):\n",
    "              act=act.numpy()\n",
    "\n",
    "          elif isinstance(act, np.ndarray):\n",
    "              act=act\n",
    "\n",
    "\n",
    "          action=int(act)\n",
    "\n",
    "          next_obs,reward,terminated,truncated, info=env.step(action)\n",
    "\n",
    "          # --Actualización de variables: ojo no introduzco el estado y accion inicial, solo introduzco los de PPO\n",
    "          observations.append(next_obs)  # S_0\n",
    "\n",
    "          Policy = Policy_net('policy',env, obs=[next_obs]) # tenemos una política entrenada\n",
    "\n",
    "          # Por cada steps en cada episodio, mientras no se llegue a un estado terminal o un estado malo\n",
    "          while terminated!= True and truncated!= True:\n",
    "              # --Aumentar el numero de steps\n",
    "              run_policy_steps += 1\n",
    "\n",
    "              # --Política para ver la acción asociada al estado\n",
    "              # Las observaciones son un de la forma [[s_0,s_1,s_2,s_3]] por eso su tamaño es (1,4)\n",
    "              action, states_oc = Policy.get_model().predict(next_obs)\n",
    "\n",
    "              action=int(action)\n",
    "\n",
    "              # --Muevo al Agente al siguiente estado\n",
    "              next_obs,reward,terminated,truncated,info=env.step(action)\n",
    "\n",
    "              # --Actualización de variables\n",
    "              actions.append(action) # A_i-1\n",
    "              rewards.append(reward) # R_i-1\n",
    "\n",
    "              # --Si llegamos a un estado final, el juego ha finalizado!!!\n",
    "              # --Se configura el tablero de nuevo\n",
    "              if terminated== True or truncated==True:\n",
    "                  obs = env.reset()\n",
    "                  reward = -1\n",
    "                  break\n",
    "              else:\n",
    "                  observations.append(next_obs) # O_i\n",
    "                  self.obs = next_obs\n",
    "\n",
    "          # Ver si el episodio ha obtendo una recompensa total igual o superior a 195\n",
    "          if sum(rewards) >= 195:\n",
    "              success_num += 1\n",
    "              if success_num >= 100:\n",
    "                  break\n",
    "          else:\n",
    "              success_num = 0\n",
    "             \n",
    "\n",
    "      observations = np.reshape(observations, newshape=[-1] + list(ob_space.shape))\n",
    "      actions = np.array(actions).astype(dtype=np.int32)\n",
    "\n",
    "\n",
    "      return observations, actions, rewards, Old_Policy, Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################\n",
    "# Clase PPOTrain\n",
    "##########################################################################################################\n",
    "# Tenemos dos politica theta_i y theta_i+1\n",
    "# Almacenamos dos políticas Policy_net(cada una de ella con su PPO) y calculamos el valor gaes a partir de valores gamma, clip_value, c_1, c_2\n",
    "# Realizamos aqui el entrenamiento, cálculo de gradiente y función de pérdida del PPO para después usarlo en el generador de la GAN\n",
    "\n",
    "class PPOTrain:\n",
    "  def __init__(self, Policy, Old_Policy, obs, actions, rewards, gamma=0.95, clip_value=0.2, c_1=1, c_2=0.01):\n",
    "        \"\"\"\n",
    "        arg:\n",
    "            Policy\n",
    "            Old_Policy\n",
    "            gamma\n",
    "            clip_value\n",
    "            c_1 parámetro para la diferencia de valores\n",
    "            c_2 parámetro para el bonus de entropía\n",
    "        \"\"\"\n",
    "        self.Policy = Policy\n",
    "        self.Old_Policy = Old_Policy\n",
    "        self.gamma = gamma\n",
    "        self.obs=obs\n",
    "\n",
    "        self.pi_trainable = self.Policy.get_trainable_variables()\n",
    "        self.old_pi_trainable = self.Old_Policy.get_trainable_variables()\n",
    "\n",
    "\n",
    "        policy_name = \"policy\"\n",
    "        old_policy_name=\"policy\"\n",
    "\n",
    "        policy_dict_ = self.pi_trainable[policy_name]\n",
    "        old_policy_dict_=self.old_pi_trainable[old_policy_name]\n",
    "\n",
    "        self.pi=[]\n",
    "        if policy_name in self.pi_trainable and old_policy_name in self.old_pi_trainable:\n",
    "            for param_name, param_value in policy_dict_.items():\n",
    "                # Elimino los pesos que hay en old_policy\n",
    "                del old_policy_dict_[param_name]\n",
    "                # Introduzco los pesos de old_policy en policy\n",
    "                old_policy_dict_[param_name] = param_value\n",
    "                self.pi.append(param_value)\n",
    "        else:\n",
    "            print(f\"No se encontró la política con el nombre: {policy_name}\")\n",
    "\n",
    "\n",
    "        # Le asignamos old_pi_trainable=pi_trainable ya que ajustaremos unos nuevos pi_trainable\n",
    "\n",
    "\n",
    "        self.actions = actions\n",
    "        self.rewards=rewards\n",
    "        self.v_preds=self.Old_Policy.get_v_preds()\n",
    "        self.v_preds_next=self.Policy.get_v_preds()\n",
    "\n",
    "        #  generative advantage estimator(lambda = 1), ver ppo paper eq(11)\n",
    "        self.gaes =self.get_gaes(self.rewards, self.v_preds, self.v_preds_next)\n",
    "\n",
    "        act_probs =self.Policy.get_action_prob()\n",
    "        act_probs_old =self.Old_Policy.get_action_prob()\n",
    "\n",
    "        # la probabilidad de las acciones del agente cuando toma la actual política\n",
    "        act_probs = act_probs * tf.one_hot(indices=self.actions, depth=act_probs.shape[1])\n",
    "        self.act_probs = tf.reduce_sum(act_probs, axis=1)\n",
    "\n",
    "        # la probabilidad de las acciones del agente cuando toma la antigua política\n",
    "        act_probs_old = act_probs_old * tf.one_hot(indices=self.actions, depth=act_probs_old.shape[1])\n",
    "        self.act_probs_old = tf.reduce_sum(act_probs_old, axis=1)\n",
    "\n",
    "        self.loss=loss_fn_ppo(self.v_preds_next, self.act_probs, self.act_probs_old, self.gaes)\n",
    "\n",
    "        self.optimizer =tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "  def loss_fn_G(self):\n",
    "      return loss_fn_ppo(self.v_preds_next,self.act_probs, self.act_probs_old, self.gaes)\n",
    "\n",
    "  def get_pi_trainable(self):\n",
    "      return self.pi\n",
    "\n",
    "  def get_optimizer(self):\n",
    "      return self.optimizer\n",
    "\n",
    "  def get_OldPolicy(self):\n",
    "      return self.Old_Policy\n",
    "\n",
    "  def get_Policy(self):\n",
    "      return self.Policy\n",
    "\n",
    "  def get_gaes(self, rewards, v_preds, v_preds_next):\n",
    "      deltas = [r_t + self.gamma * v_next - v for r_t, v_next, v in zip(rewards, v_preds_next, v_preds)]\n",
    "      # calcular la estimación generative advantage (lambda = 1), ver ppo paper eq(11)\n",
    "      gaes = copy.deepcopy(deltas)\n",
    "      for t in reversed(range(len(gaes) - 1)):  # # es T-1, donde T es time step con el que se ejecuta la política\n",
    "          gaes[t] = gaes[t] + self.gamma * gaes[t + 1]\n",
    "      return gaes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################################\n",
    "# CLASE GAIL\n",
    "####################################################################################################################\n",
    "class GAN(keras.Model):\n",
    "    # Constructor\n",
    "    def __init__(self, discriminator, generator):\n",
    "        super().__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator=generator\n",
    "        self.i=0\n",
    "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
    "\n",
    "    # Compila el modelo GAN inicializando los optimizadores y la función de pérdida del modelo GAN\n",
    "    def compile(self,d_optimizer, loss_fn_D ):\n",
    "        super(GAN, self).compile(run_eagerly=True)\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.loss_fn_D=  loss_fn_D\n",
    "\n",
    "    # Devuelve las métricas obtenidas con el generador y discriminador\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric,self.g_loss_metric]\n",
    "\n",
    "    # Evaluación del Discriminador\n",
    "    def evaluate_D(self, X_test):\n",
    "        len_real = X_test.shape[0]\n",
    "\n",
    "        generate_observations, generate_actions, rewards, Old_Policy, Policy=self.generator.generate_fakes()\n",
    "\n",
    "        generate_a_one_hot=np.eye(env.action_space.n)[generate_actions]\n",
    "\n",
    "        dataset_gen=np.concatenate([generate_observations,generate_a_one_hot],axis=1)\n",
    "\n",
    "\n",
    "        len_fakes=dataset_gen.shape[0]\n",
    "\n",
    "        # Compilamos el discriminador como CNN\n",
    "        self.discriminator.discriminator_net.compile(optimizer=self.d_optimizer, loss=self.loss_fn_D, metrics=['accuracy'])\n",
    "\n",
    "        # Evaluamos como CNN\n",
    "        loss_real, acc_real=self.discriminator.discriminator_net.evaluate(X_test, tf.ones((len_real,1)), batch_size=len_real, verbose=1)\n",
    "\n",
    "        loss_fake, acc_fake=self.discriminator.discriminator_net.evaluate(dataset_gen,tf.ones((len_fakes,1)), batch_size=len_fakes, verbose=1)\n",
    "\n",
    "        print('>Loss real: ')\n",
    "        print(loss_real)\n",
    "        print('>Loss fake: ')\n",
    "        print(loss_fake)\n",
    "\n",
    "\n",
    "    # Evaluación del generador\n",
    "    def evaluate_G(self):\n",
    "        # Definimos el entorno\n",
    "        env= gym.make('CartPole-v1')\n",
    "\n",
    "        # Lista donde amacenaremos la recompensa acumulada de cada episodio.\n",
    "        # NUESTRO OBJETIVO: Agente aprenda a tomar las acciones que maximicen la recompensa\n",
    "        rewards=[]\n",
    "\n",
    "        # Para cada episodio, el Agente se mueve por el Entorno mediante acciones hasta llegar a un estado final\n",
    "        # siguiendo la política que se ha aprendido en el entrenamiento de la GAN\n",
    "        for episode in range(EPISODES_EVALUATE_G):\n",
    "            truncated=False\n",
    "            terminated=False\n",
    "            R=0.0\n",
    "            reward=0.0\n",
    "\n",
    "            # Estado inicial del juego\n",
    "            obs,_=env.reset()\n",
    "\n",
    "            #Interactuamos con el Entorno hasta que lleguemos a un estado final\n",
    "            while terminated!= True and truncated!=True:\n",
    "                action, _=self.generator.get_model().predict(obs)\n",
    "                obs,reward,terminated,truncated, info=env.step(int(action))\n",
    "\n",
    "                # Incremento la recompensa del episodio i al haber ejecutado el step\n",
    "                R+=reward\n",
    "\n",
    "            rewards.append(R)\n",
    "\n",
    "            # Vemos para el episodio, su recompensa acumulada que es lo que se trata de maximizar\n",
    "            print(\"Episode  {} Total reward: {}\".format(episode,R))\n",
    "\n",
    "        # Cierro el entorno\n",
    "        env.close()\n",
    "\n",
    "        # Muestro las recompensas obtenidas en cada episodio\n",
    "        indices = range(0, EPISODES_EVALUATE_G)\n",
    "        plt.plot(indices,rewards)\n",
    "        plt.show()\n",
    "\n",
    "        return np.mean(rewards)\n",
    "\n",
    "    def train_step(self, X_train):\n",
    "        \n",
    "        # 1) Generamos secuencias falsas [s,a]\n",
    "        generate_observations, generate_actions, rewards, Old_Policy, Policy=self.generator.generate_fakes()\n",
    "\n",
    "        generate_a_one_hot=np.eye(env.action_space.n)[generate_actions]\n",
    "\n",
    "        \n",
    "        if generate_observations.shape[0] == generate_a_one_hot.shape[0]:\n",
    "          dataset_gen = np.concatenate([generate_observations, generate_a_one_hot], axis=1)\n",
    "        else:\n",
    "          generate_a_one_hot_resized = np.resize(generate_a_one_hot, (generate_observations.shape[0],2))\n",
    "          dataset_gen = np.concatenate([generate_observations, generate_a_one_hot_resized], axis=1)\n",
    "\n",
    "        # 2) Seleccionamos la muestra de datos generador con la que vamos a trabajar en este  batch de entrenamiento  \n",
    "        random_indices = np.random.choice(len(dataset_gen), size=min(BATCH_SIZE,len(dataset_gen)), replace=False)\n",
    "        dataset_gen= dataset_gen[random_indices]\n",
    "        \n",
    "        \n",
    "        ## 3) Obtenemos las secuencias reales [s,a] de los datos de entrenamiento y las combinamos\n",
    "        combined_images = tf.concat([X_train, dataset_gen], axis=0)\n",
    "    \n",
    "\n",
    "        # 4) Las etiquetas de las imagenes combinadas las tenemos que crear nosotros introduciendo algo de ruido con tf.random.uniform\n",
    "        labels = tf.concat([tf.ones((BATCH_SIZE, 1)), tf.zeros((BATCH_SIZE, 1))], axis=0)\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "\n",
    "\n",
    "        ##############################################################################################################################################################\n",
    "        # PASO 1:  ENTRENAMIENTO DEL DISCRIMINADOR\n",
    "        #############################################################################################################################################################\n",
    "\n",
    "\n",
    "        # Entrenamiento del discriminador con las [s,a, s', r] del agente(falsas o sintéticas) y del experto (reales) combinadas, esto es,\n",
    "        # le pasamos un conjunto que tiene tanto secuencias reales como secuencias sintéticas\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions=np.zeros((2*BATCH_SIZE,6))\n",
    "            # Predicciones obtenidas con el discriminador\n",
    "            predictions = self.discriminator.discriminator_net(combined_images)\n",
    "            # Valor de la función de pérdida al comparar las predicciones con las etiquetas reales\n",
    "            d_loss = self.loss_fn_D(labels, predictions)\n",
    "\n",
    "        # Calculo del gradiente y actualización del gradiente\n",
    "        grads = tape.gradient(d_loss, self.discriminator.getNet().trainable_weights)\n",
    "\n",
    "        self.d_optimizer.apply_gradients(\n",
    "          zip(grads, self.discriminator.getNet().trainable_weights)\n",
    "        )\n",
    "\n",
    "        ################################################################################################################################################################\n",
    "        # PASO 2: ENTRENAMIENTO DEL GENERADOR=POLÍTICA\n",
    "        ###############################################################################################################################################################\n",
    "\n",
    "\n",
    "        ppotrain=PPOTrain(Policy,Old_Policy,actions=generate_actions,rewards=rewards, obs=generate_observations[0])\n",
    "\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            g_loss = ppotrain.loss_fn_G()\n",
    "\n",
    "\n",
    "        g_loss = tf.cast(g_loss, dtype=tf.float32)\n",
    "\n",
    "        \n",
    "        ############################################################################################################################################################\n",
    "\n",
    "        # Actualización de métricas del discriminador y generador\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        print(\"\\n\")\n",
    "        print(\"\\nd_loss=\",d_loss.numpy())\n",
    "        print(\"\\ng_loss=\",g_loss.numpy())\n",
    "\n",
    "        return {\"d_loss\": self.d_loss_metric.result(),\n",
    "                    \"g_loss\": self.g_loss_metric.result()}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentación de GAIL con CartPole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción de base de datos experta con 1 trayectoria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_observations = np.genfromtxt(\"observations_CartPole_.csv\",delimiter=\"\\t\",dtype=str)\n",
    "expert_actions = np.genfromtxt('actions_CartPole_.csv', dtype=np.int32)\n",
    "expert_num_tray=np.genfromtxt('n_trayectoria_CartPole_.csv', dtype=np.int32)\n",
    "\n",
    "# Reemplazar las comas\n",
    "expert_observations = np.core.defchararray.replace(expert_observations, ',', ' ')\n",
    "\n",
    "# Crear un nuevo array para almacenar los datos convertidos\n",
    "converted_observations = np.genfromtxt(expert_observations, delimiter=' ', dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 9 9 9]\n"
     ]
    }
   ],
   "source": [
    "print(expert_num_tray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "longitud_trayectoria = np.count_nonzero(expert_num_tray == 0)\n",
    "print(longitud_trayectoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos quedamos solo con la primera trayectoria\n",
    "converted_observations=converted_observations[0:308]\n",
    "expert_actions=expert_actions[0:308]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEstados reales: \n",
      " [[ 0.00572823 -0.03831238  0.03101629  0.00900886]\n",
      " [ 0.00496198  0.15635134  0.03119646 -0.27372897]\n",
      " [ 0.00808901 -0.03920152  0.02572188  0.02862788]\n",
      " ...\n",
      " [-0.0427408   0.15409148  0.01132174 -0.22373803]\n",
      " [-0.03965897 -0.04119044  0.00684698  0.0724946 ]\n",
      " [-0.04048278  0.15383267  0.00829687 -0.21802023]]\n",
      "\tAcciones reales: \n",
      " [1 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 1 0 0 1 0 1 1 0 0\n",
      " 1 0 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 1 0\n",
      " 0 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 0 1 0 0\n",
      " 1 1 0 0 1 1 0 0 1 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 0 1 0 1 1 0 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 1 1 0 1 0 1 0 0 1 1 0 0 1 0 1 0 1 0 1\n",
      " 1 0 0 1 1 0 1 0 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 1 1 0 1 0 1 0 1\n",
      " 0 0 1 1 0 0 1 1 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 0 1 0 0 1\n",
      " 1 0 1 0 1 0 0 1 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\tEstados reales: \\n\", converted_observations)\n",
    "print(\"\\tAcciones reales: \\n\", expert_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separación de Train y Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00572823 -0.03831238  0.03101629  0.00900886  0.          1.        ]\n",
      " [ 0.00496198  0.15635134  0.03119646 -0.27372897  1.          0.        ]\n",
      " [ 0.00808901 -0.03920152  0.02572188  0.02862788  0.          1.        ]\n",
      " ...\n",
      " [-0.0427408   0.15409148  0.01132174 -0.22373803  1.          0.        ]\n",
      " [-0.03965897 -0.04119044  0.00684698  0.0724946   0.          1.        ]\n",
      " [-0.04048278  0.15383267  0.00829687 -0.21802023  1.          0.        ]]\n",
      "Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento: 246\n",
      "Nº de (ESTADOS,ACCIONES) en el conjunto de prueba: 62\n"
     ]
    }
   ],
   "source": [
    "# Construimos el dataset [s,a] reales y lo dividimos en training y test\n",
    "expert_a_one_hot=np.eye(env.action_space.n)[expert_actions]\n",
    "\n",
    "dataset=np.concatenate([converted_observations,expert_a_one_hot],axis=1)\n",
    "\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test = train_test_split(dataset, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "#Imprime el número de elementos en el conjuntos de entrenamiento y prueba\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento:', len(X_train))\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de prueba:', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:107: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "env= gym.make('CartPole-v1')\n",
    "obs,_= env.reset()\n",
    "\n",
    "# Generador\n",
    "generator=Policy_net( 'policy', env, obs)\n",
    "\n",
    "# Generamos [s,a] falsas y las políticas theta_i y theta_i+1\n",
    "observations, actions, rewards, Old_Policy, Policy=generator.generate_fakes()\n",
    "\n",
    "# Discriminador\n",
    "discriminator=Discriminator(env, discriminator_net, converted_observations, expert_actions, observations, actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan1=GAN(discriminator=discriminator,generator=generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "gan1.compile(\n",
    "    d_optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss_fn_D=loss_fn_D\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "d_loss= 2.6998672\n",
      "\n",
      "g_loss= -1.2937802\n",
      "1/3 [=========>....................] - ETA: 16:16 - d_loss: 2.6999 - g_loss: -1.2938\n",
      "\n",
      "\n",
      "d_loss= 2.6640248\n",
      "\n",
      "g_loss= -0.85499656\n",
      "2/3 [===================>..........] - ETA: 7:44 - d_loss: 2.6819 - g_loss: -1.0744 \n",
      "\n",
      "\n",
      "d_loss= 2.6732821\n",
      "\n",
      "g_loss= -0.783127\n",
      "3/3 [==============================] - 1397s 454s/step - d_loss: 2.6791 - g_loss: -0.9773\n"
     ]
    }
   ],
   "source": [
    "# Deshabilitar los mensajes de información de TensorFlow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Deshabilitar los mensajes de información de OpenAI Gym\n",
    "gym.logger.set_level(40)\n",
    "\n",
    "history=gan1.fit(X_train,\n",
    "    epochs=EPOCHS,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7574 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7776 - accuracy: 1.0000\n",
      ">Loss real: \n",
      "0.7573800683021545\n",
      ">Loss fake: \n",
      "0.7775967717170715\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos el Discriminador de GAIL en el TEST\n",
    "gan1.evaluate_D(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  0 Total reward: 500.0\n",
      "Episode  1 Total reward: 500.0\n",
      "Episode  2 Total reward: 500.0\n",
      "Episode  3 Total reward: 500.0\n",
      "Episode  4 Total reward: 500.0\n",
      "Episode  5 Total reward: 500.0\n",
      "Episode  6 Total reward: 500.0\n",
      "Episode  7 Total reward: 500.0\n",
      "Episode  8 Total reward: 500.0\n",
      "Episode  9 Total reward: 500.0\n",
      "Episode  10 Total reward: 500.0\n",
      "Episode  11 Total reward: 500.0\n",
      "Episode  12 Total reward: 500.0\n",
      "Episode  13 Total reward: 500.0\n",
      "Episode  14 Total reward: 500.0\n",
      "Episode  15 Total reward: 500.0\n",
      "Episode  16 Total reward: 500.0\n",
      "Episode  17 Total reward: 500.0\n",
      "Episode  18 Total reward: 500.0\n",
      "Episode  19 Total reward: 500.0\n",
      "Episode  20 Total reward: 500.0\n",
      "Episode  21 Total reward: 500.0\n",
      "Episode  22 Total reward: 500.0\n",
      "Episode  23 Total reward: 500.0\n",
      "Episode  24 Total reward: 500.0\n",
      "Episode  25 Total reward: 500.0\n",
      "Episode  26 Total reward: 500.0\n",
      "Episode  27 Total reward: 500.0\n",
      "Episode  28 Total reward: 500.0\n",
      "Episode  29 Total reward: 500.0\n",
      "Episode  30 Total reward: 500.0\n",
      "Episode  31 Total reward: 500.0\n",
      "Episode  32 Total reward: 500.0\n",
      "Episode  33 Total reward: 500.0\n",
      "Episode  34 Total reward: 500.0\n",
      "Episode  35 Total reward: 500.0\n",
      "Episode  36 Total reward: 500.0\n",
      "Episode  37 Total reward: 500.0\n",
      "Episode  38 Total reward: 500.0\n",
      "Episode  39 Total reward: 500.0\n",
      "Episode  40 Total reward: 500.0\n",
      "Episode  41 Total reward: 500.0\n",
      "Episode  42 Total reward: 500.0\n",
      "Episode  43 Total reward: 500.0\n",
      "Episode  44 Total reward: 500.0\n",
      "Episode  45 Total reward: 500.0\n",
      "Episode  46 Total reward: 500.0\n",
      "Episode  47 Total reward: 500.0\n",
      "Episode  48 Total reward: 500.0\n",
      "Episode  49 Total reward: 500.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recompensa de Media: 500.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos al Generador \n",
    "rewardMean=gan1.evaluate_G()\n",
    "print('\\nRecompensa de Media:', rewardMean, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción de base de datos experta con 2 trayectoria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_observations = np.genfromtxt(\"observations_CartPole_.csv\",delimiter=\"\\t\",dtype=str)\n",
    "expert_actions = np.genfromtxt('actions_CartPole_.csv', dtype=np.int32)\n",
    "expert_num_tray=np.genfromtxt('n_trayectoria_CartPole_.csv', dtype=np.int32)\n",
    "\n",
    "# Reemplazar las comas\n",
    "expert_observations = np.core.defchararray.replace(expert_observations, ',', ' ')\n",
    "\n",
    "# Crear un nuevo array para almacenar los datos convertidos\n",
    "converted_observations = np.genfromtxt(expert_observations, delimiter=' ', dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "longitud_trayectoria += np.count_nonzero(expert_num_tray == 1)\n",
    "print(longitud_trayectoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos quedamos solo con la primera trayectoria\n",
    "converted_observations=converted_observations[0:1000]\n",
    "expert_actions=expert_actions[0:1000]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEstados reales: \n",
      " [[ 0.00572823 -0.03831238  0.03101629  0.00900886]\n",
      " [ 0.00496198  0.15635134  0.03119646 -0.27372897]\n",
      " [ 0.00808901 -0.03920152  0.02572188  0.02862788]\n",
      " ...\n",
      " [-0.02125562 -0.14190234  0.00628069  0.19885743]\n",
      " [-0.02409366  0.05312921  0.01025783 -0.09183763]\n",
      " [-0.02303108  0.24810264  0.00842108 -0.38126662]]\n",
      "\tAcciones reales: \n",
      " [1 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 1 0 0 1 0 1 1 0 0\n",
      " 1 0 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 1 0\n",
      " 0 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 0 1 0 0\n",
      " 1 1 0 0 1 1 0 0 1 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 0 1 0 1 1 0 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 1 1 0 1 0 1 0 0 1 1 0 0 1 0 1 0 1 0 1\n",
      " 1 0 0 1 1 0 1 0 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 1 1 0 1 0 1 0 1\n",
      " 0 0 1 1 0 0 1 1 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 0 1 0 0 1\n",
      " 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 1 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0\n",
      " 1 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1\n",
      " 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 1\n",
      " 0 0 1 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1\n",
      " 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0\n",
      " 1 1 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 0 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1\n",
      " 0 1 0 1 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 0 1 1 0 1 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1 0\n",
      " 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 1 0 1 0 0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 1 1 0 1 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1\n",
      " 1 0 1 0 0 1 0 1 0 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1\n",
      " 0 0 1 0 1 1 0 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 1 0 1 0 0 1 0 1 0 1 0 1 0 1 0 1 1 0 0 1 1 0 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0\n",
      " 1 0 0 1 0 1 0 1 1 0 1 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 1\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\tEstados reales: \\n\", converted_observations)\n",
    "print(\"\\tAcciones reales: \\n\", expert_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4)\n"
     ]
    }
   ],
   "source": [
    "print(converted_observations.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separación de Train y Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00572823 -0.03831238  0.03101629  0.00900886  0.          1.        ]\n",
      " [ 0.00496198  0.15635134  0.03119646 -0.27372897  1.          0.        ]\n",
      " [ 0.00808901 -0.03920152  0.02572188  0.02862788  0.          1.        ]\n",
      " ...\n",
      " [-0.02125562 -0.14190234  0.00628069  0.19885743  0.          1.        ]\n",
      " [-0.02409366  0.05312921  0.01025783 -0.09183763  0.          1.        ]\n",
      " [-0.02303108  0.24810264  0.00842108 -0.38126662  1.          0.        ]]\n",
      "Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento: 800\n",
      "Nº de (ESTADOS,ACCIONES) en el conjunto de prueba: 200\n"
     ]
    }
   ],
   "source": [
    "# Construimos el dataset [s,a] reales y lo dividimos en training y test\n",
    "expert_a_one_hot=np.eye(env.action_space.n)[expert_actions]\n",
    "\n",
    "dataset=np.concatenate([converted_observations,expert_a_one_hot],axis=1)\n",
    "\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test = train_test_split(dataset, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "#Imprime el número de elementos en el conjuntos de entrenamiento y prueba\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento:', len(X_train))\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de prueba:', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "env= gym.make('CartPole-v1')\n",
    "obs,_= env.reset()\n",
    "\n",
    "# Generador\n",
    "generator=Policy_net( 'policy', env, obs)\n",
    "\n",
    "# Generamos [s,a] falsas y las políticas theta_i y theta_i+1\n",
    "observations, actions, rewards, Old_Policy, Policy=generator.generate_fakes()\n",
    "\n",
    "# Discriminador\n",
    "discriminator=Discriminator(env, discriminator_net, converted_observations, expert_actions, observations, actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan2=GAN(discriminator=discriminator,generator=generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "gan2.compile(\n",
    "    d_optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss_fn_D=loss_fn_D\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "d_loss= 2.6745842\n",
      "\n",
      "g_loss= -0.72911835\n",
      "1/9 [==>...........................] - ETA: 58:58 - d_loss: 2.6746 - g_loss: -0.7291\n",
      "\n",
      "\n",
      "d_loss= 2.6363215\n",
      "\n",
      "g_loss= -0.9000978\n",
      "2/9 [=====>........................] - ETA: 55:46 - d_loss: 2.6555 - g_loss: -0.8146\n",
      "\n",
      "\n",
      "d_loss= 2.6540318\n",
      "\n",
      "g_loss= -1.2918525\n",
      "3/9 [=========>....................] - ETA: 46:52 - d_loss: 2.6550 - g_loss: -0.9737\n",
      "\n",
      "\n",
      "d_loss= 2.641611\n",
      "\n",
      "g_loss= -1.1025237\n",
      "4/9 [============>.................] - ETA: 38:36 - d_loss: 2.6516 - g_loss: -1.0059\n",
      "\n",
      "\n",
      "d_loss= 2.5994596\n",
      "\n",
      "g_loss= -0.8518355\n",
      "5/9 [===============>..............] - ETA: 31:03 - d_loss: 2.6412 - g_loss: -0.9751\n",
      "\n",
      "\n",
      "d_loss= 2.6370044\n",
      "\n",
      "g_loss= -0.8713863\n",
      "6/9 [===================>..........] - ETA: 23:15 - d_loss: 2.6405 - g_loss: -0.9578\n",
      "\n",
      "\n",
      "d_loss= 2.6268873\n",
      "\n",
      "g_loss= -0.94496644\n",
      "7/9 [======================>.......] - ETA: 15:35 - d_loss: 2.6386 - g_loss: -0.9560\n",
      "\n",
      "\n",
      "d_loss= 2.6503723\n",
      "\n",
      "g_loss= -0.9250235\n",
      "8/9 [=========================>....] - ETA: 7:45 - d_loss: 2.6400 - g_loss: -0.9521 \n",
      "\n",
      "\n",
      "d_loss= 2.6132221\n",
      "\n",
      "g_loss= -1.0635319\n",
      "9/9 [==============================] - 4173s 466s/step - d_loss: 2.6371 - g_loss: -0.9645\n"
     ]
    }
   ],
   "source": [
    "# Deshabilitar los mensajes de información de TensorFlow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Deshabilitar los mensajes de información de OpenAI Gym\n",
    "gym.logger.set_level(40)\n",
    "\n",
    "history=gan2.fit(X_train,\n",
    "    epochs=EPOCHS,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7091 - accuracy: 0.9950\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7073 - accuracy: 0.8105\n",
      ">Loss real: \n",
      "0.7091325521469116\n",
      ">Loss fake: \n",
      "0.7073278427124023\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos el Discriminador de GAIL en el TEST\n",
    "gan2.evaluate_D(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  0 Total reward: 500.0\n",
      "Episode  1 Total reward: 500.0\n",
      "Episode  2 Total reward: 500.0\n",
      "Episode  3 Total reward: 500.0\n",
      "Episode  4 Total reward: 500.0\n",
      "Episode  5 Total reward: 500.0\n",
      "Episode  6 Total reward: 500.0\n",
      "Episode  7 Total reward: 500.0\n",
      "Episode  8 Total reward: 500.0\n",
      "Episode  9 Total reward: 500.0\n",
      "Episode  10 Total reward: 500.0\n",
      "Episode  11 Total reward: 500.0\n",
      "Episode  12 Total reward: 500.0\n",
      "Episode  13 Total reward: 500.0\n",
      "Episode  14 Total reward: 500.0\n",
      "Episode  15 Total reward: 500.0\n",
      "Episode  16 Total reward: 500.0\n",
      "Episode  17 Total reward: 500.0\n",
      "Episode  18 Total reward: 500.0\n",
      "Episode  19 Total reward: 500.0\n",
      "Episode  20 Total reward: 500.0\n",
      "Episode  21 Total reward: 500.0\n",
      "Episode  22 Total reward: 500.0\n",
      "Episode  23 Total reward: 500.0\n",
      "Episode  24 Total reward: 500.0\n",
      "Episode  25 Total reward: 500.0\n",
      "Episode  26 Total reward: 500.0\n",
      "Episode  27 Total reward: 500.0\n",
      "Episode  28 Total reward: 500.0\n",
      "Episode  29 Total reward: 500.0\n",
      "Episode  30 Total reward: 500.0\n",
      "Episode  31 Total reward: 500.0\n",
      "Episode  32 Total reward: 500.0\n",
      "Episode  33 Total reward: 500.0\n",
      "Episode  34 Total reward: 500.0\n",
      "Episode  35 Total reward: 500.0\n",
      "Episode  36 Total reward: 500.0\n",
      "Episode  37 Total reward: 500.0\n",
      "Episode  38 Total reward: 500.0\n",
      "Episode  39 Total reward: 500.0\n",
      "Episode  40 Total reward: 500.0\n",
      "Episode  41 Total reward: 500.0\n",
      "Episode  42 Total reward: 500.0\n",
      "Episode  43 Total reward: 500.0\n",
      "Episode  44 Total reward: 500.0\n",
      "Episode  45 Total reward: 500.0\n",
      "Episode  46 Total reward: 500.0\n",
      "Episode  47 Total reward: 500.0\n",
      "Episode  48 Total reward: 500.0\n",
      "Episode  49 Total reward: 500.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recompensa de Media: 500.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos al Generador \n",
    "rewardMean=gan2.evaluate_G()\n",
    "print('\\nRecompensa de Media:', rewardMean, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción de base de datos experta con 1 trayectoria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_observations = np.genfromtxt(\"observations_CartPole_.csv\",delimiter=\"\\t\",dtype=str)\n",
    "expert_actions = np.genfromtxt('actions_CartPole_.csv', dtype=np.int32)\n",
    "expert_num_tray=np.genfromtxt('n_trayectoria_CartPole_.csv', dtype=np.int32)\n",
    "\n",
    "# Reemplazar las comas\n",
    "expert_observations = np.core.defchararray.replace(expert_observations, ',', ' ')\n",
    "\n",
    "# Crear un nuevo array para almacenar los datos convertidos\n",
    "converted_observations = np.genfromtxt(expert_observations, delimiter=' ', dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n"
     ]
    }
   ],
   "source": [
    "longitud_trayectoria += np.count_nonzero(expert_num_tray == 2)\n",
    "print(longitud_trayectoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos quedamos solo con la primera trayectoria\n",
    "converted_observations=converted_observations[0:longitud_trayectoria]\n",
    "expert_actions=expert_actions[0:longitud_trayectoria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEstados reales: \n",
      " [[ 5.7282310e-03 -3.8312376e-02  3.1016285e-02  9.0088570e-03]\n",
      " [ 4.9619833e-03  1.5635134e-01  3.1196462e-02 -2.7372897e-01]\n",
      " [ 8.0890100e-03 -3.9201517e-02  2.5721883e-02  2.8627882e-02]\n",
      " ...\n",
      " [-2.9287953e-02  2.1513289e-01  6.6173290e-03 -3.3733398e-01]\n",
      " [-2.4985295e-02  1.9917408e-02 -1.2935029e-04 -4.2571660e-02]\n",
      " [-2.4586946e-02 -1.7520268e-01 -9.8078350e-04  2.5007045e-01]]\n",
      "\tAcciones reales: \n",
      " [1 0 1 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\tEstados reales: \\n\", converted_observations)\n",
    "print(\"\\tAcciones reales: \\n\", expert_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separación de Train y Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.7282310e-03 -3.8312376e-02  3.1016285e-02  9.0088570e-03\n",
      "   0.0000000e+00  1.0000000e+00]\n",
      " [ 4.9619833e-03  1.5635134e-01  3.1196462e-02 -2.7372897e-01\n",
      "   1.0000000e+00  0.0000000e+00]\n",
      " [ 8.0890100e-03 -3.9201517e-02  2.5721883e-02  2.8627882e-02\n",
      "   0.0000000e+00  1.0000000e+00]\n",
      " ...\n",
      " [-2.9287953e-02  2.1513289e-01  6.6173290e-03 -3.3733398e-01\n",
      "   1.0000000e+00  0.0000000e+00]\n",
      " [-2.4985295e-02  1.9917408e-02 -1.2935029e-04 -4.2571660e-02\n",
      "   1.0000000e+00  0.0000000e+00]\n",
      " [-2.4586946e-02 -1.7520268e-01 -9.8078350e-04  2.5007045e-01\n",
      "   0.0000000e+00  1.0000000e+00]]\n",
      "Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento: 1200\n",
      "Nº de (ESTADOS,ACCIONES) en el conjunto de prueba: 300\n"
     ]
    }
   ],
   "source": [
    "# Construimos el dataset [s,a] reales y lo dividimos en training y test\n",
    "expert_a_one_hot=np.eye(env.action_space.n)[expert_actions]\n",
    "\n",
    "dataset=np.concatenate([converted_observations,expert_a_one_hot],axis=1)\n",
    "\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test = train_test_split(dataset, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "#Imprime el número de elementos en el conjuntos de entrenamiento y prueba\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento:', len(X_train))\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de prueba:', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "env= gym.make('CartPole-v1')\n",
    "obs,_= env.reset()\n",
    "\n",
    "# Generador\n",
    "generator=Policy_net( 'policy', env, obs)\n",
    "\n",
    "# Generamos [s,a] falsas y las políticas theta_i y theta_i+1\n",
    "observations, actions, rewards, Old_Policy, Policy=generator.generate_fakes()\n",
    "\n",
    "# Discriminador\n",
    "discriminator=Discriminator(env, discriminator_net, converted_observations, expert_actions, observations, actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan3=GAN(discriminator=discriminator,generator=generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "gan3.compile(\n",
    "    d_optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss_fn_D=loss_fn_D\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "d_loss= 2.6289845\n",
      "\n",
      "g_loss= -1.2089212\n",
      " 1/14 [=>............................] - ETA: 1:40:47 - d_loss: 2.6290 - g_loss: -1.2089\n",
      "\n",
      "\n",
      "d_loss= 2.5845017\n",
      "\n",
      "g_loss= -0.94972074\n",
      " 2/14 [===>..........................] - ETA: 1:32:08 - d_loss: 2.6067 - g_loss: -1.0793\n",
      "\n",
      "\n",
      "d_loss= 2.674271\n",
      "\n",
      "g_loss= -0.8244537\n",
      " 3/14 [=====>........................] - ETA: 1:25:38 - d_loss: 2.6293 - g_loss: -0.9944\n",
      "\n",
      "\n",
      "d_loss= 2.6239052\n",
      "\n",
      "g_loss= -1.2234056\n",
      " 4/14 [=======>......................] - ETA: 1:17:31 - d_loss: 2.6279 - g_loss: -1.0516\n",
      "\n",
      "\n",
      "d_loss= 2.5944042\n",
      "\n",
      "g_loss= -1.1377223\n",
      " 5/14 [=========>....................] - ETA: 1:09:30 - d_loss: 2.6212 - g_loss: -1.0688\n",
      "\n",
      "\n",
      "d_loss= 2.5870194\n",
      "\n",
      "g_loss= -1.1998097\n",
      " 6/14 [===========>..................] - ETA: 1:01:19 - d_loss: 2.6155 - g_loss: -1.0907\n",
      "\n",
      "\n",
      "d_loss= 2.6034532\n",
      "\n",
      "g_loss= -1.2339392\n",
      " 7/14 [==============>...............] - ETA: 53:31 - d_loss: 2.6138 - g_loss: -1.1111  \n",
      "\n",
      "\n",
      "d_loss= 2.5973024\n",
      "\n",
      "g_loss= -0.869532\n",
      " 8/14 [================>.............] - ETA: 45:45 - d_loss: 2.6117 - g_loss: -1.0809\n",
      "\n",
      "\n",
      "d_loss= 2.63914\n",
      "\n",
      "g_loss= -0.88255835\n",
      " 9/14 [==================>...........] - ETA: 38:00 - d_loss: 2.6148 - g_loss: -1.0589\n",
      "\n",
      "\n",
      "d_loss= 2.5793254\n",
      "\n",
      "g_loss= -0.701835\n",
      "10/14 [====================>.........] - ETA: 30:20 - d_loss: 2.6112 - g_loss: -1.0232\n",
      "\n",
      "\n",
      "d_loss= 2.5548558\n",
      "\n",
      "g_loss= -0.7433161\n",
      "11/14 [======================>.......] - ETA: 22:42 - d_loss: 2.6061 - g_loss: -0.9977\n",
      "\n",
      "\n",
      "d_loss= 2.5800865\n",
      "\n",
      "g_loss= -1.1410003\n",
      "12/14 [========================>.....] - ETA: 15:10 - d_loss: 2.6039 - g_loss: -1.0097\n",
      "\n",
      "\n",
      "d_loss= 2.5794873\n",
      "\n",
      "g_loss= -0.76276255\n",
      "13/14 [==========================>...] - ETA: 7:35 - d_loss: 2.6021 - g_loss: -0.9907 \n",
      "\n",
      "\n",
      "d_loss= 2.606735\n",
      "\n",
      "g_loss= -1.2037426\n",
      "14/14 [==============================] - 6402s 457s/step - d_loss: 2.6024 - g_loss: -1.0059\n"
     ]
    }
   ],
   "source": [
    "# Deshabilitar los mensajes de información de TensorFlow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Deshabilitar los mensajes de información de OpenAI Gym\n",
    "gym.logger.set_level(40)\n",
    "\n",
    "history=gan3.fit(X_train,\n",
    "    epochs=EPOCHS,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6535 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6419 - accuracy: 0.0000e+00\n",
      ">Loss real: \n",
      "0.6535306572914124\n",
      ">Loss fake: \n",
      "0.6419296860694885\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos el Discriminador de GAIL en el TEST\n",
    "gan3.evaluate_D(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  0 Total reward: 500.0\n",
      "Episode  1 Total reward: 500.0\n",
      "Episode  2 Total reward: 500.0\n",
      "Episode  3 Total reward: 500.0\n",
      "Episode  4 Total reward: 500.0\n",
      "Episode  5 Total reward: 500.0\n",
      "Episode  6 Total reward: 500.0\n",
      "Episode  7 Total reward: 500.0\n",
      "Episode  8 Total reward: 500.0\n",
      "Episode  9 Total reward: 500.0\n",
      "Episode  10 Total reward: 500.0\n",
      "Episode  11 Total reward: 500.0\n",
      "Episode  12 Total reward: 500.0\n",
      "Episode  13 Total reward: 500.0\n",
      "Episode  14 Total reward: 500.0\n",
      "Episode  15 Total reward: 500.0\n",
      "Episode  16 Total reward: 500.0\n",
      "Episode  17 Total reward: 500.0\n",
      "Episode  18 Total reward: 500.0\n",
      "Episode  19 Total reward: 500.0\n",
      "Episode  20 Total reward: 500.0\n",
      "Episode  21 Total reward: 500.0\n",
      "Episode  22 Total reward: 500.0\n",
      "Episode  23 Total reward: 500.0\n",
      "Episode  24 Total reward: 500.0\n",
      "Episode  25 Total reward: 500.0\n",
      "Episode  26 Total reward: 500.0\n",
      "Episode  27 Total reward: 500.0\n",
      "Episode  28 Total reward: 500.0\n",
      "Episode  29 Total reward: 500.0\n",
      "Episode  30 Total reward: 500.0\n",
      "Episode  31 Total reward: 500.0\n",
      "Episode  32 Total reward: 500.0\n",
      "Episode  33 Total reward: 500.0\n",
      "Episode  34 Total reward: 500.0\n",
      "Episode  35 Total reward: 500.0\n",
      "Episode  36 Total reward: 500.0\n",
      "Episode  37 Total reward: 500.0\n",
      "Episode  38 Total reward: 500.0\n",
      "Episode  39 Total reward: 500.0\n",
      "Episode  40 Total reward: 500.0\n",
      "Episode  41 Total reward: 500.0\n",
      "Episode  42 Total reward: 500.0\n",
      "Episode  43 Total reward: 500.0\n",
      "Episode  44 Total reward: 500.0\n",
      "Episode  45 Total reward: 500.0\n",
      "Episode  46 Total reward: 500.0\n",
      "Episode  47 Total reward: 500.0\n",
      "Episode  48 Total reward: 500.0\n",
      "Episode  49 Total reward: 500.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recompensa de Media: 500.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos al Generador \n",
    "rewardMean=gan3.evaluate_G()\n",
    "print('\\nRecompensa de Media:', rewardMean, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción de base de datos experta con 4 trayectoria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_observations = np.genfromtxt(\"observations_CartPole_.csv\",delimiter=\"\\t\",dtype=str)\n",
    "expert_actions = np.genfromtxt('actions_CartPole_.csv', dtype=np.int32)\n",
    "expert_num_tray=np.genfromtxt('n_trayectoria_CartPole_.csv', dtype=np.int32)\n",
    "\n",
    "# Reemplazar las comas\n",
    "expert_observations = np.core.defchararray.replace(expert_observations, ',', ' ')\n",
    "\n",
    "# Crear un nuevo array para almacenar los datos convertidos\n",
    "converted_observations = np.genfromtxt(expert_observations, delimiter=' ', dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "longitud_trayectoria += np.count_nonzero(expert_num_tray == 3)\n",
    "print(longitud_trayectoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos quedamos solo con la primera trayectoria\n",
    "converted_observations=converted_observations[0:longitud_trayectoria]\n",
    "expert_actions=expert_actions[0:longitud_trayectoria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEstados reales: \n",
      " [[ 0.00572823 -0.03831238  0.03101629  0.00900886]\n",
      " [ 0.00496198  0.15635134  0.03119646 -0.27372897]\n",
      " [ 0.00808901 -0.03920152  0.02572188  0.02862788]\n",
      " ...\n",
      " [-0.03044969  0.14637755 -0.00377016 -0.21959685]\n",
      " [-0.02752214 -0.04869031 -0.0081621   0.07189444]\n",
      " [-0.02849595  0.1465477  -0.00672421 -0.22335246]]\n",
      "\tAcciones reales: \n",
      " [1 0 1 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\tEstados reales: \\n\", converted_observations)\n",
    "print(\"\\tAcciones reales: \\n\", expert_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separación de Train y Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00572823 -0.03831238  0.03101629  0.00900886  0.          1.        ]\n",
      " [ 0.00496198  0.15635134  0.03119646 -0.27372897  1.          0.        ]\n",
      " [ 0.00808901 -0.03920152  0.02572188  0.02862788  0.          1.        ]\n",
      " ...\n",
      " [-0.03044969  0.14637755 -0.00377016 -0.21959685  1.          0.        ]\n",
      " [-0.02752214 -0.04869031 -0.0081621   0.07189444  0.          1.        ]\n",
      " [-0.02849595  0.1465477  -0.00672421 -0.22335246  1.          0.        ]]\n",
      "Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento: 1600\n",
      "Nº de (ESTADOS,ACCIONES) en el conjunto de prueba: 400\n"
     ]
    }
   ],
   "source": [
    "# Construimos el dataset [s,a] reales y lo dividimos en training y test\n",
    "expert_a_one_hot=np.eye(env.action_space.n)[expert_actions]\n",
    "\n",
    "dataset=np.concatenate([converted_observations,expert_a_one_hot],axis=1)\n",
    "\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test = train_test_split(dataset, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "#Imprime el número de elementos en el conjuntos de entrenamiento y prueba\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento:', len(X_train))\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de prueba:', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "env= gym.make('CartPole-v1')\n",
    "obs,_= env.reset()\n",
    "\n",
    "# Generador\n",
    "generator=Policy_net( 'policy', env, obs)\n",
    "\n",
    "# Generamos [s,a] falsas y las políticas theta_i y theta_i+1\n",
    "observations, actions, rewards, Old_Policy, Policy=generator.generate_fakes()\n",
    "\n",
    "# Discriminador\n",
    "discriminator=Discriminator(env, discriminator_net, converted_observations, expert_actions, observations, actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan4=GAN(discriminator=discriminator,generator=generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "gan4.compile(\n",
    "    d_optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss_fn_D=loss_fn_D\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "d_loss= 2.542076\n",
      "\n",
      "g_loss= -0.79300094\n",
      " 1/18 [>.............................] - ETA: 2:12:46 - d_loss: 2.5421 - g_loss: -0.7930\n",
      "\n",
      "\n",
      "d_loss= 2.5521266\n",
      "\n",
      "g_loss= -1.1777778\n",
      " 2/18 [==>...........................] - ETA: 2:00:51 - d_loss: 2.5471 - g_loss: -0.9854\n",
      "\n",
      "\n",
      "d_loss= 2.5302887\n",
      "\n",
      "g_loss= -0.90146625\n",
      " 3/18 [====>.........................] - ETA: 1:55:36 - d_loss: 2.5415 - g_loss: -0.9574\n",
      "\n",
      "\n",
      "d_loss= 2.5423343\n",
      "\n",
      "g_loss= -0.6153197\n",
      " 4/18 [=====>........................] - ETA: 1:47:27 - d_loss: 2.5417 - g_loss: -0.8719\n",
      "\n",
      "\n",
      "d_loss= 2.567187\n",
      "\n",
      "g_loss= -1.1002028\n",
      " 5/18 [=======>......................] - ETA: 1:42:12 - d_loss: 2.5468 - g_loss: -0.9176\n",
      "\n",
      "\n",
      "d_loss= 2.5559196\n",
      "\n",
      "g_loss= -1.1382117\n",
      " 6/18 [=========>....................] - ETA: 1:34:23 - d_loss: 2.5483 - g_loss: -0.9543\n",
      "\n",
      "\n",
      "d_loss= 2.528142\n",
      "\n",
      "g_loss= -0.7512719\n",
      " 7/18 [==========>...................] - ETA: 1:26:22 - d_loss: 2.5454 - g_loss: -0.9253\n",
      "\n",
      "\n",
      "d_loss= 2.5088196\n",
      "\n",
      "g_loss= -0.8989172\n",
      " 8/18 [============>.................] - ETA: 1:19:00 - d_loss: 2.5409 - g_loss: -0.9220\n",
      "\n",
      "\n",
      "d_loss= 2.4813871\n",
      "\n",
      "g_loss= -0.79997176\n",
      " 9/18 [==============>...............] - ETA: 1:11:20 - d_loss: 2.5343 - g_loss: -0.9085\n",
      "\n",
      "\n",
      "d_loss= 2.4972653\n",
      "\n",
      "g_loss= -0.9424855\n",
      "10/18 [===============>..............] - ETA: 1:03:05 - d_loss: 2.5306 - g_loss: -0.9119\n",
      "\n",
      "\n",
      "d_loss= 2.495546\n",
      "\n",
      "g_loss= -1.0324641\n",
      "11/18 [=================>............] - ETA: 54:55 - d_loss: 2.5274 - g_loss: -0.9228  \n",
      "\n",
      "\n",
      "d_loss= 2.5619323\n",
      "\n",
      "g_loss= -1.0310322\n",
      "12/18 [===================>..........] - ETA: 46:58 - d_loss: 2.5303 - g_loss: -0.9318\n",
      "\n",
      "\n",
      "d_loss= 2.4717913\n",
      "\n",
      "g_loss= -1.0480922\n",
      "13/18 [====================>.........] - ETA: 39:03 - d_loss: 2.5258 - g_loss: -0.9408\n",
      "\n",
      "\n",
      "d_loss= 2.436039\n",
      "\n",
      "g_loss= -0.56822914\n",
      "14/18 [======================>.......] - ETA: 31:12 - d_loss: 2.5193 - g_loss: -0.9142\n",
      "\n",
      "\n",
      "d_loss= 2.4982464\n",
      "\n",
      "g_loss= -1.2146819\n",
      "15/18 [========================>.....] - ETA: 23:21 - d_loss: 2.5179 - g_loss: -0.9342\n",
      "\n",
      "\n",
      "d_loss= 2.5431936\n",
      "\n",
      "g_loss= -0.81530446\n",
      "16/18 [=========================>....] - ETA: 15:32 - d_loss: 2.5195 - g_loss: -0.9268\n",
      "\n",
      "\n",
      "d_loss= 2.4822757\n",
      "\n",
      "g_loss= -1.2129103\n",
      "17/18 [===========================>..] - ETA: 7:44 - d_loss: 2.5173 - g_loss: -0.9436 \n",
      "\n",
      "\n",
      "d_loss= 2.5453348\n",
      "\n",
      "g_loss= -0.9552916\n",
      "18/18 [==============================] - 8347s 463s/step - d_loss: 2.5189 - g_loss: -0.9443\n"
     ]
    }
   ],
   "source": [
    "# Deshabilitar los mensajes de información de TensorFlow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Deshabilitar los mensajes de información de OpenAI Gym\n",
    "gym.logger.set_level(40)\n",
    "\n",
    "history=gan4.fit(X_train,\n",
    "    epochs=EPOCHS,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5781 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5830 - accuracy: 0.0000e+00\n",
      ">Loss real: \n",
      "0.5781092643737793\n",
      ">Loss fake: \n",
      "0.5829794406890869\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos el Discriminador de GAIL en el TEST\n",
    "gan4.evaluate_D(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  0 Total reward: 500.0\n",
      "Episode  1 Total reward: 500.0\n",
      "Episode  2 Total reward: 500.0\n",
      "Episode  3 Total reward: 500.0\n",
      "Episode  4 Total reward: 500.0\n",
      "Episode  5 Total reward: 500.0\n",
      "Episode  6 Total reward: 500.0\n",
      "Episode  7 Total reward: 500.0\n",
      "Episode  8 Total reward: 500.0\n",
      "Episode  9 Total reward: 500.0\n",
      "Episode  10 Total reward: 500.0\n",
      "Episode  11 Total reward: 500.0\n",
      "Episode  12 Total reward: 500.0\n",
      "Episode  13 Total reward: 500.0\n",
      "Episode  14 Total reward: 500.0\n",
      "Episode  15 Total reward: 500.0\n",
      "Episode  16 Total reward: 500.0\n",
      "Episode  17 Total reward: 500.0\n",
      "Episode  18 Total reward: 500.0\n",
      "Episode  19 Total reward: 500.0\n",
      "Episode  20 Total reward: 500.0\n",
      "Episode  21 Total reward: 500.0\n",
      "Episode  22 Total reward: 500.0\n",
      "Episode  23 Total reward: 500.0\n",
      "Episode  24 Total reward: 500.0\n",
      "Episode  25 Total reward: 500.0\n",
      "Episode  26 Total reward: 500.0\n",
      "Episode  27 Total reward: 500.0\n",
      "Episode  28 Total reward: 500.0\n",
      "Episode  29 Total reward: 500.0\n",
      "Episode  30 Total reward: 500.0\n",
      "Episode  31 Total reward: 500.0\n",
      "Episode  32 Total reward: 500.0\n",
      "Episode  33 Total reward: 500.0\n",
      "Episode  34 Total reward: 500.0\n",
      "Episode  35 Total reward: 500.0\n",
      "Episode  36 Total reward: 500.0\n",
      "Episode  37 Total reward: 500.0\n",
      "Episode  38 Total reward: 500.0\n",
      "Episode  39 Total reward: 500.0\n",
      "Episode  40 Total reward: 500.0\n",
      "Episode  41 Total reward: 500.0\n",
      "Episode  42 Total reward: 500.0\n",
      "Episode  43 Total reward: 500.0\n",
      "Episode  44 Total reward: 500.0\n",
      "Episode  45 Total reward: 500.0\n",
      "Episode  46 Total reward: 500.0\n",
      "Episode  47 Total reward: 500.0\n",
      "Episode  48 Total reward: 500.0\n",
      "Episode  49 Total reward: 500.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAeiklEQVR4nO3dfWyV9f3/8dfp3Sk3PecAlh46WpQwKAXKBGY5G2zGdhTomFMiSjoljsBkxXEzDLLpqJpY4syWiQ68i7iErYILTpkyiwhMKAgFZkVGgKDUtIdOm/a0IKW01/cPf5ztTPTHoS3n3e75SK6EXnfnc33ScJ65evXU5TiOIwAAAEPiYj0AAACA/0agAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwJyEWA/gSrS3t6umpkYpKSlyuVyxHg4AALgMjuOoqalJ6enpiov76nsk3TJQampqlJGREethAACAK1BdXa3Bgwd/5T7dMlBSUlIkfX6BHo8nxqMBAACXIxQKKSMjI/w+/lW6ZaBc/LGOx+MhUAAA6GYu5/EMHpIFAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJgTVaCUlJTI5XJFLFlZWZKk+vp63XvvvRoxYoR69eqlzMxM/exnP1NjY2PEOU6dOqXCwkL17t1bAwcO1H333acLFy503hUBAIBuLyHaA0aNGqWtW7f++wQJn5+ipqZGNTU1evzxx5Wdna2PPvpI99xzj2pqavTyyy9Lktra2lRYWCi/36/du3ertrZWd911lxITE/Xoo4920iUBAIDuzuU4jnO5O5eUlOiVV17RoUOHLmv/jRs36kc/+pHOnDmjhIQEvfHGG/r+97+vmpoapaWlSZLWrl2r5cuX61//+peSkpIu67yhUEher1eNjY3yeDyXO3wAABBD0bx/R/0MyrFjx5Senq6hQ4eqqKhIp06d+tJ9Lw7g4l2WiooKjRkzJhwnklRQUKBQKKTDhw9/6XlaWloUCoUiFgAA0HNFFSi5ublat26dtmzZojVr1ujkyZOaPHmympqavrDvJ598okceeUTz588PrwsGgxFxIin8dTAY/NLXLS0tldfrDS8ZGRnRDBsAAHQzUQXKtGnTdNtttyknJ0cFBQV6/fXX1dDQoA0bNkTsFwqFVFhYqOzsbJWUlHR4kCtWrFBjY2N4qa6u7vA5AQCAXVE/JPuffD6fhg8fruPHj4fXNTU1aerUqUpJSdGmTZuUmJgY3ub3+/Xuu+9GnOP06dPhbV/G7XbL7XZ3ZKgAAKAb6dDnoDQ3N+vEiRMaNGiQpM/vnEyZMkVJSUl69dVXlZycHLF/IBBQVVWV6urqwuvKy8vl8XiUnZ3dkaEAAIAeJKpAWbZsmXbs2KEPP/xQu3fv1i233KL4+HjNnj07HCdnzpzR888/r1AopGAwqGAwqLa2NknSlClTlJ2drTvvvFP/+Mc/9Le//U0PPPCAiouLuUMCAADCovoRz8cff6zZs2fr008/VWpqqiZNmqQ9e/YoNTVV27dv1969eyVJw4YNizju5MmTuvbaaxUfH6/NmzdrwYIFCgQC6tOnj+bMmaOHH364864IAAB0e1F9DooVfA4KAADdT5d+DgoAAEBXI1AAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgTlSBUlJSIpfLFbFkZWWFtz/zzDO68cYb5fF45HK51NDQ8IVz1NfXq6ioSB6PRz6fT3PnzlVzc3OHLwQAAPQcUd9BGTVqlGpra8PLO++8E9529uxZTZ06Vb/4xS++9PiioiIdPnxY5eXl2rx5s3bu3Kn58+df2egBAECPlBD1AQkJ8vv9l9y2ePFiSdL27dsvuf3IkSPasmWL9u3bpwkTJkiSVq9erenTp+vxxx9Xenp6tMMBAAA9UNR3UI4dO6b09HQNHTpURUVFOnXq1GUfW1FRIZ/PF44TScrPz1dcXJz27t37pce1tLQoFApFLAAAoOeKKlByc3O1bt06bdmyRWvWrNHJkyc1efJkNTU1XdbxwWBQAwcOjFiXkJCg/v37KxgMfulxpaWl8nq94SUjIyOaYQMAgG4mqkCZNm2abrvtNuXk5KigoECvv/66GhoatGHDhq4anyRpxYoVamxsDC/V1dVd+noAACC2on4G5T/5fD4NHz5cx48fv6z9/X6/6urqItZduHBB9fX1X/pciyS53W653e6ODBUAAHQjHfoclObmZp04cUKDBg26rP0DgYAaGhpUWVkZXrdt2za1t7crNze3I0MBAAA9SFR3UJYtW6YZM2ZoyJAhqqmp0cqVKxUfH6/Zs2dL+vwZk2AwGL6jUlVVpZSUFGVmZqp///4aOXKkpk6dqnnz5mnt2rVqbW3VwoULdccdd/AbPAAAICyqOygff/yxZs+erREjRmjWrFkaMGCA9uzZo9TUVEnS2rVrdf3112vevHmSpO985zu6/vrr9eqrr4bPsX79emVlZSkvL0/Tp0/XpEmT9Mwzz3TiJQEAgO7O5TiOE+tBRCsUCsnr9aqxsVEejyfWwwEAAJchmvdv/hYPAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOVEFSklJiVwuV8SSlZUV3n7u3DkVFxdrwIAB6tu3r2bOnKnTp09HnOPUqVMqLCxU7969NXDgQN133326cOFC51wNAADoERKiPWDUqFHaunXrv0+Q8O9TLFmyRH/961+1ceNGeb1eLVy4ULfeeqt27dolSWpra1NhYaH8fr92796t2tpa3XXXXUpMTNSjjz7aCZcDAAB6gqgDJSEhQX6//wvrGxsb9fzzz+uPf/yjbrrpJknSCy+8oJEjR2rPnj2aOHGi3nzzTX3wwQfaunWr0tLS9I1vfEOPPPKIli9frpKSEiUlJXX8ijrAcRx91toW0zEAAGBFr8R4uVyumLx21IFy7NgxpaenKzk5WYFAQKWlpcrMzFRlZaVaW1uVn58f3jcrK0uZmZmqqKjQxIkTVVFRoTFjxigtLS28T0FBgRYsWKDDhw/r+uuvv+RrtrS0qKWlJfx1KBSKdtiX5bPWNmX/6m9dcm4AALqbDx4uUO+kqFOhU0T1DEpubq7WrVunLVu2aM2aNTp58qQmT56spqYmBYNBJSUlyefzRRyTlpamYDAoSQoGgxFxcnH7xW1fprS0VF6vN7xkZGREM2wAANDNRJVF06ZNC/87JydHubm5GjJkiDZs2KBevXp1+uAuWrFihZYuXRr+OhQKdUmk9EqM1wcPF3T6eQEA6I56JcbH7LU7dN/G5/Np+PDhOn78uL73ve/p/PnzamhoiLiLcvr06fAzK36/X++++27EOS7+ls+lnmu5yO12y+12d2Sol8XlcsXsVhYAAPi3Dn0OSnNzs06cOKFBgwZp/PjxSkxM1FtvvRXefvToUZ06dUqBQECSFAgEVFVVpbq6uvA+5eXl8ng8ys7O7shQAABADxLV7YJly5ZpxowZGjJkiGpqarRy5UrFx8dr9uzZ8nq9mjt3rpYuXar+/fvL4/Ho3nvvVSAQ0MSJEyVJU6ZMUXZ2tu6880499thjCgaDeuCBB1RcXHxV7pAAAIDuIapA+fjjjzV79mx9+umnSk1N1aRJk7Rnzx6lpqZKkn77298qLi5OM2fOVEtLiwoKCvT73/8+fHx8fLw2b96sBQsWKBAIqE+fPpozZ44efvjhzr0qAADQrbkcx3FiPYhohUIheb1eNTY2yuPxxHo4AADgMkTz/s3f4gEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOZ0KFBWrVoll8ulxYsXh9edOHFCt9xyi1JTU+XxeDRr1iydPn064rj6+noVFRXJ4/HI5/Np7ty5am5u7shQAABAD3LFgbJv3z49/fTTysnJCa87c+aMpkyZIpfLpW3btmnXrl06f/68ZsyYofb29vB+RUVFOnz4sMrLy7V582bt3LlT8+fP79iVAACAHuOKAqW5uVlFRUV69tln1a9fv/D6Xbt26cMPP9S6des0ZswYjRkzRi+++KL279+vbdu2SZKOHDmiLVu26LnnnlNubq4mTZqk1atXq6ysTDU1NZ1zVQAAoFu7okApLi5WYWGh8vPzI9a3tLTI5XLJ7XaH1yUnJysuLk7vvPOOJKmiokI+n08TJkwI75Ofn6+4uDjt3bv3kq/X0tKiUCgUsQAAgJ4r6kApKyvTgQMHVFpa+oVtEydOVJ8+fbR8+XKdPXtWZ86c0bJly9TW1qba2lpJUjAY1MCBAyOOS0hIUP/+/RUMBi/5mqWlpfJ6veElIyMj2mEDAIBuJKpAqa6u1qJFi7R+/XolJyd/YXtqaqo2btyo1157TX379pXX61VDQ4PGjRunuLgrfx53xYoVamxsDC/V1dVXfC4AAGBfQjQ7V1ZWqq6uTuPGjQuva2tr086dO/Xkk0+qpaVFU6ZM0YkTJ/TJJ58oISFBPp9Pfr9fQ4cOlST5/X7V1dVFnPfChQuqr6+X3++/5Ou63e6IHxsBAICeLapAycvLU1VVVcS6u+++W1lZWVq+fLni4+PD66+55hpJ0rZt21RXV6cf/OAHkqRAIKCGhgZVVlZq/Pjx4X3a29uVm5vboYsBAAA9Q1SBkpKSotGjR0es69OnjwYMGBBe/8ILL2jkyJFKTU1VRUWFFi1apCVLlmjEiBGSpJEjR2rq1KmaN2+e1q5dq9bWVi1cuFB33HGH0tPTO+myAABAdxZVoFyOo0ePasWKFaqvr9e1116rX/7yl1qyZEnEPuvXr9fChQuVl5enuLg4zZw5U0888URnDwUAAHRTLsdxnFgPIlqhUEher1eNjY3yeDyxHg4AALgM0bx/87d4AACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzOlQoKxatUoul0uLFy8OrwsGg7rzzjvl9/vVp08fjRs3Tn/+858jjquvr1dRUZE8Ho98Pp/mzp2r5ubmjgwFAAD0IFccKPv27dPTTz+tnJyciPV33XWXjh49qldffVVVVVW69dZbNWvWLB08eDC8T1FRkQ4fPqzy8nJt3rxZO3fu1Pz586/8KgAAQI9yRYHS3NysoqIiPfvss+rXr1/Ett27d+vee+/VDTfcoKFDh+qBBx6Qz+dTZWWlJOnIkSPasmWLnnvuOeXm5mrSpElavXq1ysrKVFNT0/ErAgAA3d4VBUpxcbEKCwuVn5//hW3f+ta39NJLL6m+vl7t7e0qKyvTuXPndOONN0qSKioq5PP5NGHChPAx+fn5iouL0969ey/5ei0tLQqFQhELAADouRKiPaCsrEwHDhzQvn37Lrl9w4YNuv322zVgwAAlJCSod+/e2rRpk4YNGybp82dUBg4cGDmIhAT1799fwWDwkucsLS3VQw89FO1QAQBANxXVHZTq6motWrRI69evV3Jy8iX3efDBB9XQ0KCtW7dq//79Wrp0qWbNmqWqqqorHuSKFSvU2NgYXqqrq6/4XAAAwL6o7qBUVlaqrq5O48aNC69ra2vTzp079eSTT+ro0aN68skn9f7772vUqFGSpLFjx+rvf/+7nnrqKa1du1Z+v191dXUR571w4YLq6+vl9/sv+bput1tutzvaawMAAN1UVIGSl5f3hTshd999t7KysrR8+XKdPXtWkhQXF3ljJj4+Xu3t7ZKkQCCghoYGVVZWavz48ZKkbdu2qb29Xbm5uVd8IQAAoOeIKlBSUlI0evToiHV9+vTRgAEDNHr0aLW2tmrYsGH6yU9+oscff1wDBgzQK6+8Ev51YkkaOXKkpk6dqnnz5mnt2rVqbW3VwoULdccddyg9Pb3zrgwAAHRbnfpJsomJiXr99deVmpqqGTNmKCcnR3/4wx/04osvavr06eH91q9fr6ysLOXl5Wn69OmaNGmSnnnmmc4cCgAA6MZcjuM4sR5EtEKhkLxerxobG+XxeGI9HAAAcBmief/mb/EAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGBOQqwHcCUcx5EkhUKhGI8EAABcrovv2xffx79KtwyUpqYmSVJGRkaMRwIAAKLV1NQkr9f7lfu4nMvJGGPa29tVU1OjlJQUuVyuTj13KBRSRkaGqqur5fF4OvXc+CLm++pivq8u5vvqYr6vriuZb8dx1NTUpPT0dMXFffVTJt3yDkpcXJwGDx7cpa/h8Xj4Br+KmO+ri/m+upjvq4v5vrqine//352Ti3hIFgAAmEOgAAAAcwiU/+J2u7Vy5Uq53e5YD+V/AvN9dTHfVxfzfXUx31dXV893t3xIFgAA9GzcQQEAAOYQKAAAwBwCBQAAmEOgAAAAcwiU//DUU0/p2muvVXJysnJzc/Xuu+/Gekg9ws6dOzVjxgylp6fL5XLplVdeidjuOI5+9atfadCgQerVq5fy8/N17Nix2Ay2BygtLdU3v/lNpaSkaODAgfrhD3+oo0ePRuxz7tw5FRcXa8CAAerbt69mzpyp06dPx2jE3duaNWuUk5MT/rCqQCCgN954I7ydue5aq1atksvl0uLFi8PrmPPOU1JSIpfLFbFkZWWFt3flXBMo/89LL72kpUuXauXKlTpw4IDGjh2rgoIC1dXVxXpo3d6ZM2c0duxYPfXUU5fc/thjj+mJJ57Q2rVrtXfvXvXp00cFBQU6d+7cVR5pz7Bjxw4VFxdrz549Ki8vV2trq6ZMmaIzZ86E91myZIlee+01bdy4UTt27FBNTY1uvfXWGI66+xo8eLBWrVqlyspK7d+/XzfddJNuvvlmHT58WBJz3ZX27dunp59+Wjk5ORHrmfPONWrUKNXW1oaXd955J7ytS+fageM4jnPDDTc4xcXF4a/b2tqc9PR0p7S0NIaj6nkkOZs2bQp/3d7e7vj9fufXv/51eF1DQ4PjdrudP/3pTzEYYc9TV1fnSHJ27NjhOM7n85uYmOhs3LgxvM+RI0ccSU5FRUWshtmj9OvXz3nuueeY6y7U1NTkfP3rX3fKy8ud7373u86iRYscx+H7u7OtXLnSGTt27CW3dfVccwdF0vnz51VZWan8/Pzwuri4OOXn56uioiKGI+v5Tp48qWAwGDH3Xq9Xubm5zH0naWxslCT1799fklRZWanW1taIOc/KylJmZiZz3kFtbW0qKyvTmTNnFAgEmOsuVFxcrMLCwoi5lfj+7grHjh1Tenq6hg4dqqKiIp06dUpS1891t/xjgZ3tk08+UVtbm9LS0iLWp6Wl6Z///GeMRvW/IRgMStIl5/7iNly59vZ2LV68WN/+9rc1evRoSZ/PeVJSknw+X8S+zPmVq6qqUiAQ0Llz59S3b19t2rRJ2dnZOnToEHPdBcrKynTgwAHt27fvC9v4/u5cubm5WrdunUaMGKHa2lo99NBDmjx5st5///0un2sCBejBiouL9f7770f8zBidb8SIETp06JAaGxv18ssva86cOdqxY0esh9UjVVdXa9GiRSovL1dycnKsh9PjTZs2LfzvnJwc5ebmasiQIdqwYYN69erVpa/Nj3gkXXPNNYqPj//Ck8enT5+W3++P0aj+N1ycX+a+8y1cuFCbN2/W22+/rcGDB4fX+/1+nT9/Xg0NDRH7M+dXLikpScOGDdP48eNVWlqqsWPH6ne/+x1z3QUqKytVV1encePGKSEhQQkJCdqxY4eeeOIJJSQkKC0tjTnvQj6fT8OHD9fx48e7/PubQNHn/7mMHz9eb731Vnhde3u73nrrLQUCgRiOrOe77rrr5Pf7I+Y+FApp7969zP0VchxHCxcu1KZNm7Rt2zZdd911EdvHjx+vxMTEiDk/evSoTp06xZx3kvb2drW0tDDXXSAvL09VVVU6dOhQeJkwYYKKiorC/2bOu05zc7NOnDihQYMGdf33d4cfs+0hysrKHLfb7axbt8754IMPnPnz5zs+n88JBoOxHlq319TU5Bw8eNA5ePCgI8n5zW9+4xw8eND56KOPHMdxnFWrVjk+n8/5y1/+4rz33nvOzTff7Fx33XXOZ599FuORd08LFixwvF6vs337dqe2tja8nD17NrzPPffc42RmZjrbtm1z9u/f7wQCAScQCMRw1N3X/fff7+zYscM5efKk89577zn333+/43K5nDfffNNxHOb6avjP3+JxHOa8M/385z93tm/f7pw8edLZtWuXk5+f71xzzTVOXV2d4zhdO9cEyn9YvXq1k5mZ6SQlJTk33HCDs2fPnlgPqUd4++23HUlfWObMmeM4zue/avzggw86aWlpjtvtdvLy8pyjR4/GdtDd2KXmWpLzwgsvhPf57LPPnJ/+9KdOv379nN69ezu33HKLU1tbG7tBd2M//vGPnSFDhjhJSUlOamqqk5eXF44Tx2Gur4b/DhTmvPPcfvvtzqBBg5ykpCTna1/7mnP77bc7x48fD2/vyrl2OY7jdPw+DAAAQOfhGRQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMOf/AMJiXdvmZHbnAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recompensa de Media: 500.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos al Generador \n",
    "rewardMean=gan4.evaluate_G()\n",
    "print('\\nRecompensa de Media:', rewardMean, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción de base de datos experta con 5 trayectoria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_observations = np.genfromtxt(\"observations_CartPole_.csv\",delimiter=\"\\t\",dtype=str)\n",
    "expert_actions = np.genfromtxt('actions_CartPole_.csv', dtype=np.int32)\n",
    "expert_num_tray=np.genfromtxt('n_trayectoria_CartPole_.csv', dtype=np.int32)\n",
    "\n",
    "# Reemplazar las comas\n",
    "expert_observations = np.core.defchararray.replace(expert_observations, ',', ' ')\n",
    "\n",
    "# Crear un nuevo array para almacenar los datos convertidos\n",
    "converted_observations = np.genfromtxt(expert_observations, delimiter=' ', dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n"
     ]
    }
   ],
   "source": [
    "longitud_trayectoria += np.count_nonzero(expert_num_tray == 4)\n",
    "print(longitud_trayectoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos quedamos solo con la primera trayectoria\n",
    "converted_observations=converted_observations[0:longitud_trayectoria]\n",
    "expert_actions=expert_actions[0:longitud_trayectoria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEstados reales: \n",
      " [[ 0.00572823 -0.03831238  0.03101629  0.00900886]\n",
      " [ 0.00496198  0.15635134  0.03119646 -0.27372897]\n",
      " [ 0.00808901 -0.03920152  0.02572188  0.02862788]\n",
      " ...\n",
      " [-0.02261659 -0.16291702  0.00098082  0.25042167]\n",
      " [-0.02587493  0.03219091  0.00598926 -0.04195173]\n",
      " [-0.02523111  0.22722647  0.00515022 -0.332739  ]]\n",
      "\tAcciones reales: \n",
      " [1 0 1 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\tEstados reales: \\n\", converted_observations)\n",
    "print(\"\\tAcciones reales: \\n\", expert_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separación de Train y Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.7282310e-03 -3.8312376e-02  3.1016285e-02  9.0088570e-03\n",
      "   0.0000000e+00  1.0000000e+00]\n",
      " [ 4.9619833e-03  1.5635134e-01  3.1196462e-02 -2.7372897e-01\n",
      "   1.0000000e+00  0.0000000e+00]\n",
      " [ 8.0890100e-03 -3.9201517e-02  2.5721883e-02  2.8627882e-02\n",
      "   0.0000000e+00  1.0000000e+00]\n",
      " ...\n",
      " [-2.2616590e-02 -1.6291702e-01  9.8082270e-04  2.5042167e-01\n",
      "   0.0000000e+00  1.0000000e+00]\n",
      " [-2.5874930e-02  3.2190910e-02  5.9892560e-03 -4.1951735e-02\n",
      "   0.0000000e+00  1.0000000e+00]\n",
      " [-2.5231112e-02  2.2722647e-01  5.1502213e-03 -3.3273900e-01\n",
      "   1.0000000e+00  0.0000000e+00]]\n",
      "Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento: 2000\n",
      "Nº de (ESTADOS,ACCIONES) en el conjunto de prueba: 500\n"
     ]
    }
   ],
   "source": [
    "# Construimos el dataset [s,a] reales y lo dividimos en training y test\n",
    "expert_a_one_hot=np.eye(env.action_space.n)[expert_actions]\n",
    "\n",
    "dataset=np.concatenate([converted_observations,expert_a_one_hot],axis=1)\n",
    "\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test = train_test_split(dataset, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "#Imprime el número de elementos en el conjuntos de entrenamiento y prueba\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento:', len(X_train))\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de prueba:', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "env= gym.make('CartPole-v1')\n",
    "obs,_= env.reset()\n",
    "\n",
    "# Generador\n",
    "generator=Policy_net( 'policy', env, obs)\n",
    "\n",
    "# Generamos [s,a] falsas y las políticas theta_i y theta_i+1\n",
    "observations, actions, rewards, Old_Policy, Policy=generator.generate_fakes()\n",
    "\n",
    "# Discriminador\n",
    "discriminator=Discriminator(env, discriminator_net, converted_observations, expert_actions, observations, actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan5=GAN(discriminator=discriminator,generator=generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "gan5.compile(\n",
    "    d_optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss_fn_D=loss_fn_D\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "d_loss= 2.4715126\n",
      "\n",
      "g_loss= -0.891493\n",
      " 1/23 [>.............................] - ETA: 2:47:31 - d_loss: 2.4715 - g_loss: -0.8915\n",
      "\n",
      "\n",
      "d_loss= 2.4639573\n",
      "\n",
      "g_loss= -0.725038\n",
      " 2/23 [=>............................] - ETA: 2:37:22 - d_loss: 2.4677 - g_loss: -0.8083\n",
      "\n",
      "\n",
      "d_loss= 2.4285548\n",
      "\n",
      "g_loss= nan\n",
      " 3/23 [==>...........................] - ETA: 2:32:24 - d_loss: 2.4547 - g_loss: nan    \n",
      "\n",
      "\n",
      "d_loss= 2.532225\n",
      "\n",
      "g_loss= -0.830414\n",
      " 4/23 [====>.........................] - ETA: 2:25:27 - d_loss: 2.4741 - g_loss: nan\n",
      "\n",
      "\n",
      "d_loss= 2.4126983\n",
      "\n",
      "g_loss= -1.1243919\n",
      " 5/23 [=====>........................] - ETA: 2:20:16 - d_loss: 2.4618 - g_loss: nan\n",
      "\n",
      "\n",
      "d_loss= 2.456843\n",
      "\n",
      "g_loss= -0.95814013\n",
      " 6/23 [======>.......................] - ETA: 2:15:05 - d_loss: 2.4610 - g_loss: nan\n",
      "\n",
      "\n",
      "d_loss= 2.4314651\n",
      "\n",
      "g_loss= -1.1352364\n",
      " 7/23 [========>.....................] - ETA: 2:08:06 - d_loss: 2.4568 - g_loss: nan\n",
      "\n",
      "\n",
      "d_loss= 2.4387815\n",
      "\n",
      "g_loss= -1.055678\n",
      " 8/23 [=========>....................] - ETA: 2:00:16 - d_loss: 2.4545 - g_loss: nan\n",
      "\n",
      "\n",
      "d_loss= 2.4242055\n",
      "\n",
      "g_loss= -0.8699109\n",
      " 9/23 [==========>...................] - ETA: 1:52:12 - d_loss: 2.4511 - g_loss: nan\n",
      "\n",
      "\n",
      "d_loss= 2.4524565\n",
      "\n",
      "g_loss= -1.3125368\n",
      "10/23 [============>.................] - ETA: 1:43:16 - d_loss: 2.4513 - g_loss: nan\n",
      "\n",
      "\n",
      "d_loss= 2.5328918\n",
      "\n",
      "g_loss= -0.82799363\n",
      "11/23 [=============>................] - ETA: 1:35:02 - d_loss: 2.4587 - g_loss: nan\n",
      "\n",
      "\n",
      "d_loss= 2.3792572\n",
      "\n",
      "g_loss= -1.235962\n",
      "12/23 [==============>...............] - ETA: 1:26:54 - d_loss: 2.4521 - g_loss: nan\n",
      "\n",
      "\n",
      "d_loss= 2.4294338\n",
      "\n",
      "g_loss= -0.8172547\n",
      "13/23 [===============>..............] - ETA: 1:18:48 - d_loss: 2.4503 - g_loss: nan\n",
      "\n",
      "\n",
      "d_loss= 2.3917398\n",
      "\n",
      "g_loss= -1.0171549\n",
      "14/23 [=================>............] - ETA: 1:10:35 - d_loss: 2.4461 - g_loss: nan\n",
      "\n",
      "\n",
      "d_loss= 2.3869114\n",
      "\n",
      "g_loss= -1.009397\n",
      "15/23 [==================>...........] - ETA: 1:02:33 - d_loss: 2.4422 - g_loss: nan\n",
      "\n",
      "\n",
      "d_loss= 2.4481657\n",
      "\n",
      "g_loss= -0.7623676\n",
      "16/23 [===================>..........] - ETA: 54:38 - d_loss: 2.4426 - g_loss: nan  \n",
      "\n",
      "\n",
      "d_loss= 2.3622303\n",
      "\n",
      "g_loss= -1.0533377\n",
      "17/23 [=====================>........] - ETA: 46:44 - d_loss: 2.4378 - g_loss: nan\n",
      "\n",
      "\n",
      "d_loss= 2.4020774\n",
      "\n",
      "g_loss= -0.9572836\n",
      "18/23 [======================>.......] - ETA: 38:56 - d_loss: 2.4359 - g_loss: nan\n",
      "\n",
      "\n",
      "d_loss= 2.425557\n",
      "\n",
      "g_loss= -0.9186955\n",
      "19/23 [=======================>......] - ETA: 31:06 - d_loss: 2.4353 - g_loss: nan\n",
      "\n",
      "\n",
      "d_loss= 2.3931181\n",
      "\n",
      "g_loss= -1.2056755\n",
      "20/23 [=========================>....] - ETA: 23:17 - d_loss: 2.4332 - g_loss: nan\n",
      "\n",
      "\n",
      "d_loss= 2.333298\n",
      "\n",
      "g_loss= -1.1965824\n",
      "21/23 [==========================>...] - ETA: 15:31 - d_loss: 2.4284 - g_loss: nan\n",
      "\n",
      "\n",
      "d_loss= 2.4133148\n",
      "\n",
      "g_loss= -1.2562454\n",
      "22/23 [===========================>..] - ETA: 7:44 - d_loss: 2.4278 - g_loss: nan \n",
      "\n",
      "\n",
      "d_loss= 2.3836462\n",
      "\n",
      "g_loss= -1.1343416\n",
      "23/23 [==============================] - 10659s 464s/step - d_loss: 2.4258 - g_loss: nan\n"
     ]
    }
   ],
   "source": [
    "# Deshabilitar los mensajes de información de TensorFlow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Deshabilitar los mensajes de información de OpenAI GymCuando nos sa\n",
    "gym.logger.set_level(40)\n",
    "\n",
    "history=gan5.fit(X_train,\n",
    "    epochs=EPOCHS,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4801 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4777 - accuracy: 0.0000e+00\n",
      ">Loss real: \n",
      "0.4801226854324341\n",
      ">Loss fake: \n",
      "0.47767895460128784\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos el Discriminador de GAIL en el TEST\n",
    "gan5.evaluate_D(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  0 Total reward: 500.0\n",
      "Episode  1 Total reward: 500.0\n",
      "Episode  2 Total reward: 500.0\n",
      "Episode  3 Total reward: 500.0\n",
      "Episode  4 Total reward: 500.0\n",
      "Episode  5 Total reward: 500.0\n",
      "Episode  6 Total reward: 500.0\n",
      "Episode  7 Total reward: 500.0\n",
      "Episode  8 Total reward: 500.0\n",
      "Episode  9 Total reward: 500.0\n",
      "Episode  10 Total reward: 500.0\n",
      "Episode  11 Total reward: 500.0\n",
      "Episode  12 Total reward: 500.0\n",
      "Episode  13 Total reward: 500.0\n",
      "Episode  14 Total reward: 500.0\n",
      "Episode  15 Total reward: 500.0\n",
      "Episode  16 Total reward: 500.0\n",
      "Episode  17 Total reward: 500.0\n",
      "Episode  18 Total reward: 500.0\n",
      "Episode  19 Total reward: 500.0\n",
      "Episode  20 Total reward: 500.0\n",
      "Episode  21 Total reward: 500.0\n",
      "Episode  22 Total reward: 500.0\n",
      "Episode  23 Total reward: 500.0\n",
      "Episode  24 Total reward: 500.0\n",
      "Episode  25 Total reward: 500.0\n",
      "Episode  26 Total reward: 500.0\n",
      "Episode  27 Total reward: 500.0\n",
      "Episode  28 Total reward: 500.0\n",
      "Episode  29 Total reward: 500.0\n",
      "Episode  30 Total reward: 500.0\n",
      "Episode  31 Total reward: 500.0\n",
      "Episode  32 Total reward: 500.0\n",
      "Episode  33 Total reward: 500.0\n",
      "Episode  34 Total reward: 500.0\n",
      "Episode  35 Total reward: 500.0\n",
      "Episode  36 Total reward: 500.0\n",
      "Episode  37 Total reward: 500.0\n",
      "Episode  38 Total reward: 500.0\n",
      "Episode  39 Total reward: 500.0\n",
      "Episode  40 Total reward: 500.0\n",
      "Episode  41 Total reward: 500.0\n",
      "Episode  42 Total reward: 500.0\n",
      "Episode  43 Total reward: 500.0\n",
      "Episode  44 Total reward: 500.0\n",
      "Episode  45 Total reward: 500.0\n",
      "Episode  46 Total reward: 500.0\n",
      "Episode  47 Total reward: 500.0\n",
      "Episode  48 Total reward: 500.0\n",
      "Episode  49 Total reward: 500.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recompensa de Media: 500.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos al Generador \n",
    "rewardMean=gan5.evaluate_G()\n",
    "print('\\nRecompensa de Media:', rewardMean, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción de base de datos experta con 6 trayectoria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_observations = np.genfromtxt(\"observations_CartPole_.csv\",delimiter=\"\\t\",dtype=str)\n",
    "expert_actions = np.genfromtxt('actions_CartPole_.csv', dtype=np.int32)\n",
    "expert_num_tray=np.genfromtxt('n_trayectoria_CartPole_.csv', dtype=np.int32)\n",
    "\n",
    "# Reemplazar las comas\n",
    "expert_observations = np.core.defchararray.replace(expert_observations, ',', ' ')\n",
    "\n",
    "# Crear un nuevo array para almacenar los datos convertidos\n",
    "converted_observations = np.genfromtxt(expert_observations, delimiter=' ', dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    }
   ],
   "source": [
    "longitud_trayectoria += np.count_nonzero(expert_num_tray == 5)\n",
    "print(longitud_trayectoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos quedamos solo con la primera trayectoria\n",
    "converted_observations=converted_observations[0:longitud_trayectoria]\n",
    "expert_actions=expert_actions[0:longitud_trayectoria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEstados reales: \n",
      " [[ 0.00572823 -0.03831238  0.03101629  0.00900886]\n",
      " [ 0.00496198  0.15635134  0.03119646 -0.27372897]\n",
      " [ 0.00808901 -0.03920152  0.02572188  0.02862788]\n",
      " ...\n",
      " [-0.02217253  0.17468227  0.00079885 -0.2510374 ]\n",
      " [-0.01867888 -0.02045107 -0.0042219   0.0418974 ]\n",
      " [-0.0190879   0.17473117 -0.00338395 -0.25211456]]\n",
      "\tAcciones reales: \n",
      " [1 0 1 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\tEstados reales: \\n\", converted_observations)\n",
    "print(\"\\tAcciones reales: \\n\", expert_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separación de Train y Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.7282310e-03 -3.8312376e-02  3.1016285e-02  9.0088570e-03\n",
      "   0.0000000e+00  1.0000000e+00]\n",
      " [ 4.9619833e-03  1.5635134e-01  3.1196462e-02 -2.7372897e-01\n",
      "   1.0000000e+00  0.0000000e+00]\n",
      " [ 8.0890100e-03 -3.9201517e-02  2.5721883e-02  2.8627882e-02\n",
      "   0.0000000e+00  1.0000000e+00]\n",
      " ...\n",
      " [-2.2172527e-02  1.7468227e-01  7.9885125e-04 -2.5103740e-01\n",
      "   1.0000000e+00  0.0000000e+00]\n",
      " [-1.8678881e-02 -2.0451074e-02 -4.2218966e-03  4.1897405e-02\n",
      "   0.0000000e+00  1.0000000e+00]\n",
      " [-1.9087903e-02  1.7473117e-01 -3.3839485e-03 -2.5211456e-01\n",
      "   1.0000000e+00  0.0000000e+00]]\n",
      "Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento: 2400\n",
      "Nº de (ESTADOS,ACCIONES) en el conjunto de prueba: 600\n"
     ]
    }
   ],
   "source": [
    "# Construimos el dataset [s,a] reales y lo dividimos en training y test\n",
    "expert_a_one_hot=np.eye(env.action_space.n)[expert_actions]\n",
    "\n",
    "dataset=np.concatenate([converted_observations,expert_a_one_hot],axis=1)\n",
    "\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test = train_test_split(dataset, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "#Imprime el número de elementos en el conjuntos de entrenamiento y prueba\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento:', len(X_train))\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de prueba:', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "env= gym.make('CartPole-v1')\n",
    "obs,_= env.reset()\n",
    "\n",
    "# Generador\n",
    "generator=Policy_net( 'policy', env, obs)\n",
    "\n",
    "# Generamos [s,a] falsas y las políticas theta_i y theta_i+1\n",
    "observations, actions, rewards, Old_Policy, Policy=generator.generate_fakes()\n",
    "\n",
    "# Discriminador\n",
    "discriminator=Discriminator(env, discriminator_net, converted_observations, expert_actions, observations, actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan6=GAN(discriminator=discriminator,generator=generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "gan6.compile(\n",
    "    d_optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss_fn_D=loss_fn_D\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "d_loss= 2.3685048\n",
      "\n",
      "g_loss= -1.2273296\n",
      " 1/27 [>.............................] - ETA: 3:15:06 - d_loss: 2.3685 - g_loss: -1.2273\n",
      "\n",
      "\n",
      "d_loss= 2.3596258\n",
      "\n",
      "g_loss= -1.1086441\n",
      " 2/27 [=>............................] - ETA: 3:09:04 - d_loss: 2.3641 - g_loss: -1.1680\n",
      "\n",
      "\n",
      "d_loss= 2.365448\n",
      "\n",
      "g_loss= -1.011794\n",
      " 3/27 [==>...........................] - ETA: 3:01:24 - d_loss: 2.3645 - g_loss: -1.1159\n",
      "\n",
      "\n",
      "d_loss= 2.3252032\n",
      "\n",
      "g_loss= -0.99648356\n",
      " 4/27 [===>..........................] - ETA: 2:53:02 - d_loss: 2.3547 - g_loss: -1.0861\n",
      "\n",
      "\n",
      "d_loss= 2.3885553\n",
      "\n",
      "g_loss= -0.98502266\n",
      " 5/27 [====>.........................] - ETA: 2:45:22 - d_loss: 2.3615 - g_loss: -1.0659\n",
      "\n",
      "\n",
      "d_loss= 2.3900044\n",
      "\n",
      "g_loss= -1.1982098\n",
      " 6/27 [=====>........................] - ETA: 2:38:20 - d_loss: 2.3662 - g_loss: -1.0879\n",
      "\n",
      "\n",
      "d_loss= 2.3384948\n",
      "\n",
      "g_loss= -1.2535645\n",
      " 7/27 [======>.......................] - ETA: 2:30:39 - d_loss: 2.3623 - g_loss: -1.1116\n",
      "\n",
      "\n",
      "d_loss= 2.330599\n",
      "\n",
      "g_loss= -0.7471645\n",
      " 8/27 [=======>......................] - ETA: 2:22:38 - d_loss: 2.3583 - g_loss: -1.0660\n",
      "\n",
      "\n",
      "d_loss= 2.2940662\n",
      "\n",
      "g_loss= -0.9556335\n",
      " 9/27 [=========>....................] - ETA: 2:15:18 - d_loss: 2.3512 - g_loss: -1.0538\n",
      "\n",
      "\n",
      "d_loss= 2.3022685\n",
      "\n",
      "g_loss= -1.0756762\n",
      "10/27 [==========>...................] - ETA: 2:07:54 - d_loss: 2.3463 - g_loss: -1.0560\n",
      "\n",
      "\n",
      "d_loss= 2.3247347\n",
      "\n",
      "g_loss= -1.1670966\n",
      "11/27 [===========>..................] - ETA: 2:00:12 - d_loss: 2.3443 - g_loss: -1.0661\n",
      "\n",
      "\n",
      "d_loss= 2.3726015\n",
      "\n",
      "g_loss= -1.1080246\n",
      "12/27 [============>.................] - ETA: 1:52:23 - d_loss: 2.3467 - g_loss: -1.0696\n",
      "\n",
      "\n",
      "d_loss= 2.3288023\n",
      "\n",
      "g_loss= -1.1986549\n",
      "13/27 [=============>................] - ETA: 1:44:42 - d_loss: 2.3453 - g_loss: -1.0795\n",
      "\n",
      "\n",
      "d_loss= 2.3387156\n",
      "\n",
      "g_loss= -1.0271791\n",
      "14/27 [==============>...............] - ETA: 1:37:10 - d_loss: 2.3448 - g_loss: -1.0757\n",
      "\n",
      "\n",
      "d_loss= 2.3305726\n",
      "\n",
      "g_loss= -1.2190232\n",
      "15/27 [===============>..............] - ETA: 1:29:42 - d_loss: 2.3439 - g_loss: -1.0853\n",
      "\n",
      "\n",
      "d_loss= 2.3209317\n",
      "\n",
      "g_loss= -1.2526836\n",
      "16/27 [================>.............] - ETA: 1:22:12 - d_loss: 2.3424 - g_loss: -1.0958\n",
      "\n",
      "\n",
      "d_loss= 2.343663\n",
      "\n",
      "g_loss= -0.9420943\n",
      "17/27 [=================>............] - ETA: 1:14:53 - d_loss: 2.3425 - g_loss: -1.0867\n",
      "\n",
      "\n",
      "d_loss= 2.3173318\n",
      "\n",
      "g_loss= -1.00801\n",
      "18/27 [===================>..........] - ETA: 1:07:20 - d_loss: 2.3411 - g_loss: -1.0823\n",
      "\n",
      "\n",
      "d_loss= 2.276526\n",
      "\n",
      "g_loss= -1.0129673\n",
      "19/27 [====================>.........] - ETA: 59:43 - d_loss: 2.3377 - g_loss: -1.0787  \n",
      "\n",
      "\n",
      "d_loss= 2.3297677\n",
      "\n",
      "g_loss= -0.6284544\n",
      "20/27 [=====================>........] - ETA: 52:11 - d_loss: 2.3373 - g_loss: -1.0562\n",
      "\n",
      "\n",
      "d_loss= 2.3133218\n",
      "\n",
      "g_loss= -1.085191\n",
      "21/27 [======================>.......] - ETA: 44:44 - d_loss: 2.3362 - g_loss: -1.0576\n",
      "\n",
      "\n",
      "d_loss= 2.2993586\n",
      "\n",
      "g_loss= -1.1962471\n",
      "22/27 [=======================>......] - ETA: 37:15 - d_loss: 2.3345 - g_loss: -1.0639\n",
      "\n",
      "\n",
      "d_loss= 2.2850163\n",
      "\n",
      "g_loss= -1.1889324\n",
      "23/27 [========================>.....] - ETA: 29:45 - d_loss: 2.3324 - g_loss: -1.0693\n",
      "\n",
      "\n",
      "d_loss= 2.250573\n",
      "\n",
      "g_loss= -1.238322\n",
      "24/27 [=========================>....] - ETA: 22:18 - d_loss: 2.3289 - g_loss: -1.0764\n",
      "\n",
      "\n",
      "d_loss= 2.2631273\n",
      "\n",
      "g_loss= -1.0554844\n",
      "25/27 [==========================>...] - ETA: 14:51 - d_loss: 2.3263 - g_loss: -1.0755\n",
      "\n",
      "\n",
      "d_loss= 2.2287052\n",
      "\n",
      "g_loss= -1.130722\n",
      "26/27 [===========================>..] - ETA: 7:25 - d_loss: 2.3226 - g_loss: -1.0776 \n",
      "\n",
      "\n",
      "d_loss= 2.319713\n",
      "\n",
      "g_loss= -0.8177655\n",
      "27/27 [==============================] - 12021s 445s/step - d_loss: 2.3225 - g_loss: -1.0680\n"
     ]
    }
   ],
   "source": [
    "# Deshabilitar los mensajes de información de TensorFlow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Deshabilitar los mensajes de información de OpenAI Gym\n",
    "gym.logger.set_level(40)\n",
    "\n",
    "history=gan6.fit(X_train,\n",
    "    epochs=EPOCHS,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3608 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3601 - accuracy: 0.0000e+00\n",
      ">Loss real: \n",
      "0.3607860803604126\n",
      ">Loss fake: \n",
      "0.36013343930244446\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos el Discriminador de GAIL en el TEST\n",
    "gan6.evaluate_D(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  0 Total reward: 500.0\n",
      "Episode  1 Total reward: 500.0\n",
      "Episode  2 Total reward: 500.0\n",
      "Episode  3 Total reward: 500.0\n",
      "Episode  4 Total reward: 500.0\n",
      "Episode  5 Total reward: 500.0\n",
      "Episode  6 Total reward: 500.0\n",
      "Episode  7 Total reward: 500.0\n",
      "Episode  8 Total reward: 500.0\n",
      "Episode  9 Total reward: 500.0\n",
      "Episode  10 Total reward: 500.0\n",
      "Episode  11 Total reward: 500.0\n",
      "Episode  12 Total reward: 500.0\n",
      "Episode  13 Total reward: 500.0\n",
      "Episode  14 Total reward: 500.0\n",
      "Episode  15 Total reward: 500.0\n",
      "Episode  16 Total reward: 500.0\n",
      "Episode  17 Total reward: 500.0\n",
      "Episode  18 Total reward: 500.0\n",
      "Episode  19 Total reward: 500.0\n",
      "Episode  20 Total reward: 500.0\n",
      "Episode  21 Total reward: 500.0\n",
      "Episode  22 Total reward: 500.0\n",
      "Episode  23 Total reward: 500.0\n",
      "Episode  24 Total reward: 500.0\n",
      "Episode  25 Total reward: 500.0\n",
      "Episode  26 Total reward: 500.0\n",
      "Episode  27 Total reward: 500.0\n",
      "Episode  28 Total reward: 500.0\n",
      "Episode  29 Total reward: 500.0\n",
      "Episode  30 Total reward: 500.0\n",
      "Episode  31 Total reward: 500.0\n",
      "Episode  32 Total reward: 500.0\n",
      "Episode  33 Total reward: 500.0\n",
      "Episode  34 Total reward: 500.0\n",
      "Episode  35 Total reward: 500.0\n",
      "Episode  36 Total reward: 500.0\n",
      "Episode  37 Total reward: 500.0\n",
      "Episode  38 Total reward: 500.0\n",
      "Episode  39 Total reward: 500.0\n",
      "Episode  40 Total reward: 500.0\n",
      "Episode  41 Total reward: 500.0\n",
      "Episode  42 Total reward: 500.0\n",
      "Episode  43 Total reward: 500.0\n",
      "Episode  44 Total reward: 500.0\n",
      "Episode  45 Total reward: 500.0\n",
      "Episode  46 Total reward: 500.0\n",
      "Episode  47 Total reward: 500.0\n",
      "Episode  48 Total reward: 500.0\n",
      "Episode  49 Total reward: 500.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recompensa de Media: 500.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos al Generador \n",
    "rewardMean=gan6.evaluate_G()\n",
    "print('\\nRecompensa de Media:', rewardMean, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción de base de datos experta con 7 trayectoria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_observations = np.genfromtxt(\"observations_CartPole_.csv\",delimiter=\"\\t\",dtype=str)\n",
    "expert_actions = np.genfromtxt('actions_CartPole_.csv', dtype=np.int32)\n",
    "expert_num_tray=np.genfromtxt('n_trayectoria_CartPole_.csv', dtype=np.int32)\n",
    "\n",
    "# Reemplazar las comas\n",
    "expert_observations = np.core.defchararray.replace(expert_observations, ',', ' ')\n",
    "\n",
    "# Crear un nuevo array para almacenar los datos convertidos\n",
    "converted_observations = np.genfromtxt(expert_observations, delimiter=' ', dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500\n"
     ]
    }
   ],
   "source": [
    "longitud_trayectoria += np.count_nonzero(expert_num_tray == 6)\n",
    "print(longitud_trayectoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos quedamos solo con la primera trayectoria\n",
    "converted_observations=converted_observations[0:longitud_trayectoria]\n",
    "expert_actions=expert_actions[0:longitud_trayectoria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEstados reales: \n",
      " [[ 5.7282310e-03 -3.8312376e-02  3.1016285e-02  9.0088570e-03]\n",
      " [ 4.9619833e-03  1.5635134e-01  3.1196462e-02 -2.7372897e-01]\n",
      " [ 8.0890100e-03 -3.9201517e-02  2.5721883e-02  2.8627882e-02]\n",
      " ...\n",
      " [-3.4051698e-02 -1.4851935e-01 -4.6977460e-03  2.5984666e-01]\n",
      " [-3.7022088e-02  4.6669340e-02  4.9918704e-04 -3.4314286e-02]\n",
      " [-3.6088698e-02 -1.4845976e-01 -1.8709873e-04  2.5852610e-01]]\n",
      "\tAcciones reales: \n",
      " [1 0 1 ... 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\tEstados reales: \\n\", converted_observations)\n",
    "print(\"\\tAcciones reales: \\n\", expert_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separación de Train y Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.7282310e-03 -3.8312376e-02  3.1016285e-02  9.0088570e-03\n",
      "   0.0000000e+00  1.0000000e+00]\n",
      " [ 4.9619833e-03  1.5635134e-01  3.1196462e-02 -2.7372897e-01\n",
      "   1.0000000e+00  0.0000000e+00]\n",
      " [ 8.0890100e-03 -3.9201517e-02  2.5721883e-02  2.8627882e-02\n",
      "   0.0000000e+00  1.0000000e+00]\n",
      " ...\n",
      " [-3.4051698e-02 -1.4851935e-01 -4.6977460e-03  2.5984666e-01\n",
      "   0.0000000e+00  1.0000000e+00]\n",
      " [-3.7022088e-02  4.6669340e-02  4.9918704e-04 -3.4314286e-02\n",
      "   1.0000000e+00  0.0000000e+00]\n",
      " [-3.6088698e-02 -1.4845976e-01 -1.8709873e-04  2.5852610e-01\n",
      "   0.0000000e+00  1.0000000e+00]]\n",
      "Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento: 2800\n",
      "Nº de (ESTADOS,ACCIONES) en el conjunto de prueba: 700\n"
     ]
    }
   ],
   "source": [
    "# Construimos el dataset [s,a] reales y lo dividimos en training y test\n",
    "expert_a_one_hot=np.eye(env.action_space.n)[expert_actions]\n",
    "\n",
    "dataset=np.concatenate([converted_observations,expert_a_one_hot],axis=1)\n",
    "\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test = train_test_split(dataset, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "#Imprime el número de elementos en el conjuntos de entrenamiento y prueba\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento:', len(X_train))\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de prueba:', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "env= gym.make('CartPole-v1')\n",
    "obs,_= env.reset()\n",
    "\n",
    "# Generador\n",
    "generator=Policy_net( 'policy', env, obs)\n",
    "\n",
    "# Generamos [s,a] falsas y las políticas theta_i y theta_i+1\n",
    "observations, actions, rewards, Old_Policy, Policy=generator.generate_fakes()\n",
    "\n",
    "# Discriminador\n",
    "discriminator=Discriminator(env, discriminator_net, converted_observations, expert_actions, observations, actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan7=GAN(discriminator=discriminator,generator=generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "gan7.compile(\n",
    "    d_optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss_fn_D=loss_fn_D\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "d_loss= 2.2261398\n",
      "\n",
      "g_loss= -1.1993479\n",
      " 1/32 [..............................] - ETA: 3:43:10 - d_loss: 2.2261 - g_loss: -1.1993\n",
      "\n",
      "\n",
      "d_loss= 2.2570183\n",
      "\n",
      "g_loss= -0.9213828\n",
      " 2/32 [>.............................] - ETA: 3:36:48 - d_loss: 2.2416 - g_loss: -1.0604\n",
      "\n",
      "\n",
      "d_loss= 2.2680671\n",
      "\n",
      "g_loss= -1.2020552\n",
      " 3/32 [=>............................] - ETA: 3:30:32 - d_loss: 2.2504 - g_loss: -1.1076\n",
      "\n",
      "\n",
      "d_loss= 2.2346883\n",
      "\n",
      "g_loss= -1.1714077\n",
      " 4/32 [==>...........................] - ETA: 3:24:06 - d_loss: 2.2465 - g_loss: -1.1235\n",
      "\n",
      "\n",
      "d_loss= 2.2227268\n",
      "\n",
      "g_loss= -0.85562015\n",
      " 5/32 [===>..........................] - ETA: 3:18:06 - d_loss: 2.2417 - g_loss: -1.0700\n",
      "\n",
      "\n",
      "d_loss= 2.2489023\n",
      "\n",
      "g_loss= -1.0120468\n",
      " 6/32 [====>.........................] - ETA: 3:11:29 - d_loss: 2.2429 - g_loss: -1.0603\n",
      "\n",
      "\n",
      "d_loss= 2.2634614\n",
      "\n",
      "g_loss= -1.0018247\n",
      " 7/32 [=====>........................] - ETA: 3:03:46 - d_loss: 2.2459 - g_loss: -1.0520\n",
      "\n",
      "\n",
      "d_loss= 2.1967328\n",
      "\n",
      "g_loss= -1.0160702\n",
      " 8/32 [======>.......................] - ETA: 2:55:57 - d_loss: 2.2397 - g_loss: -1.0475\n",
      "\n",
      "\n",
      "d_loss= 2.2519035\n",
      "\n",
      "g_loss= -0.83251107\n",
      " 9/32 [=======>......................] - ETA: 2:48:06 - d_loss: 2.2411 - g_loss: -1.0236\n",
      "\n",
      "\n",
      "d_loss= 2.2031722\n",
      "\n",
      "g_loss= -1.1074169\n",
      "10/32 [========>.....................] - ETA: 2:41:41 - d_loss: 2.2373 - g_loss: -1.0320\n",
      "\n",
      "\n",
      "d_loss= 2.2537956\n",
      "\n",
      "g_loss= -0.95224845\n",
      "11/32 [=========>....................] - ETA: 2:34:39 - d_loss: 2.2388 - g_loss: -1.0247\n",
      "\n",
      "\n",
      "d_loss= 2.201097\n",
      "\n",
      "g_loss= -1.1064128\n",
      "12/32 [==========>...................] - ETA: 2:27:23 - d_loss: 2.2356 - g_loss: -1.0315\n",
      "\n",
      "\n",
      "d_loss= 2.1804845\n",
      "\n",
      "g_loss= -0.62886643\n",
      "13/32 [===========>..................] - ETA: 2:20:21 - d_loss: 2.2314 - g_loss: -1.0006\n",
      "\n",
      "\n",
      "d_loss= 2.2080965\n",
      "\n",
      "g_loss= -1.3143661\n",
      "14/32 [============>.................] - ETA: 2:13:18 - d_loss: 2.2297 - g_loss: -1.0230\n",
      "\n",
      "\n",
      "d_loss= 2.1671603\n",
      "\n",
      "g_loss= -0.95043725\n",
      "15/32 [=============>................] - ETA: 2:06:04 - d_loss: 2.2256 - g_loss: -1.0181\n",
      "\n",
      "\n",
      "d_loss= 2.2418728\n",
      "\n",
      "g_loss= -1.0344899\n",
      "16/32 [==============>...............] - ETA: 1:58:54 - d_loss: 2.2266 - g_loss: -1.0192\n",
      "\n",
      "\n",
      "d_loss= 2.1899962\n",
      "\n",
      "g_loss= -1.1961744\n",
      "17/32 [==============>...............] - ETA: 1:51:46 - d_loss: 2.2244 - g_loss: -1.0296\n",
      "\n",
      "\n",
      "d_loss= 2.159946\n",
      "\n",
      "g_loss= -1.2529945\n",
      "18/32 [===============>..............] - ETA: 1:44:18 - d_loss: 2.2208 - g_loss: -1.0420\n",
      "\n",
      "\n",
      "d_loss= 2.160964\n",
      "\n",
      "g_loss= -1.141427\n",
      "19/32 [================>.............] - ETA: 1:36:46 - d_loss: 2.2177 - g_loss: -1.0472\n",
      "\n",
      "\n",
      "d_loss= 2.1857595\n",
      "\n",
      "g_loss= -1.0508208\n",
      "20/32 [=================>............] - ETA: 1:29:17 - d_loss: 2.2161 - g_loss: -1.0474\n",
      "\n",
      "\n",
      "d_loss= 2.2039757\n",
      "\n",
      "g_loss= -1.2188973\n",
      "21/32 [==================>...........] - ETA: 1:21:53 - d_loss: 2.2155 - g_loss: -1.0556\n",
      "\n",
      "\n",
      "d_loss= 2.2189107\n",
      "\n",
      "g_loss= -0.77969563\n",
      "22/32 [===================>..........] - ETA: 1:14:27 - d_loss: 2.2157 - g_loss: -1.0430\n",
      "\n",
      "\n",
      "d_loss= 2.1612258\n",
      "\n",
      "g_loss= -1.1749055\n",
      "23/32 [====================>.........] - ETA: 1:07:06 - d_loss: 2.2133 - g_loss: -1.0488\n",
      "\n",
      "\n",
      "d_loss= 2.148812\n",
      "\n",
      "g_loss= -0.8040933\n",
      "24/32 [=====================>........] - ETA: 59:40 - d_loss: 2.2106 - g_loss: -1.0386  \n",
      "\n",
      "\n",
      "d_loss= 2.194949\n",
      "\n",
      "g_loss= -0.8537756\n",
      "25/32 [======================>.......] - ETA: 52:11 - d_loss: 2.2100 - g_loss: -1.0312\n",
      "\n",
      "\n",
      "d_loss= 2.1521964\n",
      "\n",
      "g_loss= -1.1077656\n",
      "26/32 [=======================>......] - ETA: 44:44 - d_loss: 2.2078 - g_loss: -1.0341\n",
      "\n",
      "\n",
      "d_loss= 2.1126127\n",
      "\n",
      "g_loss= -1.0219948\n",
      "27/32 [========================>.....] - ETA: 37:16 - d_loss: 2.2042 - g_loss: -1.0337\n",
      "\n",
      "\n",
      "d_loss= 2.1149876\n",
      "\n",
      "g_loss= -0.7907962\n",
      "28/32 [=========================>....] - ETA: 29:51 - d_loss: 2.2011 - g_loss: -1.0250\n",
      "\n",
      "\n",
      "d_loss= 2.1140807\n",
      "\n",
      "g_loss= -1.1407329\n",
      "29/32 [==========================>...] - ETA: 22:23 - d_loss: 2.1981 - g_loss: -1.0290\n",
      "\n",
      "\n",
      "d_loss= 2.1206312\n",
      "\n",
      "g_loss= -0.7923177\n",
      "30/32 [===========================>..] - ETA: 14:57 - d_loss: 2.1955 - g_loss: -1.0211\n",
      "\n",
      "\n",
      "d_loss= 2.149238\n",
      "\n",
      "g_loss= -1.2723032\n",
      "31/32 [============================>.] - ETA: 7:28 - d_loss: 2.1940 - g_loss: -1.0292 \n",
      "\n",
      "\n",
      "d_loss= 2.1567204\n",
      "\n",
      "g_loss= -0.835474\n",
      "32/32 [==============================] - 14360s 449s/step - d_loss: 2.1928 - g_loss: -1.0231\n"
     ]
    }
   ],
   "source": [
    "# Deshabilitar los mensajes de información de TensorFlow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Deshabilitar los mensajes de información de OpenAI Gym\n",
    "gym.logger.set_level(40)\n",
    "\n",
    "history=gan7.fit(X_train,\n",
    "    epochs=EPOCHS,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2073 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2108 - accuracy: 0.0000e+00\n",
      ">Loss real: \n",
      "0.20734503865242004\n",
      ">Loss fake: \n",
      "0.2107636034488678\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos el Discriminador de GAIL en el TEST\n",
    "gan7.evaluate_D(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  0 Total reward: 500.0\n",
      "Episode  1 Total reward: 500.0\n",
      "Episode  2 Total reward: 500.0\n",
      "Episode  3 Total reward: 500.0\n",
      "Episode  4 Total reward: 500.0\n",
      "Episode  5 Total reward: 500.0\n",
      "Episode  6 Total reward: 500.0\n",
      "Episode  7 Total reward: 500.0\n",
      "Episode  8 Total reward: 500.0\n",
      "Episode  9 Total reward: 500.0\n",
      "Episode  10 Total reward: 500.0\n",
      "Episode  11 Total reward: 500.0\n",
      "Episode  12 Total reward: 500.0\n",
      "Episode  13 Total reward: 500.0\n",
      "Episode  14 Total reward: 500.0\n",
      "Episode  15 Total reward: 500.0\n",
      "Episode  16 Total reward: 500.0\n",
      "Episode  17 Total reward: 500.0\n",
      "Episode  18 Total reward: 500.0\n",
      "Episode  19 Total reward: 500.0\n",
      "Episode  20 Total reward: 500.0\n",
      "Episode  21 Total reward: 500.0\n",
      "Episode  22 Total reward: 500.0\n",
      "Episode  23 Total reward: 500.0\n",
      "Episode  24 Total reward: 500.0\n",
      "Episode  25 Total reward: 500.0\n",
      "Episode  26 Total reward: 500.0\n",
      "Episode  27 Total reward: 500.0\n",
      "Episode  28 Total reward: 500.0\n",
      "Episode  29 Total reward: 500.0\n",
      "Episode  30 Total reward: 500.0\n",
      "Episode  31 Total reward: 500.0\n",
      "Episode  32 Total reward: 500.0\n",
      "Episode  33 Total reward: 500.0\n",
      "Episode  34 Total reward: 500.0\n",
      "Episode  35 Total reward: 500.0\n",
      "Episode  36 Total reward: 500.0\n",
      "Episode  37 Total reward: 500.0\n",
      "Episode  38 Total reward: 500.0\n",
      "Episode  39 Total reward: 500.0\n",
      "Episode  40 Total reward: 500.0\n",
      "Episode  41 Total reward: 151.0\n",
      "Episode  42 Total reward: 500.0\n",
      "Episode  43 Total reward: 500.0\n",
      "Episode  44 Total reward: 500.0\n",
      "Episode  45 Total reward: 500.0\n",
      "Episode  46 Total reward: 500.0\n",
      "Episode  47 Total reward: 500.0\n",
      "Episode  48 Total reward: 500.0\n",
      "Episode  49 Total reward: 500.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recompensa de Media: 493.02 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos al Generador \n",
    "rewardMean=gan7.evaluate_G()\n",
    "print('\\nRecompensa de Media:', rewardMean, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción de base de datos experta con 8 trayectoria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_observations = np.genfromtxt(\"observations_CartPole_.csv\",delimiter=\"\\t\",dtype=str)\n",
    "expert_actions = np.genfromtxt('actions_CartPole_.csv', dtype=np.int32)\n",
    "expert_num_tray=np.genfromtxt('n_trayectoria_CartPole_.csv', dtype=np.int32)\n",
    "\n",
    "# Reemplazar las comas\n",
    "expert_observations = np.core.defchararray.replace(expert_observations, ',', ' ')\n",
    "\n",
    "# Crear un nuevo array para almacenar los datos convertidos\n",
    "converted_observations = np.genfromtxt(expert_observations, delimiter=' ', dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    }
   ],
   "source": [
    "longitud_trayectoria += np.count_nonzero(expert_num_tray == 7)\n",
    "print(longitud_trayectoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos quedamos solo con la primera trayectoria\n",
    "converted_observations=converted_observations[0:longitud_trayectoria]\n",
    "expert_actions=expert_actions[0:longitud_trayectoria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEstados reales: \n",
      " [[ 0.00572823 -0.03831238  0.03101629  0.00900886]\n",
      " [ 0.00496198  0.15635134  0.03119646 -0.27372897]\n",
      " [ 0.00808901 -0.03920152  0.02572188  0.02862788]\n",
      " ...\n",
      " [-0.0186169   0.1786086  -0.00126522 -0.25009453]\n",
      " [-0.01504473 -0.01649527 -0.00626712  0.04218904]\n",
      " [-0.01537464 -0.2115268  -0.00542333  0.33288807]]\n",
      "\tAcciones reales: \n",
      " [1 0 1 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\tEstados reales: \\n\", converted_observations)\n",
    "print(\"\\tAcciones reales: \\n\", expert_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separación de Train y Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00572823 -0.03831238  0.03101629  0.00900886  0.          1.        ]\n",
      " [ 0.00496198  0.15635134  0.03119646 -0.27372897  1.          0.        ]\n",
      " [ 0.00808901 -0.03920152  0.02572188  0.02862788  0.          1.        ]\n",
      " ...\n",
      " [-0.0186169   0.1786086  -0.00126522 -0.25009453  1.          0.        ]\n",
      " [-0.01504473 -0.01649527 -0.00626712  0.04218904  1.          0.        ]\n",
      " [-0.01537464 -0.2115268  -0.00542333  0.33288807  0.          1.        ]]\n",
      "Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento: 3200\n",
      "Nº de (ESTADOS,ACCIONES) en el conjunto de prueba: 800\n"
     ]
    }
   ],
   "source": [
    "# Construimos el dataset [s,a] reales y lo dividimos en training y test\n",
    "expert_a_one_hot=np.eye(env.action_space.n)[expert_actions]\n",
    "\n",
    "dataset=np.concatenate([converted_observations,expert_a_one_hot],axis=1)\n",
    "\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test = train_test_split(dataset, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "#Imprime el número de elementos en el conjuntos de entrenamiento y prueba\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento:', len(X_train))\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de prueba:', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "env= gym.make('CartPole-v1')\n",
    "obs,_= env.reset()\n",
    "\n",
    "# Generador\n",
    "generator=Policy_net( 'policy', env, obs)\n",
    "\n",
    "# Generamos [s,a] falsas y las políticas theta_i y theta_i+1\n",
    "observations, actions, rewards, Old_Policy, Policy=generator.generate_fakes()\n",
    "\n",
    "# Discriminador\n",
    "discriminator=Discriminator(env, discriminator_net, converted_observations, expert_actions, observations, actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan8=GAN(discriminator=discriminator,generator=generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "gan8.compile(\n",
    "    d_optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss_fn_D=loss_fn_D\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "d_loss= 2.1068065\n",
      "\n",
      "g_loss= -0.9082667\n",
      " 1/36 [..............................] - ETA: 4:33:32 - d_loss: 2.1068 - g_loss: -0.9083\n",
      "\n",
      "\n",
      "d_loss= 2.0903964\n",
      "\n",
      "g_loss= -0.9949434\n",
      " 2/36 [>.............................] - ETA: 4:47:25 - d_loss: 2.0986 - g_loss: -0.9516\n",
      "\n",
      "\n",
      "d_loss= 2.1101513\n",
      "\n",
      "g_loss= -0.9427878\n",
      " 3/36 [=>............................] - ETA: 4:28:49 - d_loss: 2.1025 - g_loss: -0.9487\n",
      "\n",
      "\n",
      "d_loss= 2.1009626\n",
      "\n",
      "g_loss= -1.2811124\n",
      " 4/36 [==>...........................] - ETA: 4:16:22 - d_loss: 2.1021 - g_loss: -1.0318\n",
      "\n",
      "\n",
      "d_loss= 2.0617013\n",
      "\n",
      "g_loss= -1.1984996\n",
      " 5/36 [===>..........................] - ETA: 4:06:54 - d_loss: 2.0940 - g_loss: -1.0651\n",
      "\n",
      "\n",
      "d_loss= 2.100798\n",
      "\n",
      "g_loss= -1.0087556\n",
      " 6/36 [====>.........................] - ETA: 4:01:31 - d_loss: 2.0951 - g_loss: -1.0557\n",
      "\n",
      "\n",
      "d_loss= 2.0466273\n",
      "\n",
      "g_loss= -0.9472334\n",
      " 7/36 [====>.........................] - ETA: 3:55:14 - d_loss: 2.0882 - g_loss: -1.0402\n",
      "\n",
      "\n",
      "d_loss= 2.0832665\n",
      "\n",
      "g_loss= -0.89147377\n",
      " 8/36 [=====>........................] - ETA: 3:49:49 - d_loss: 2.0876 - g_loss: -1.0216\n",
      "\n",
      "\n",
      "d_loss= 2.071287\n",
      "\n",
      "g_loss= -1.2328168\n",
      " 9/36 [======>.......................] - ETA: 3:41:23 - d_loss: 2.0858 - g_loss: -1.0451\n",
      "\n",
      "\n",
      "d_loss= 2.1038437\n",
      "\n",
      "g_loss= -1.0737743\n",
      "10/36 [=======>......................] - ETA: 3:32:58 - d_loss: 2.0876 - g_loss: -1.0480\n",
      "\n",
      "\n",
      "d_loss= 2.0687878\n",
      "\n",
      "g_loss= -1.2763433\n",
      "11/36 [========>.....................] - ETA: 3:23:15 - d_loss: 2.0859 - g_loss: -1.0687\n",
      "\n",
      "\n",
      "d_loss= 2.0842557\n",
      "\n",
      "g_loss= -1.0337306\n",
      "12/36 [=========>....................] - ETA: 3:13:29 - d_loss: 2.0857 - g_loss: -1.0658\n",
      "\n",
      "\n",
      "d_loss= 2.092024\n",
      "\n",
      "g_loss= -0.9305038\n",
      "13/36 [=========>....................] - ETA: 3:04:13 - d_loss: 2.0862 - g_loss: -1.0554\n",
      "\n",
      "\n",
      "d_loss= 2.0756044\n",
      "\n",
      "g_loss= -0.7664256\n",
      "14/36 [==========>...................] - ETA: 2:55:14 - d_loss: 2.0855 - g_loss: -1.0348\n",
      "\n",
      "\n",
      "d_loss= 2.044819\n",
      "\n",
      "g_loss= -1.1847515\n",
      "15/36 [===========>..................] - ETA: 2:46:37 - d_loss: 2.0828 - g_loss: -1.0448\n",
      "\n",
      "\n",
      "d_loss= 2.0723333\n",
      "\n",
      "g_loss= -1.1029757\n",
      "16/36 [============>.................] - ETA: 2:38:01 - d_loss: 2.0821 - g_loss: -1.0484\n",
      "\n",
      "\n",
      "d_loss= 2.0777125\n",
      "\n",
      "g_loss= -1.1098737\n",
      "17/36 [=============>................] - ETA: 2:29:25 - d_loss: 2.0818 - g_loss: -1.0520\n",
      "\n",
      "\n",
      "d_loss= 2.0175443\n",
      "\n",
      "g_loss= -0.81788063\n",
      "18/36 [==============>...............] - ETA: 2:21:00 - d_loss: 2.0783 - g_loss: -1.0390\n",
      "\n",
      "\n",
      "d_loss= 1.9894363\n",
      "\n",
      "g_loss= -1.2489301\n",
      "19/36 [==============>...............] - ETA: 2:12:54 - d_loss: 2.0736 - g_loss: -1.0501\n",
      "\n",
      "\n",
      "d_loss= 2.0652347\n",
      "\n",
      "g_loss= -0.9840857\n",
      "20/36 [===============>..............] - ETA: 2:05:21 - d_loss: 2.0732 - g_loss: -1.0468\n",
      "\n",
      "\n",
      "d_loss= 2.0543394\n",
      "\n",
      "g_loss= -1.2086446\n",
      "21/36 [================>.............] - ETA: 1:57:26 - d_loss: 2.0723 - g_loss: -1.0545\n",
      "\n",
      "\n",
      "d_loss= 2.005878\n",
      "\n",
      "g_loss= -1.0993668\n",
      "22/36 [=================>............] - ETA: 1:49:23 - d_loss: 2.0693 - g_loss: -1.0565\n",
      "\n",
      "\n",
      "d_loss= 2.033239\n",
      "\n",
      "g_loss= -0.86102575\n",
      "23/36 [==================>...........] - ETA: 1:41:26 - d_loss: 2.0677 - g_loss: -1.0480\n",
      "\n",
      "\n",
      "d_loss= 2.0297804\n",
      "\n",
      "g_loss= -1.0936568\n",
      "24/36 [===================>..........] - ETA: 1:33:35 - d_loss: 2.0661 - g_loss: -1.0499\n",
      "\n",
      "\n",
      "d_loss= 2.024043\n",
      "\n",
      "g_loss= -1.0449886\n",
      "25/36 [===================>..........] - ETA: 1:25:38 - d_loss: 2.0644 - g_loss: -1.0497\n",
      "\n",
      "\n",
      "d_loss= 2.0293574\n",
      "\n",
      "g_loss= -0.9764022\n",
      "26/36 [====================>.........] - ETA: 1:17:54 - d_loss: 2.0631 - g_loss: -1.0469\n",
      "\n",
      "\n",
      "d_loss= 2.0203464\n",
      "\n",
      "g_loss= -0.84566444\n",
      "27/36 [=====================>........] - ETA: 1:10:09 - d_loss: 2.0615 - g_loss: -1.0394\n",
      "\n",
      "\n",
      "d_loss= 2.059228\n",
      "\n",
      "g_loss= -0.8700175\n",
      "28/36 [======================>.......] - ETA: 1:02:23 - d_loss: 2.0614 - g_loss: -1.0334\n",
      "\n",
      "\n",
      "d_loss= 2.0044577\n",
      "\n",
      "g_loss= -0.8540357\n",
      "29/36 [=======================>......] - ETA: 54:31 - d_loss: 2.0595 - g_loss: -1.0272  \n",
      "\n",
      "\n",
      "d_loss= 2.0233653\n",
      "\n",
      "g_loss= -0.8064134\n",
      "30/36 [========================>.....] - ETA: 46:40 - d_loss: 2.0583 - g_loss: -1.0198\n",
      "\n",
      "\n",
      "d_loss= 2.0470793\n",
      "\n",
      "g_loss= -1.1048583\n",
      "31/36 [========================>.....] - ETA: 38:56 - d_loss: 2.0579 - g_loss: -1.0226\n",
      "\n",
      "\n",
      "d_loss= 2.0209837\n",
      "\n",
      "g_loss= -0.8529188\n",
      "32/36 [=========================>....] - ETA: 31:17 - d_loss: 2.0567 - g_loss: -1.0173\n",
      "\n",
      "\n",
      "d_loss= 2.0664504\n",
      "\n",
      "g_loss= -0.85315365\n",
      "33/36 [==========================>...] - ETA: 23:31 - d_loss: 2.0570 - g_loss: -1.0123\n",
      "\n",
      "\n",
      "d_loss= 2.06769\n",
      "\n",
      "g_loss= -0.6843217\n",
      "34/36 [===========================>..] - ETA: 15:42 - d_loss: 2.0573 - g_loss: -1.0027\n",
      "\n",
      "\n",
      "d_loss= 2.004682\n",
      "\n",
      "g_loss= -1.2871437\n",
      "35/36 [============================>.] - ETA: 7:51 - d_loss: 2.0558 - g_loss: -1.0108 \n",
      "\n",
      "\n",
      "d_loss= 1.9834379\n",
      "\n",
      "g_loss= -1.1603667\n",
      "36/36 [==============================] - 17019s 473s/step - d_loss: 2.0538 - g_loss: -1.0149\n"
     ]
    }
   ],
   "source": [
    "# Deshabilitar los mensajes de información de TensorFlow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Deshabilitar los mensajes de información de OpenAI Gym\n",
    "gym.logger.set_level(40)\n",
    "\n",
    "history=gan8.fit(X_train,\n",
    "    epochs=EPOCHS,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0818 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0744 - accuracy: 0.0000e+00\n",
      ">Loss real: \n",
      "0.08181589096784592\n",
      ">Loss fake: \n",
      "0.07439804077148438\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos el Discriminador de GAIL en el TEST\n",
    "gan8.evaluate_D(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  0 Total reward: 500.0\n",
      "Episode  1 Total reward: 500.0\n",
      "Episode  2 Total reward: 500.0\n",
      "Episode  3 Total reward: 500.0\n",
      "Episode  4 Total reward: 500.0\n",
      "Episode  5 Total reward: 500.0\n",
      "Episode  6 Total reward: 500.0\n",
      "Episode  7 Total reward: 500.0\n",
      "Episode  8 Total reward: 500.0\n",
      "Episode  9 Total reward: 500.0\n",
      "Episode  10 Total reward: 500.0\n",
      "Episode  11 Total reward: 500.0\n",
      "Episode  12 Total reward: 500.0\n",
      "Episode  13 Total reward: 500.0\n",
      "Episode  14 Total reward: 500.0\n",
      "Episode  15 Total reward: 500.0\n",
      "Episode  16 Total reward: 500.0\n",
      "Episode  17 Total reward: 500.0\n",
      "Episode  18 Total reward: 500.0\n",
      "Episode  19 Total reward: 500.0\n",
      "Episode  20 Total reward: 500.0\n",
      "Episode  21 Total reward: 500.0\n",
      "Episode  22 Total reward: 500.0\n",
      "Episode  23 Total reward: 500.0\n",
      "Episode  24 Total reward: 500.0\n",
      "Episode  25 Total reward: 500.0\n",
      "Episode  26 Total reward: 500.0\n",
      "Episode  27 Total reward: 500.0\n",
      "Episode  28 Total reward: 500.0\n",
      "Episode  29 Total reward: 500.0\n",
      "Episode  30 Total reward: 500.0\n",
      "Episode  31 Total reward: 500.0\n",
      "Episode  32 Total reward: 500.0\n",
      "Episode  33 Total reward: 500.0\n",
      "Episode  34 Total reward: 500.0\n",
      "Episode  35 Total reward: 500.0\n",
      "Episode  36 Total reward: 500.0\n",
      "Episode  37 Total reward: 500.0\n",
      "Episode  38 Total reward: 500.0\n",
      "Episode  39 Total reward: 500.0\n",
      "Episode  40 Total reward: 500.0\n",
      "Episode  41 Total reward: 500.0\n",
      "Episode  42 Total reward: 500.0\n",
      "Episode  43 Total reward: 500.0\n",
      "Episode  44 Total reward: 500.0\n",
      "Episode  45 Total reward: 500.0\n",
      "Episode  46 Total reward: 500.0\n",
      "Episode  47 Total reward: 500.0\n",
      "Episode  48 Total reward: 500.0\n",
      "Episode  49 Total reward: 500.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recompensa de Media: 500.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos al Generador \n",
    "rewardMean=gan8.evaluate_G()\n",
    "print('\\nRecompensa de Media:', rewardMean, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción de base de datos experta con 9 trayectoria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_observations = np.genfromtxt(\"observations_CartPole_.csv\",delimiter=\"\\t\",dtype=str)\n",
    "expert_actions = np.genfromtxt('actions_CartPole_.csv', dtype=np.int32)\n",
    "expert_num_tray=np.genfromtxt('n_trayectoria_CartPole_.csv', dtype=np.int32)\n",
    "\n",
    "# Reemplazar las comas\n",
    "expert_observations = np.core.defchararray.replace(expert_observations, ',', ' ')\n",
    "\n",
    "# Crear un nuevo array para almacenar los datos convertidos\n",
    "converted_observations = np.genfromtxt(expert_observations, delimiter=' ', dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500\n"
     ]
    }
   ],
   "source": [
    "longitud_trayectoria += np.count_nonzero(expert_num_tray == 8)\n",
    "print(longitud_trayectoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos quedamos solo con la primera trayectoria\n",
    "converted_observations=converted_observations[0:longitud_trayectoria]\n",
    "expert_actions=expert_actions[0:longitud_trayectoria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEstados reales: \n",
      " [[ 0.00572823 -0.03831238  0.03101629  0.00900886]\n",
      " [ 0.00496198  0.15635134  0.03119646 -0.27372897]\n",
      " [ 0.00808901 -0.03920152  0.02572188  0.02862788]\n",
      " ...\n",
      " [-0.03005801 -0.22147515  0.00891429  0.30272087]\n",
      " [-0.03448751 -0.02648138  0.01496871  0.0128626 ]\n",
      " [-0.03501714  0.16842274  0.01522596 -0.27506018]]\n",
      "\tAcciones reales: \n",
      " [1 0 1 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\tEstados reales: \\n\", converted_observations)\n",
    "print(\"\\tAcciones reales: \\n\", expert_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separación de Train y Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00572823 -0.03831238  0.03101629  0.00900886  0.          1.        ]\n",
      " [ 0.00496198  0.15635134  0.03119646 -0.27372897  1.          0.        ]\n",
      " [ 0.00808901 -0.03920152  0.02572188  0.02862788  0.          1.        ]\n",
      " ...\n",
      " [-0.03005801 -0.22147515  0.00891429  0.30272087  0.          1.        ]\n",
      " [-0.03448751 -0.02648138  0.01496871  0.0128626   0.          1.        ]\n",
      " [-0.03501714  0.16842274  0.01522596 -0.27506018  1.          0.        ]]\n",
      "Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento: 3600\n",
      "Nº de (ESTADOS,ACCIONES) en el conjunto de prueba: 900\n"
     ]
    }
   ],
   "source": [
    "# Construimos el dataset [s,a] reales y lo dividimos en training y test\n",
    "expert_a_one_hot=np.eye(env.action_space.n)[expert_actions]\n",
    "\n",
    "dataset=np.concatenate([converted_observations,expert_a_one_hot],axis=1)\n",
    "\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test = train_test_split(dataset, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "#Imprime el número de elementos en el conjuntos de entrenamiento y prueba\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento:', len(X_train))\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de prueba:', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "env= gym.make('CartPole-v1')\n",
    "obs,_= env.reset()\n",
    "\n",
    "# Generador\n",
    "generator=Policy_net( 'policy', env, obs)\n",
    "\n",
    "# Generamos [s,a] falsas y las políticas theta_i y theta_i+1\n",
    "observations, actions, rewards, Old_Policy, Policy=generator.generate_fakes()\n",
    "\n",
    "# Discriminador\n",
    "discriminator=Discriminator(env, discriminator_net, converted_observations, expert_actions, observations, actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan9=GAN(discriminator=discriminator,generator=generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "gan9.compile(\n",
    "    d_optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss_fn_D=loss_fn_D\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "d_loss= 1.9952602\n",
      "\n",
      "g_loss= -0.83535737\n",
      " 1/40 [..............................] - ETA: 5:20:22 - d_loss: 1.9953 - g_loss: -0.8354\n",
      "\n",
      "\n",
      "d_loss= 1.9649125\n",
      "\n",
      "g_loss= -1.2702848\n",
      " 2/40 [>.............................] - ETA: 5:22:14 - d_loss: 1.9801 - g_loss: -1.0528\n",
      "\n",
      "\n",
      "d_loss= 1.9753921\n",
      "\n",
      "g_loss= -0.6540884\n",
      " 3/40 [=>............................] - ETA: 5:11:09 - d_loss: 1.9785 - g_loss: -0.9199\n",
      "\n",
      "\n",
      "d_loss= 2.007296\n",
      "\n",
      "g_loss= -0.7901392\n",
      " 4/40 [==>...........................] - ETA: 5:01:56 - d_loss: 1.9857 - g_loss: -0.8875\n",
      "\n",
      "\n",
      "d_loss= 1.9838417\n",
      "\n",
      "g_loss= -0.8374457\n",
      " 5/40 [==>...........................] - ETA: 4:54:59 - d_loss: 1.9853 - g_loss: -0.8775\n",
      "\n",
      "\n",
      "d_loss= 1.9735923\n",
      "\n",
      "g_loss= -1.2216411\n",
      " 6/40 [===>..........................] - ETA: 4:46:41 - d_loss: 1.9834 - g_loss: -0.9348\n",
      "\n",
      "\n",
      "d_loss= 1.9769558\n",
      "\n",
      "g_loss= -1.2608734\n",
      " 7/40 [====>.........................] - ETA: 4:38:34 - d_loss: 1.9825 - g_loss: -0.9814\n",
      "\n",
      "\n",
      "d_loss= 2.0012953\n",
      "\n",
      "g_loss= -1.075411\n",
      " 8/40 [=====>........................] - ETA: 4:29:42 - d_loss: 1.9848 - g_loss: -0.9932\n",
      "\n",
      "\n",
      "d_loss= 1.937967\n",
      "\n",
      "g_loss= -0.84535056\n",
      " 9/40 [=====>........................] - ETA: 4:21:16 - d_loss: 1.9796 - g_loss: -0.9767\n",
      "\n",
      "\n",
      "d_loss= 1.9459493\n",
      "\n",
      "g_loss= -1.2042146\n",
      "10/40 [======>.......................] - ETA: 4:10:48 - d_loss: 1.9762 - g_loss: -0.9995\n",
      "\n",
      "\n",
      "d_loss= 1.9227406\n",
      "\n",
      "g_loss= -0.941588\n",
      "11/40 [=======>......................] - ETA: 3:59:57 - d_loss: 1.9714 - g_loss: -0.9942\n",
      "\n",
      "\n",
      "d_loss= 1.9425105\n",
      "\n",
      "g_loss= -1.0953283\n",
      "12/40 [========>.....................] - ETA: 3:49:48 - d_loss: 1.9690 - g_loss: -1.0026\n",
      "\n",
      "\n",
      "d_loss= 1.9746503\n",
      "\n",
      "g_loss= -1.0319265\n",
      "13/40 [========>.....................] - ETA: 3:39:48 - d_loss: 1.9694 - g_loss: -1.0049\n",
      "\n",
      "\n",
      "d_loss= 1.8836809\n",
      "\n",
      "g_loss= -1.1428417\n",
      "14/40 [=========>....................] - ETA: 3:30:24 - d_loss: 1.9633 - g_loss: -1.0147\n",
      "\n",
      "\n",
      "d_loss= 1.9510524\n",
      "\n",
      "g_loss= -1.0456874\n",
      "15/40 [==========>...................] - ETA: 3:21:24 - d_loss: 1.9625 - g_loss: -1.0168\n",
      "\n",
      "\n",
      "d_loss= 1.9456493\n",
      "\n",
      "g_loss= -0.9206034\n",
      "16/40 [===========>..................] - ETA: 3:12:47 - d_loss: 1.9614 - g_loss: -1.0108\n",
      "\n",
      "\n",
      "d_loss= 1.9573466\n",
      "\n",
      "g_loss= -0.93455136\n",
      "17/40 [===========>..................] - ETA: 3:03:47 - d_loss: 1.9612 - g_loss: -1.0063\n",
      "\n",
      "\n",
      "d_loss= 1.9842656\n",
      "\n",
      "g_loss= -0.44410324\n",
      "18/40 [============>.................] - ETA: 2:55:03 - d_loss: 1.9625 - g_loss: -0.9751\n",
      "\n",
      "\n",
      "d_loss= 1.9506924\n",
      "\n",
      "g_loss= -1.0200884\n",
      "19/40 [=============>................] - ETA: 2:46:43 - d_loss: 1.9618 - g_loss: -0.9774\n",
      "\n",
      "\n",
      "d_loss= 1.9330436\n",
      "\n",
      "g_loss= -0.8992237\n",
      "20/40 [==============>...............] - ETA: 2:38:40 - d_loss: 1.9604 - g_loss: -0.9735\n",
      "\n",
      "\n",
      "d_loss= 1.9269838\n",
      "\n",
      "g_loss= -0.92304444\n",
      "21/40 [==============>...............] - ETA: 2:30:23 - d_loss: 1.9588 - g_loss: -0.9711\n",
      "\n",
      "\n",
      "d_loss= 1.938\n",
      "\n",
      "g_loss= -0.9466454\n",
      "22/40 [===============>..............] - ETA: 2:22:11 - d_loss: 1.9579 - g_loss: -0.9700\n",
      "\n",
      "\n",
      "d_loss= 1.9050138\n",
      "\n",
      "g_loss= -0.8799796\n",
      "23/40 [================>.............] - ETA: 2:14:05 - d_loss: 1.9556 - g_loss: -0.9661\n",
      "\n",
      "\n",
      "d_loss= 1.9571164\n",
      "\n",
      "g_loss= -0.9424624\n",
      "24/40 [=================>............] - ETA: 2:05:52 - d_loss: 1.9556 - g_loss: -0.9651\n",
      "\n",
      "\n",
      "d_loss= 1.9319056\n",
      "\n",
      "g_loss= -0.79596627\n",
      "25/40 [=================>............] - ETA: 1:57:48 - d_loss: 1.9547 - g_loss: -0.9584\n",
      "\n",
      "\n",
      "d_loss= 1.9272238\n",
      "\n",
      "g_loss= -1.0151199\n",
      "26/40 [==================>...........] - ETA: 1:49:57 - d_loss: 1.9536 - g_loss: -0.9605\n",
      "\n",
      "\n",
      "d_loss= 1.919475\n",
      "\n",
      "g_loss= -0.8250788\n",
      "27/40 [===================>..........] - ETA: 1:42:08 - d_loss: 1.9524 - g_loss: -0.9555\n",
      "\n",
      "\n",
      "d_loss= 1.9292425\n",
      "\n",
      "g_loss= -1.2376028\n",
      "28/40 [====================>.........] - ETA: 1:34:14 - d_loss: 1.9515 - g_loss: -0.9656\n",
      "\n",
      "\n",
      "d_loss= 1.9259864\n",
      "\n",
      "g_loss= -0.9886611\n",
      "29/40 [====================>.........] - ETA: 1:26:16 - d_loss: 1.9507 - g_loss: -0.9664\n",
      "\n",
      "\n",
      "d_loss= 1.9364228\n",
      "\n",
      "g_loss= -0.92503434\n",
      "30/40 [=====================>........] - ETA: 1:18:17 - d_loss: 1.9502 - g_loss: -0.9650\n",
      "\n",
      "\n",
      "d_loss= 1.9079878\n",
      "\n",
      "g_loss= -0.9844119\n",
      "31/40 [======================>.......] - ETA: 1:10:25 - d_loss: 1.9488 - g_loss: -0.9656\n",
      "\n",
      "\n",
      "d_loss= 1.8842422\n",
      "\n",
      "g_loss= -0.9119241\n",
      "32/40 [=======================>......] - ETA: 1:02:31 - d_loss: 1.9468 - g_loss: -0.9640\n",
      "\n",
      "\n",
      "d_loss= 1.9065133\n",
      "\n",
      "g_loss= -1.1788745\n",
      "33/40 [=======================>......] - ETA: 54:44 - d_loss: 1.9456 - g_loss: -0.9705  \n",
      "\n",
      "\n",
      "d_loss= 1.9185083\n",
      "\n",
      "g_loss= -1.0315765\n",
      "34/40 [========================>.....] - ETA: 46:52 - d_loss: 1.9448 - g_loss: -0.9723\n",
      "\n",
      "\n",
      "d_loss= 1.9354346\n",
      "\n",
      "g_loss= -1.1641484\n",
      "35/40 [=========================>....] - ETA: 39:02 - d_loss: 1.9445 - g_loss: -0.9778\n",
      "\n",
      "\n",
      "d_loss= 1.9153076\n",
      "\n",
      "g_loss= -1.1973119\n",
      "36/40 [==========================>...] - ETA: 31:16 - d_loss: 1.9437 - g_loss: -0.9838\n",
      "\n",
      "\n",
      "d_loss= 1.9293813\n",
      "\n",
      "g_loss= -1.0938474\n",
      "37/40 [==========================>...] - ETA: 23:27 - d_loss: 1.9433 - g_loss: -0.9868\n",
      "\n",
      "\n",
      "d_loss= 1.9247079\n",
      "\n",
      "g_loss= -0.94681484\n",
      "38/40 [===========================>..] - ETA: 15:38 - d_loss: 1.9428 - g_loss: -0.9858\n",
      "\n",
      "\n",
      "d_loss= 1.8998567\n",
      "\n",
      "g_loss= -1.1482875\n",
      "39/40 [============================>.] - ETA: 7:48 - d_loss: 1.9417 - g_loss: -0.9899 \n",
      "\n",
      "\n",
      "d_loss= 1.9054058\n",
      "\n",
      "g_loss= -0.6540855\n",
      "40/40 [==============================] - 18760s 468s/step - d_loss: 1.9408 - g_loss: -0.9815\n"
     ]
    }
   ],
   "source": [
    "# Deshabilitar los mensajes de información de TensorFlow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Deshabilitar los mensajes de información de OpenAI Gym\n",
    "gym.logger.set_level(40)\n",
    "\n",
    "history=gan9.fit(X_train,\n",
    "    epochs=EPOCHS,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0183 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0168 - accuracy: 0.0000e+00\n",
      ">Loss real: \n",
      "0.018305018544197083\n",
      ">Loss fake: \n",
      "0.016794763505458832\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos el Discriminador de GAIL en el TEST\n",
    "gan9.evaluate_D(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  0 Total reward: 500.0\n",
      "Episode  1 Total reward: 500.0\n",
      "Episode  2 Total reward: 500.0\n",
      "Episode  3 Total reward: 500.0\n",
      "Episode  4 Total reward: 500.0\n",
      "Episode  5 Total reward: 500.0\n",
      "Episode  6 Total reward: 500.0\n",
      "Episode  7 Total reward: 500.0\n",
      "Episode  8 Total reward: 500.0\n",
      "Episode  9 Total reward: 500.0\n",
      "Episode  10 Total reward: 500.0\n",
      "Episode  11 Total reward: 500.0\n",
      "Episode  12 Total reward: 500.0\n",
      "Episode  13 Total reward: 500.0\n",
      "Episode  14 Total reward: 500.0\n",
      "Episode  15 Total reward: 500.0\n",
      "Episode  16 Total reward: 500.0\n",
      "Episode  17 Total reward: 500.0\n",
      "Episode  18 Total reward: 500.0\n",
      "Episode  19 Total reward: 500.0\n",
      "Episode  20 Total reward: 500.0\n",
      "Episode  21 Total reward: 500.0\n",
      "Episode  22 Total reward: 500.0\n",
      "Episode  23 Total reward: 500.0\n",
      "Episode  24 Total reward: 500.0\n",
      "Episode  25 Total reward: 500.0\n",
      "Episode  26 Total reward: 500.0\n",
      "Episode  27 Total reward: 500.0\n",
      "Episode  28 Total reward: 500.0\n",
      "Episode  29 Total reward: 500.0\n",
      "Episode  30 Total reward: 500.0\n",
      "Episode  31 Total reward: 500.0\n",
      "Episode  32 Total reward: 500.0\n",
      "Episode  33 Total reward: 500.0\n",
      "Episode  34 Total reward: 500.0\n",
      "Episode  35 Total reward: 500.0\n",
      "Episode  36 Total reward: 500.0\n",
      "Episode  37 Total reward: 500.0\n",
      "Episode  38 Total reward: 500.0\n",
      "Episode  39 Total reward: 500.0\n",
      "Episode  40 Total reward: 500.0\n",
      "Episode  41 Total reward: 500.0\n",
      "Episode  42 Total reward: 500.0\n",
      "Episode  43 Total reward: 500.0\n",
      "Episode  44 Total reward: 500.0\n",
      "Episode  45 Total reward: 500.0\n",
      "Episode  46 Total reward: 500.0\n",
      "Episode  47 Total reward: 500.0\n",
      "Episode  48 Total reward: 500.0\n",
      "Episode  49 Total reward: 500.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recompensa de Media: 500.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos al Generador \n",
    "rewardMean=gan9.evaluate_G()\n",
    "print('\\nRecompensa de Media:', rewardMean, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción de base de datos experta con 10 trayectoria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_observations = np.genfromtxt(\"observations_CartPole_.csv\",delimiter=\"\\t\",dtype=str)\n",
    "expert_actions = np.genfromtxt('actions_CartPole_.csv', dtype=np.int32)\n",
    "expert_num_tray=np.genfromtxt('n_trayectoria_CartPole_.csv', dtype=np.int32)\n",
    "\n",
    "# Reemplazar las comas\n",
    "expert_observations = np.core.defchararray.replace(expert_observations, ',', ' ')\n",
    "\n",
    "# Crear un nuevo array para almacenar los datos convertidos\n",
    "converted_observations = np.genfromtxt(expert_observations, delimiter=' ', dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "longitud_trayectoria += np.count_nonzero(expert_num_tray == 9)\n",
    "print(longitud_trayectoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos quedamos solo con la primera trayectoria\n",
    "converted_observations=converted_observations[0:longitud_trayectoria]\n",
    "expert_actions=expert_actions[0:longitud_trayectoria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEstados reales: \n",
      " [[ 0.00572823 -0.03831238  0.03101629  0.00900886]\n",
      " [ 0.00496198  0.15635134  0.03119646 -0.27372897]\n",
      " [ 0.00808901 -0.03920152  0.02572188  0.02862788]\n",
      " ...\n",
      " [-0.03035956 -0.1520803   0.0103268   0.24866116]\n",
      " [-0.03340117  0.04289266  0.01530002 -0.04074667]\n",
      " [-0.03254332  0.23779191  0.01448509 -0.3285633 ]]\n",
      "\tAcciones reales: \n",
      " [1 0 1 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\tEstados reales: \\n\", converted_observations)\n",
    "print(\"\\tAcciones reales: \\n\", expert_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separación de Train y Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00572823 -0.03831238  0.03101629  0.00900886  0.          1.        ]\n",
      " [ 0.00496198  0.15635134  0.03119646 -0.27372897  1.          0.        ]\n",
      " [ 0.00808901 -0.03920152  0.02572188  0.02862788  0.          1.        ]\n",
      " ...\n",
      " [-0.03035956 -0.1520803   0.0103268   0.24866116  0.          1.        ]\n",
      " [-0.03340117  0.04289266  0.01530002 -0.04074667  0.          1.        ]\n",
      " [-0.03254332  0.23779191  0.01448509 -0.3285633   1.          0.        ]]\n",
      "Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento: 4000\n",
      "Nº de (ESTADOS,ACCIONES) en el conjunto de prueba: 1000\n"
     ]
    }
   ],
   "source": [
    "# Construimos el dataset [s,a] reales y lo dividimos en training y test\n",
    "expert_a_one_hot=np.eye(env.action_space.n)[expert_actions]\n",
    "\n",
    "dataset=np.concatenate([converted_observations,expert_a_one_hot],axis=1)\n",
    "\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test = train_test_split(dataset, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "#Imprime el número de elementos en el conjuntos de entrenamiento y prueba\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento:', len(X_train))\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de prueba:', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "env= gym.make('CartPole-v1')\n",
    "obs,_= env.reset()\n",
    "\n",
    "# Generador\n",
    "generator=Policy_net( 'policy', env, obs)\n",
    "\n",
    "# Generamos [s,a] falsas y las políticas theta_i y theta_i+1\n",
    "observations, actions, rewards, Old_Policy, Policy=generator.generate_fakes()\n",
    "\n",
    "# Discriminador\n",
    "discriminator=Discriminator(env, discriminator_net, converted_observations, expert_actions, observations, actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan10=GAN(discriminator=discriminator,generator=generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "gan10.compile(\n",
    "    d_optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss_fn_D=loss_fn_D\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "d_loss= 1.9244822\n",
      "\n",
      "g_loss= -0.9320656\n",
      " 1/45 [..............................] - ETA: 5:35:47 - d_loss: 1.9245 - g_loss: -0.9321\n",
      "\n",
      "\n",
      "d_loss= 1.8807418\n",
      "\n",
      "g_loss= -1.2312539\n",
      " 2/45 [>.............................] - ETA: 5:14:57 - d_loss: 1.9026 - g_loss: -1.0817\n",
      "\n",
      "\n",
      "d_loss= 1.934237\n",
      "\n",
      "g_loss= -1.1551963\n",
      " 3/45 [=>............................] - ETA: 5:08:28 - d_loss: 1.9132 - g_loss: -1.1062\n",
      "\n",
      "\n",
      "d_loss= 1.9074911\n",
      "\n",
      "g_loss= -0.8033719\n",
      " 4/45 [=>............................] - ETA: 4:59:37 - d_loss: 1.9117 - g_loss: -1.0305\n",
      "\n",
      "\n",
      "d_loss= 1.8802083\n",
      "\n",
      "g_loss= -0.862467\n",
      " 5/45 [==>...........................] - ETA: 4:54:08 - d_loss: 1.9054 - g_loss: -0.9969\n",
      "\n",
      "\n",
      "d_loss= 1.8877099\n",
      "\n",
      "g_loss= -0.80291784\n",
      " 6/45 [===>..........................] - ETA: 4:47:19 - d_loss: 1.9025 - g_loss: -0.9645\n",
      "\n",
      "\n",
      "d_loss= 1.8980758\n",
      "\n",
      "g_loss= -0.86416537\n",
      " 7/45 [===>..........................] - ETA: 4:40:18 - d_loss: 1.9018 - g_loss: -0.9502\n",
      "\n",
      "\n",
      "d_loss= 1.9142215\n",
      "\n",
      "g_loss= -0.9252326\n",
      " 8/45 [====>.........................] - ETA: 4:33:00 - d_loss: 1.9034 - g_loss: -0.9471\n",
      "\n",
      "\n",
      "d_loss= 1.9504335\n",
      "\n",
      "g_loss= -1.0861694\n",
      " 9/45 [=====>........................] - ETA: 4:25:32 - d_loss: 1.9086 - g_loss: -0.9625\n",
      "\n",
      "\n",
      "d_loss= 1.8635004\n",
      "\n",
      "g_loss= -1.2322887\n",
      "10/45 [=====>........................] - ETA: 4:18:16 - d_loss: 1.9041 - g_loss: -0.9895\n",
      "\n",
      "\n",
      "d_loss= 1.8737156\n",
      "\n",
      "g_loss= -0.9764233\n",
      "11/45 [======>.......................] - ETA: 4:10:45 - d_loss: 1.9013 - g_loss: -0.9883\n",
      "\n",
      "\n",
      "d_loss= 1.8628342\n",
      "\n",
      "g_loss= -0.8451671\n",
      "12/45 [=======>......................] - ETA: 4:03:31 - d_loss: 1.8981 - g_loss: -0.9764\n",
      "\n",
      "\n",
      "d_loss= 1.9530617\n",
      "\n",
      "g_loss= -0.9749886\n",
      "13/45 [=======>......................] - ETA: 3:55:54 - d_loss: 1.9024 - g_loss: -0.9763\n",
      "\n",
      "\n",
      "d_loss= 1.9631333\n",
      "\n",
      "g_loss= -1.270411\n",
      "14/45 [========>.....................] - ETA: 3:48:38 - d_loss: 1.9067 - g_loss: -0.9973\n",
      "\n",
      "\n",
      "d_loss= 1.9094716\n",
      "\n",
      "g_loss= -0.9576293\n",
      "15/45 [=========>....................] - ETA: 3:41:10 - d_loss: 1.9069 - g_loss: -0.9946\n",
      "\n",
      "\n",
      "d_loss= 1.8736839\n",
      "\n",
      "g_loss= -1.2799348\n",
      "16/45 [=========>....................] - ETA: 3:34:12 - d_loss: 1.9048 - g_loss: -1.0125\n",
      "\n",
      "\n",
      "d_loss= 1.9141092\n",
      "\n",
      "g_loss= -0.9515056\n",
      "17/45 [==========>...................] - ETA: 3:26:49 - d_loss: 1.9054 - g_loss: -1.0089\n",
      "\n",
      "\n",
      "d_loss= 1.9066627\n",
      "\n",
      "g_loss= -0.6505261\n",
      "18/45 [===========>..................] - ETA: 3:19:39 - d_loss: 1.9054 - g_loss: -0.9890\n",
      "\n",
      "\n",
      "d_loss= 1.9190623\n",
      "\n",
      "g_loss= -1.0222926\n",
      "19/45 [===========>..................] - ETA: 3:12:26 - d_loss: 1.9061 - g_loss: -0.9907\n",
      "\n",
      "\n",
      "d_loss= 1.8982465\n",
      "\n",
      "g_loss= -1.0728436\n",
      "20/45 [============>.................] - ETA: 3:05:06 - d_loss: 1.9058 - g_loss: -0.9948\n",
      "\n",
      "\n",
      "d_loss= 1.9391514\n",
      "\n",
      "g_loss= -1.1322376\n",
      "21/45 [=============>................] - ETA: 2:57:33 - d_loss: 1.9073 - g_loss: -1.0014\n",
      "\n",
      "\n",
      "d_loss= 1.905335\n",
      "\n",
      "g_loss= -1.0675747\n",
      "22/45 [=============>................] - ETA: 2:50:15 - d_loss: 1.9073 - g_loss: -1.0044\n",
      "\n",
      "\n",
      "d_loss= 1.9108754\n",
      "\n",
      "g_loss= -0.7827869\n",
      "23/45 [==============>...............] - ETA: 2:42:49 - d_loss: 1.9074 - g_loss: -0.9948\n",
      "\n",
      "\n",
      "d_loss= 1.9249626\n",
      "\n",
      "g_loss= -0.7348751\n",
      "24/45 [===============>..............] - ETA: 2:35:20 - d_loss: 1.9081 - g_loss: -0.9839\n",
      "\n",
      "\n",
      "d_loss= 1.8773259\n",
      "\n",
      "g_loss= -0.87042934\n",
      "25/45 [===============>..............] - ETA: 2:27:59 - d_loss: 1.9069 - g_loss: -0.9794\n",
      "\n",
      "\n",
      "d_loss= 1.9398816\n",
      "\n",
      "g_loss= -0.9034014\n",
      "26/45 [================>.............] - ETA: 2:20:38 - d_loss: 1.9082 - g_loss: -0.9765\n",
      "\n",
      "\n",
      "d_loss= 1.8988996\n",
      "\n",
      "g_loss= -0.71598464\n",
      "27/45 [=================>............] - ETA: 2:13:16 - d_loss: 1.9078 - g_loss: -0.9668\n",
      "\n",
      "\n",
      "d_loss= 1.9207894\n",
      "\n",
      "g_loss= -1.2519367\n",
      "28/45 [=================>............] - ETA: 2:05:52 - d_loss: 1.9083 - g_loss: -0.9770\n",
      "\n",
      "\n",
      "d_loss= 1.9565225\n",
      "\n",
      "g_loss= -0.93218786\n",
      "29/45 [==================>...........] - ETA: 1:58:27 - d_loss: 1.9100 - g_loss: -0.9755\n",
      "\n",
      "\n",
      "d_loss= 1.9429561\n",
      "\n",
      "g_loss= -1.2876574\n",
      "30/45 [===================>..........] - ETA: 1:51:03 - d_loss: 1.9111 - g_loss: -0.9859\n",
      "\n",
      "\n",
      "d_loss= 1.9097679\n",
      "\n",
      "g_loss= -1.0881977\n",
      "31/45 [===================>..........] - ETA: 1:43:41 - d_loss: 1.9110 - g_loss: -0.9892\n",
      "\n",
      "\n",
      "d_loss= 1.9594343\n",
      "\n",
      "g_loss= -0.86481833\n",
      "32/45 [====================>.........] - ETA: 1:36:19 - d_loss: 1.9125 - g_loss: -0.9853\n",
      "\n",
      "\n",
      "d_loss= 1.8981447\n",
      "\n",
      "g_loss= -1.1908101\n",
      "33/45 [=====================>........] - ETA: 1:28:53 - d_loss: 1.9121 - g_loss: -0.9915\n",
      "\n",
      "\n",
      "d_loss= 1.9294876\n",
      "\n",
      "g_loss= -0.9739109\n",
      "34/45 [=====================>........] - ETA: 1:21:30 - d_loss: 1.9126 - g_loss: -0.9910\n",
      "\n",
      "\n",
      "d_loss= 1.9205207\n",
      "\n",
      "g_loss= -1.2103153\n",
      "35/45 [======================>.......] - ETA: 1:14:08 - d_loss: 1.9128 - g_loss: -0.9973\n",
      "\n",
      "\n",
      "d_loss= 1.8946109\n",
      "\n",
      "g_loss= -1.0089588\n",
      "36/45 [=======================>......] - ETA: 1:06:44 - d_loss: 1.9123 - g_loss: -0.9976\n",
      "\n",
      "\n",
      "d_loss= 1.8976251\n",
      "\n",
      "g_loss= -0.6351026\n",
      "37/45 [=======================>......] - ETA: 59:18 - d_loss: 1.9119 - g_loss: -0.9878  \n",
      "\n",
      "\n",
      "d_loss= 1.9360995\n",
      "\n",
      "g_loss= -0.8743149\n",
      "38/45 [========================>.....] - ETA: 51:54 - d_loss: 1.9126 - g_loss: -0.9848\n",
      "\n",
      "\n",
      "d_loss= 1.9394958\n",
      "\n",
      "g_loss= -1.2534226\n",
      "39/45 [=========================>....] - ETA: 44:29 - d_loss: 1.9133 - g_loss: -0.9917\n",
      "\n",
      "\n",
      "d_loss= 1.9594927\n",
      "\n",
      "g_loss= -1.032288\n",
      "40/45 [=========================>....] - ETA: 37:05 - d_loss: 1.9144 - g_loss: -0.9927\n",
      "\n",
      "\n",
      "d_loss= 1.880575\n",
      "\n",
      "g_loss= -1.0988206\n",
      "41/45 [==========================>...] - ETA: 29:41 - d_loss: 1.9136 - g_loss: -0.9953\n",
      "\n",
      "\n",
      "d_loss= 1.906346\n",
      "\n",
      "g_loss= -1.0248759\n",
      "42/45 [===========================>..] - ETA: 22:16 - d_loss: 1.9134 - g_loss: -0.9960\n",
      "\n",
      "\n",
      "d_loss= 1.8928924\n",
      "\n",
      "g_loss= -1.0920677\n",
      "43/45 [===========================>..] - ETA: 14:51 - d_loss: 1.9129 - g_loss: -0.9982\n",
      "\n",
      "\n",
      "d_loss= 1.9141134\n",
      "\n",
      "g_loss= -1.2421131\n",
      "44/45 [============================>.] - ETA: 7:25 - d_loss: 1.9130 - g_loss: -1.0038 \n",
      "\n",
      "\n",
      "d_loss= 1.891101\n",
      "\n",
      "g_loss= -0.72000736\n",
      "45/45 [==============================] - 20066s 446s/step - d_loss: 1.9125 - g_loss: -0.9975\n"
     ]
    }
   ],
   "source": [
    "# Deshabilitar los mensajes de información de TensorFlow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Deshabilitar los mensajes de información de OpenAI Gym\n",
    "gym.logger.set_level(40)\n",
    "\n",
    "history=gan10.fit(X_train,\n",
    "    epochs=EPOCHS,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0022 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0023 - accuracy: 0.0000e+00\n",
      ">Loss real: \n",
      "0.002202261472120881\n",
      ">Loss fake: \n",
      "0.0023386504035443068\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos el Discriminador de GAIL en el TEST\n",
    "gan10.evaluate_D(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  0 Total reward: 500.0\n",
      "Episode  1 Total reward: 500.0\n",
      "Episode  2 Total reward: 500.0\n",
      "Episode  3 Total reward: 500.0\n",
      "Episode  4 Total reward: 500.0\n",
      "Episode  5 Total reward: 500.0\n",
      "Episode  6 Total reward: 500.0\n",
      "Episode  7 Total reward: 500.0\n",
      "Episode  8 Total reward: 500.0\n",
      "Episode  9 Total reward: 500.0\n",
      "Episode  10 Total reward: 500.0\n",
      "Episode  11 Total reward: 500.0\n",
      "Episode  12 Total reward: 500.0\n",
      "Episode  13 Total reward: 500.0\n",
      "Episode  14 Total reward: 500.0\n",
      "Episode  15 Total reward: 500.0\n",
      "Episode  16 Total reward: 500.0\n",
      "Episode  17 Total reward: 500.0\n",
      "Episode  18 Total reward: 500.0\n",
      "Episode  19 Total reward: 500.0\n",
      "Episode  20 Total reward: 500.0\n",
      "Episode  21 Total reward: 500.0\n",
      "Episode  22 Total reward: 500.0\n",
      "Episode  23 Total reward: 500.0\n",
      "Episode  24 Total reward: 500.0\n",
      "Episode  25 Total reward: 500.0\n",
      "Episode  26 Total reward: 500.0\n",
      "Episode  27 Total reward: 500.0\n",
      "Episode  28 Total reward: 500.0\n",
      "Episode  29 Total reward: 500.0\n",
      "Episode  30 Total reward: 500.0\n",
      "Episode  31 Total reward: 500.0\n",
      "Episode  32 Total reward: 500.0\n",
      "Episode  33 Total reward: 500.0\n",
      "Episode  34 Total reward: 500.0\n",
      "Episode  35 Total reward: 500.0\n",
      "Episode  36 Total reward: 500.0\n",
      "Episode  37 Total reward: 500.0\n",
      "Episode  38 Total reward: 500.0\n",
      "Episode  39 Total reward: 500.0\n",
      "Episode  40 Total reward: 500.0\n",
      "Episode  41 Total reward: 500.0\n",
      "Episode  42 Total reward: 500.0\n",
      "Episode  43 Total reward: 500.0\n",
      "Episode  44 Total reward: 500.0\n",
      "Episode  45 Total reward: 500.0\n",
      "Episode  46 Total reward: 500.0\n",
      "Episode  47 Total reward: 500.0\n",
      "Episode  48 Total reward: 500.0\n",
      "Episode  49 Total reward: 500.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recompensa de Media: 500.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos al Generador \n",
    "rewardMean=gan10.evaluate_G()\n",
    "print('\\nRecompensa de Media:', rewardMean, '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
