{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jun 15 12:37:23 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.147.05   Driver Version: 525.147.05   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   35C    P8    16W / 100W |     46MiB /  6144MiB |     41%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2204      G   /usr/lib/xorg/Xorg                 45MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "#########################################################################\n",
    "## COMPROBAR GPU ASIGNADA EN COLABORATORY\n",
    "#########################################################################\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gymnasium in /home/usuario/.local/lib/python3.10/site-packages (0.28.1)\n",
      "Requirement already satisfied: jax-jumpy>=1.0.0 in /home/usuario/.local/lib/python3.10/site-packages (from gymnasium) (1.0.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /home/usuario/.local/lib/python3.10/site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/usuario/.local/lib/python3.10/site-packages (from gymnasium) (1.24.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/usuario/.local/lib/python3.10/site-packages (from gymnasium) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/usuario/.local/lib/python3.10/site-packages (from gymnasium) (4.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: stable_baselines3 in /home/usuario/.local/lib/python3.10/site-packages (2.0.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/usuario/.local/lib/python3.10/site-packages (from stable_baselines3) (1.24.3)\n",
      "Requirement already satisfied: matplotlib in /home/usuario/.local/lib/python3.10/site-packages (from stable_baselines3) (3.7.2)\n",
      "Requirement already satisfied: cloudpickle in /home/usuario/.local/lib/python3.10/site-packages (from stable_baselines3) (2.2.1)\n",
      "Requirement already satisfied: torch>=1.11 in /home/usuario/.local/lib/python3.10/site-packages (from stable_baselines3) (2.0.1)\n",
      "Requirement already satisfied: pandas in /home/usuario/.local/lib/python3.10/site-packages (from stable_baselines3) (1.5.3)\n",
      "Requirement already satisfied: gymnasium==0.28.1 in /home/usuario/.local/lib/python3.10/site-packages (from stable_baselines3) (0.28.1)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /home/usuario/.local/lib/python3.10/site-packages (from gymnasium==0.28.1->stable_baselines3) (0.0.4)\n",
      "Requirement already satisfied: jax-jumpy>=1.0.0 in /home/usuario/.local/lib/python3.10/site-packages (from gymnasium==0.28.1->stable_baselines3) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/usuario/.local/lib/python3.10/site-packages (from gymnasium==0.28.1->stable_baselines3) (4.5.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/usuario/.local/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/usuario/.local/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (11.7.91)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/usuario/.local/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/usuario/.local/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (11.7.99)\n",
      "Requirement already satisfied: networkx in /home/usuario/.local/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (3.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/usuario/.local/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/usuario/.local/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (11.7.4.91)\n",
      "Requirement already satisfied: sympy in /home/usuario/.local/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (1.12)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/usuario/.local/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (11.4.0.1)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/usuario/.local/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (2.0.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/usuario/.local/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (11.7.101)\n",
      "Requirement already satisfied: jinja2 in /home/usuario/.local/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (3.1.2)\n",
      "Requirement already satisfied: filelock in /home/usuario/.local/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (3.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/usuario/.local/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/usuario/.local/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/usuario/.local/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (10.9.0.58)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11->stable_baselines3) (0.37.1)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11->stable_baselines3) (59.6.0)\n",
      "Requirement already satisfied: lit in /home/usuario/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.11->stable_baselines3) (16.0.6)\n",
      "Requirement already satisfied: cmake in /home/usuario/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.11->stable_baselines3) (3.26.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib->stable_baselines3) (9.0.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib->stable_baselines3) (2.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/usuario/.local/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (23.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/usuario/.local/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/usuario/.local/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (1.1.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/usuario/.local/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/usuario/.local/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/usuario/.local/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->stable_baselines3) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/usuario/.local/lib/python3.10/site-packages (from jinja2->torch>=1.11->stable_baselines3) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/usuario/.local/lib/python3.10/site-packages (from sympy->torch>=1.11->stable_baselines3) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install stable_baselines3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-15 12:37:25.403859: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-15 12:37:25.416417: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-15 12:37:25.562117: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-15 12:37:25.562630: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-15 12:37:26.382277: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#########################################################################\n",
    "## LIBRERIAS NECESARIAS\n",
    "#########################################################################\n",
    "import tensorflow as tf\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from tensorflow.keras.layers import concatenate\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import layers\n",
    "import copy\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "\n",
    "import os\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "## Variables globales (hiperparámetros)\n",
    "###########################################################################\n",
    "EPOCHS=1\n",
    "BATCH_SIZE=90\n",
    "\n",
    "EPISODES=10\n",
    "EPISODES_EVALUATE_G=50\n",
    "\n",
    "TOTAL_TIMESTEPS_PPO_GENERATOR=50000\n",
    "LEARNING_RATE=0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gym CartPole-v1\n",
    "\n",
    "Un péndulo está unido mediante una articulación no accionada a un carro que se desplaza a lo largo de una pista sin fricción. El péndulo se coloca verticalmente sobre el carro y el objetivo es equilibrar el poste aplicando fuerzas en dirección izquierda y derecha sobre el carro.\n",
    "\n",
    "**Espacio de Acciones**: Espacio discreto de tamaño (2)\n",
    "\n",
    "* Acción 0: Empujar el carro hacia la izquierda\n",
    "* Acción 1: Empujar el carro hacia la derecha\n",
    "\n",
    "**Espacio de Observaciones**: Espacio continuuo de tamaño (4,)\n",
    "\n",
    "* La observación es un ndarray con forma (4,) con los valores correspondientes a las siguientes posiciones y velocidades:\n",
    "    * Num     |     Observación |     Min |    Max\n",
    "\n",
    "    * 0    Posición del Carro                 - 4.8                            4.8\n",
    "\n",
    "    *  1    Velocidad del Carro                 -Inf                            Inf\n",
    "\n",
    "    * 2    Ángulo del Poste              ~ -0.418 rad (-24°)          ~ 0.418 rad (24°)\n",
    "\n",
    "    * 3    Velocidad Angular del Poste         -Inf                            Inf\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Definimos el entorno\n",
    "env= gym.make('CartPole-v1')\n",
    "\n",
    "# Obtenemos el espacio de estados y acciones del entorno\n",
    "ob_space=env.observation_space\n",
    "ac_space=env.action_space\n",
    "\n",
    "# Mostramos el número de acciones del entorno\n",
    "print(env.action_space.n)\n",
    "# Mostramos el número de observaciones del entorno\n",
    "print(ob_space.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red neuronal del Discriminador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator_net\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (Dense)              (None, None, 4)           48        \n",
      "                                                                 \n",
      " layer2 (Dense)              (None, None, 4)           20        \n",
      "                                                                 \n",
      " layer3 (Dense)              (None, None, 4)           20        \n",
      "                                                                 \n",
      " prob (Dense)                (None, None, 1)           5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93 (372.00 Byte)\n",
      "Trainable params: 93 (372.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-15 12:37:29.368342: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2024-06-15 12:37:29.368367: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: usuario-ASUS-TUF-Gaming-F15-FX507ZM-TUF507ZM\n",
      "2024-06-15 12:37:29.368370: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: usuario-ASUS-TUF-Gaming-F15-FX507ZM-TUF507ZM\n",
      "2024-06-15 12:37:29.368453: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 525.147.5\n",
      "2024-06-15 12:37:29.368465: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 525.147.5\n",
      "2024-06-15 12:37:29.368467: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 525.147.5\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "# Red neuronal del Discriminador\n",
    "################################################################################################################################################\n",
    "\n",
    "# Input: secuencias [s,a,s',r] reales o sintéticas, de longitud 2*ob_space.shape[0] + ac_space.n+1.\n",
    "# Output: probabilidad de que la secuencia sea real, valor perteneciente al intervalo [0,1]\n",
    "discriminator_net=keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(None, 2*ob_space.shape[0] + ac_space.n+1)),\n",
    "        layers.Dense(units=4,activation=tf.nn.relu, name='layer1'),\n",
    "        layers.Dense(units=4,activation=tf.nn.relu, name='layer2'),\n",
    "        layers.Dense(units=4, activation=tf.nn.relu, name='layer3'),\n",
    "        layers.Dense(units=1, activation=tf.sigmoid, name='prob'),\n",
    "\n",
    "    ],\n",
    "    name=\"discriminator_net\"\n",
    "\n",
    ")\n",
    "discriminator_net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de pérdida del Discriminador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################\n",
    "# Función de pérdida del Discriminador\n",
    "#########################################################################################################\n",
    "\n",
    "# prob1=> output de la red neuronal del Discriminador cuando recibe como entrada una secuencia REAL [s,a, s', r] de la base de datos\n",
    "# prob2=> output de la red neuronal del Discriminador cuando recibe como entrada una secuencia FALSA [s,a, s', r]\n",
    "def loss_fn_D(prob1, prob2):\n",
    "\n",
    "    # Esperanza del logaritmo de la D(x)=salida de la red neuronal cuando x=entrada REAL\n",
    "    loss_expert = tf.reduce_mean(tf.math.log(tf.clip_by_value(prob1, 0.01, 1)))\n",
    "\n",
    "    # Esperanza del logaritmo de 1-D(x) donde D(x)=salida de la red neuronal cuando x=entrada FALSA\n",
    "    loss_agent = tf.reduce_mean(tf.math.log(tf.clip_by_value(1 - prob2, 0.01,1)))\n",
    "\n",
    "    loss_expert = tf.cast(loss_expert, dtype=tf.float32)\n",
    "    loss_agent = tf.cast(loss_agent, dtype=tf.float32)\n",
    "\n",
    "    loss = loss_expert + loss_agent\n",
    "\n",
    "    loss = -loss\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clase del Discriminador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################\n",
    "# Clase DISCRIMINADOR\n",
    "########################################################################################\n",
    "class Discriminator:\n",
    "    def __init__(self, env, discriminator_net, expert_s, expert_a, expert_s_prima, expert_r, agent_s, agent_a, agent_s_prima, agent_r):\n",
    "        # -Red neuronal del Discriminador\n",
    "        self.discriminator_net=discriminator_net\n",
    "\n",
    "        # -Experto: [s,a,s',r]\n",
    "        self.expert_s=expert_s\n",
    "        self.expert_a=expert_a\n",
    "        self.expert_s_prima=expert_s_prima\n",
    "        self.expert_r= np.array(expert_r)\n",
    "\n",
    "\n",
    "        expert_a_one_hot=tf.one_hot(self.expert_a,depth=env.action_space.n)\n",
    "        # Añadimos ruido para estabilizar el entrenamiento\n",
    "        expert_a_one_hot+= tf.random.normal(tf.shape(expert_a_one_hot), mean=0.2, stddev=0.1, dtype=tf.float32)/1.2\n",
    "        expert_s_a=tf.concat([self.expert_s,expert_a_one_hot],axis=1)\n",
    "        expert_s_a_s=tf.concat([expert_s_a, self.expert_s_prima], axis=1)\n",
    "        expert_r=self.expert_r.reshape(-1, 1)\n",
    "\n",
    "        # expert_s_a_s_r=>secuencia experta=>[s,a,s',r]\n",
    "        self.expert_s_a_s_r=tf.concat([expert_s_a_s, expert_r], axis=1)\n",
    "\n",
    "        # -Agente:  [s,a,s',r]\n",
    "        self.agent_s=agent_s\n",
    "        self.agent_a=agent_a\n",
    "        self.agent_s_prima=agent_s_prima\n",
    "        self.agent_r=np.array(agent_r)\n",
    "\n",
    "        agent_a_one_hot=tf.one_hot(self.agent_a,depth=env.action_space.n)\n",
    "        agent_a_one_hot+= tf.random.normal(tf.shape(agent_a_one_hot), mean=0.2, stddev=0.1, dtype=tf.float32)/1.2\n",
    "        agent_s_a=tf.concat([self.agent_s,agent_a_one_hot],axis=1)\n",
    "        agent_s_a_s=tf.concat([agent_s_a, self.agent_s_prima], axis=1)\n",
    "        agent_r=self.agent_r.reshape(-1, 1)\n",
    "\n",
    "        # agent_s_a_s_r=>secuencia agente=>[s,a,s',r]\n",
    "        self.agent_s_a_s_r=tf.concat([agent_s_a_s, agent_r], axis=1)\n",
    "\n",
    "        # Calculamos la salida de la red para [s,a,s',r] del experto y del agente ya que lo necesitamos para reward\n",
    "\n",
    "        # -Salida de la red neuronal Discriminador para [s,a,s',r] expertos(verdaderos)\n",
    "        self.prob_expert=self.discriminator_net(self.expert_s_a_s_r)\n",
    "\n",
    "        # -Salida  de la red neuronal Discrimiinador para [s,a,s',r] Agente(falsos)\n",
    "        self.prob_agent=self.discriminator_net(self.agent_s_a_s_r)\n",
    "\n",
    "        #-Recompensa obtenida cuando el Agente realiza [s,a,s',r] falsas\n",
    "        self.rewards=tf.math.log(tf.clip_by_value(self.prob_agent,1e-10,1)) #log(P(expert|s,a)) cuando mas grande es mejor el agente\n",
    "\n",
    "\n",
    "    def getNet(self):\n",
    "        return self.discriminator_net\n",
    "\n",
    "    def getAgent_S_A(self):\n",
    "        return self.agent_s_a\n",
    "\n",
    "    def getExpert_S_A(self):\n",
    "        return self.expert_s_a\n",
    "\n",
    "    def getProb(self):\n",
    "        return self.prob_expert, self.prob_agent\n",
    "\n",
    "    def getRewards(self):\n",
    "        return self.rewards\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes neuronales del Generador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator_net_Act\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (Dense)              (None, None, 4)           20        \n",
      "                                                                 \n",
      " layer2 (Dense)              (None, None, 4)           20        \n",
      "                                                                 \n",
      " layer3 (Dense)              (None, None, 2)           10        \n",
      "                                                                 \n",
      " layer4 (Dense)              (None, None, 2)           6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56 (224.00 Byte)\n",
      "Trainable params: 56 (224.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#####################################################################################################\n",
    "# Red neuronal del Generador donde se producen acciones\n",
    "####################################################################################################\n",
    "\n",
    "# Input: estados, listas de tamaño 4, s=[s1,s2,s3,s4]\n",
    "# Output: acciones, listas de tamaño 2, a=[a1,a2]\n",
    "generator_net_Act = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(None, ob_space.shape[0])),\n",
    "        layers.Dense(units=4, activation=tf.tanh,name='layer1'),\n",
    "        layers.Dense(units=4, activation=tf.tanh, name='layer2'),\n",
    "        layers.Dense(units=2, activation=tf.tanh, name='layer3'),\n",
    "        layers.Dense(units=ac_space.n, activation=tf.nn.softmax, name='layer4')\n",
    "\n",
    "    ],\n",
    "    name=\"generator_net_Act\"\n",
    ")\n",
    "\n",
    "generator_net_Act.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator_v_preds\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (Dense)              (None, None, 4)           20        \n",
      "                                                                 \n",
      " layer2 (Dense)              (None, None, 4)           20        \n",
      "                                                                 \n",
      " layer3 (Dense)              (None, None, 1)           5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45 (180.00 Byte)\n",
      "Trainable params: 45 (180.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#############################################################################################################\n",
    "# Red neuronal del Generador donde se producen v_pred\n",
    "#############################################################################################################\n",
    "\n",
    "# Input: estados, listas de tamaño 4, s=[s0,s1,s2,s3]\n",
    "# Output: v_pred, listas de tamaño 1, v_pred\n",
    "\n",
    "generator_net_v_preds=keras.Sequential(\n",
    "    [\n",
    "            keras.Input(shape=(None,ob_space.shape[0])),\n",
    "            layers.Dense(units=4, activation=tf.tanh,name='layer1'),\n",
    "            layers.Dense(units=4, activation=tf.tanh, name='layer2'),\n",
    "            layers.Dense(units=1, activation=None, name='layer3'),\n",
    "        ],\n",
    "    name=\"generator_v_preds\"\n",
    ")\n",
    "\n",
    "generator_net_v_preds.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de pérdida del Generador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################################\n",
    "# Función de pérdida del Generador: función objetivo de PPO \"clipped surrogated\"\n",
    "#################################################################################################################\n",
    "def loss_fn_ppo(act_probs,act_probs_old,gaes,clip_value=0.2):\n",
    "    ratios = tf.exp(tf.math.log(tf.clip_by_value(act_probs, 1e-10, 1.0))\n",
    "                    - tf.math.log(tf.clip_by_value(act_probs_old, 1e-10, 1.0)))\n",
    "\n",
    "    clipped_ratios = tf.clip_by_value(ratios,clip_value_min=1 -clip_value,clip_value_max=1 +clip_value)\n",
    "    loss_clip = tf.minimum( tf.multiply(gaes, ratios), tf.multiply(gaes, clipped_ratios))\n",
    "    loss_clip = tf.reduce_mean(loss_clip)\n",
    "\n",
    "    loss = -loss_clip\n",
    "    tf.summary.scalar('total', loss)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clase del Generador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################################################\n",
    "# Clase del GENERADOR: política con su optimizador PPO\n",
    "################################################################################################################\n",
    "\n",
    "# Observesé que cada generador implementa una política distinta, por tanto, se ha decidido llamar a la clase Policy_net en lugar de generator\n",
    "class Policy_net:\n",
    "    def __init__(self, name: str, env, obs):\n",
    "        \"\"\"\n",
    "        name: string\n",
    "        env: gym env\n",
    "        obs:\n",
    "        \"\"\"\n",
    "\n",
    "        # -Entorno\n",
    "        self.env=env\n",
    "        env.reset()\n",
    "\n",
    "        # -Modelo PPO: algoritmo de Optimización de Política Proximal\n",
    "        self.model=PPO(policy=\"MlpPolicy\", env=env, verbose=0)\n",
    "\n",
    "\n",
    "        self.model.learn(total_timesteps=TOTAL_TIMESTEPS_PPO_GENERATOR)\n",
    "\n",
    "        # -Observación inicial a partir de la cual se crean las acciones iniciales haciendo uso de las redes neuronales del generador\n",
    "        self.obs=np.reshape(np.array(obs),(1,ob_space.shape[0]))\n",
    "\n",
    "        # Utilizamos las dos redes neuronales que hemos creado : generator_net_Act y generator_net_v_preds\n",
    "        # V_pred=>recompensa media de que un agente ejecute una acción\n",
    "\n",
    "        # -Acción inicial generada con red neuronal y v_pred con red neuronal\n",
    "        self.act_probs =generator_net_Act(self.obs)\n",
    "        self.v_preds = generator_net_v_preds(self.obs)\n",
    "\n",
    "        # -Accion estocástica inicial\n",
    "        self.act_stochastic = tf.random.categorical(tf.math.log(self.act_probs), num_samples=1)\n",
    "\n",
    "        # -Acción determinística inicial\n",
    "        self.act_deterministic = tf.argmax(self.act_probs, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    # Para cada estado obs me dice la acción que el agente va a ejecutar sobre el entorno junto con v_pred\n",
    "    # La elección de la acción puede ser estocástica o determinística\n",
    "    def act(self, stochastic=True):\n",
    "        if stochastic:\n",
    "            return self.act_stochastic, self.v_preds\n",
    "        else:\n",
    "            return self.act_deterministic, self.v_preds\n",
    "\n",
    "    def get_action_prob(self):\n",
    "        return self.act_probs\n",
    "\n",
    "    def get_v_preds(self):\n",
    "        return self.v_preds\n",
    "\n",
    "    def get_obs(self):\n",
    "        return self.obs\n",
    "\n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "\n",
    "    # Devuelve los parámetros \\theta de la política \\pi\n",
    "    def get_trainable_variables(self):\n",
    "        return self.model.get_parameters()\n",
    "\n",
    "    # Generar [s,a,s',r] sinteticos\n",
    "    def generate_fakes(self):\n",
    "\n",
    "        ob_space = env.observation_space\n",
    "        reward = 0\n",
    "\n",
    "\n",
    "        # Por cada episodio\n",
    "        for iteration in range(EPISODES):\n",
    "            # Inicializo todas las variables\n",
    "            observations = []\n",
    "            actions = []\n",
    "            rewards = []\n",
    "            next_observations=[]\n",
    "\n",
    "            run_policy_steps = 0\n",
    "\n",
    "\n",
    "            # La primera acción de cada episodio se crea con la red neuronal\n",
    "            obs,_=env.reset()\n",
    "\n",
    "            Old_Policy = Policy_net('old_policy', env, obs=obs)\n",
    "\n",
    "            act, v_pred = Old_Policy.act(stochastic=True)\n",
    "\n",
    "            #Convertir de tensor a array\n",
    "            if type(act)=='Tensor':\n",
    "                # Crear una sesión de TensorFlow\n",
    "                sess = tf.compat.v1.Session()\n",
    "\n",
    "                # Evaluar el tensor dentro de la sesión y obtener el resultado como un objeto NumPy ndarray\n",
    "                act = sess.run(act)\n",
    "\n",
    "                # Cerrar la sesión\n",
    "                sess.close()\n",
    "\n",
    "            if isinstance(act, tf.Tensor):\n",
    "                act=act.numpy()\n",
    "\n",
    "            elif isinstance(act, np.ndarray):\n",
    "                act=act\n",
    "\n",
    "\n",
    "            action=int(act)\n",
    "\n",
    "            next_obs,reward,terminated,truncated, info=env.step(action)\n",
    "\n",
    "            truncated=False\n",
    "            terminated=False\n",
    "\n",
    "            # Tenemos una política entrenada\n",
    "            Policy = Policy_net('policy',env, obs=[next_obs])\n",
    "\n",
    "            # Por cada steps en cada episodio, mientras no se llegue a un estado terminal o un estado malo\n",
    "            while terminated!= True and truncated!= True:\n",
    "                # --Aumentar el numero de steps\n",
    "                run_policy_steps += 1\n",
    "\n",
    "                # --Política para ver la acción asociada al estaactiondo\n",
    "                # Las observaciones son un de la forma [[s_0,s_1,s_2,s_3]] por eso su tamaño es (1,4)\n",
    "                observations.append(next_obs)  # S_i-1\n",
    "\n",
    "                action, states_oc = Policy.get_model().predict(next_obs)\n",
    "\n",
    "                action=int(action)\n",
    "\n",
    "                # --Muevo al Agente al siguiente estado\n",
    "                next_obs,reward,terminated,truncated,info=env.step(action)\n",
    "\n",
    "                # --Actualización de variables\n",
    "                actions.append(action) # A_i-1\n",
    "                rewards.append(reward) # R_i-1\n",
    "\n",
    "                # --Si llegamos a un estado final, el juego ha finalizado!!!\n",
    "                # --Se configura el tablero de nuevo\n",
    "                if terminated== True or truncated==True:\n",
    "                    next_observations.append(next_obs)  # S_i\n",
    "                    obs = env.reset()\n",
    "                    reward = -1\n",
    "                else:\n",
    "                    next_observations.append(next_obs)  # S_i\n",
    "                    self.obs = next_obs\n",
    "\n",
    "\n",
    "\n",
    "        observations = np.reshape(observations, newshape=[-1] + list(ob_space.shape))\n",
    "        next_observations = np.reshape(next_observations, newshape=[-1] + list(ob_space.shape))\n",
    "        actions = np.array(actions).astype(dtype=np.int32)\n",
    "        \n",
    "        # Devolvemos la secuencia (S,A,S',R) junto con la política anterior y la actual política,\n",
    "        return observations, actions, next_observations, rewards, Old_Policy, Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################\n",
    "# Clase PPOTrain\n",
    "##########################################################################################################\n",
    "# Tenemos dos politica theta_i y theta_i+1\n",
    "# Almacenamos dos políticas Policy_net(cada una de ella con su PPO) y calculamos el valor gaes a partir de valores gamma, clip_value, c_1, c_2\n",
    "# Realizamos aqui el entrenamiento, cálculo de gradiente y función de pérdida del PPO para después usarlo en el generador de la GAN\n",
    "\n",
    "class PPOTrain:\n",
    "\n",
    "    def __init__(self, Policy, Old_Policy, obs, actions, rewards, gamma=0.95, clip_value=0.2, c_1=1, c_2=0.01):\n",
    "        \"\"\"\n",
    "        arg:\n",
    "            Policy\n",
    "            Old_Policy\n",
    "            gamma\n",
    "            clip_value\n",
    "            c_1 parámetro para la diferencia de valores\n",
    "            c_2 parámetro para el bonus de entropía\n",
    "        \"\"\"\n",
    "        self.Policy = Policy\n",
    "        self.Old_Policy = Old_Policy\n",
    "        self.gamma = gamma\n",
    "        self.obs=obs\n",
    "\n",
    "        self.pi_trainable = self.Policy.get_trainable_variables()\n",
    "        self.old_pi_trainable = self.Old_Policy.get_trainable_variables()\n",
    "\n",
    "\n",
    "        policy_name = \"policy\"\n",
    "        old_policy_name=\"policy\"\n",
    "\n",
    "        policy_dict_ = self.pi_trainable[policy_name]\n",
    "        old_policy_dict_=self.old_pi_trainable[old_policy_name]\n",
    "\n",
    "        self.pi=[]\n",
    "        if policy_name in self.pi_trainable and old_policy_name in self.old_pi_trainable:\n",
    "            for param_name, param_value in policy_dict_.items():\n",
    "                # Elimino los pesos que hay en old_policy\n",
    "                del old_policy_dict_[param_name]\n",
    "                # Introduzco los pesos de old_policy en policy\n",
    "                old_policy_dict_[param_name] = param_value\n",
    "                self.pi.append(param_value)\n",
    "        else:\n",
    "            print(f\"No se encontró la política con el nombre: {policy_name}\")\n",
    "\n",
    "\n",
    "        # Le asignamos old_pi_trainable=pi_trainable ya que ajustaremos unos nuevos pi_trainable\n",
    "\n",
    "\n",
    "        self.actions = actions\n",
    "        self.rewards=rewards\n",
    "        self.v_preds=self.Old_Policy.get_v_preds()\n",
    "        self.v_preds_next=self.Policy.get_v_preds()\n",
    "\n",
    "        #  generative advantage estimator(lambda = 1), ver ppo paper eq(11)\n",
    "        self.gaes =self.get_gaes(self.rewards, self.v_preds, self.v_preds_next)\n",
    "\n",
    "        act_probs =self.Policy.get_action_prob()\n",
    "        act_probs_old =self.Old_Policy.get_action_prob()\n",
    "\n",
    "        # la probabilidad de las acciones del agente cuando toma la actual política\n",
    "        act_probs = act_probs * tf.one_hot(indices=self.actions, depth=act_probs.shape[1])\n",
    "        self.act_probs = tf.reduce_sum(act_probs, axis=1)\n",
    "\n",
    "        # la probabilidad de las acciones del agente cuando toma la antigua política\n",
    "        act_probs_old = act_probs_old * tf.one_hot(indices=self.actions, depth=act_probs_old.shape[1])\n",
    "        self.act_probs_old = tf.reduce_sum(act_probs_old, axis=1)\n",
    "\n",
    "        self.loss=loss_fn_ppo(self.act_probs, self.act_probs_old, self.gaes)\n",
    "\n",
    "        self.optimizer =tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "    def loss_fn_G(self):\n",
    "        return loss_fn_ppo(self.act_probs, self.act_probs_old, self.gaes)\n",
    "\n",
    "    def get_pi_trainable(self):\n",
    "        return self.pi\n",
    "\n",
    "    def get_optimizer(self):\n",
    "        return self.optimizer\n",
    "\n",
    "    def get_OldPolicy(self):\n",
    "        return self.Old_Policy\n",
    "\n",
    "    def get_Policy(self):\n",
    "        return self.Policy\n",
    "\n",
    "    def get_gaes(self, rewards, v_preds, v_preds_next):\n",
    "        deltas = [r_t + self.gamma * v_next - v for r_t, v_next, v in zip(rewards, v_preds_next, v_preds)]\n",
    "        # calcular la estimación generative advantage (lambda = 1), ver ppo paper eq(11)\n",
    "        gaes = copy.deepcopy(deltas)\n",
    "        for t in reversed(range(len(gaes) - 1)):  # # es T-1, donde T es time step con el que se ejecuta la política\n",
    "            gaes[t] = gaes[t] + self.gamma * gaes[t + 1]\n",
    "        return gaes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extended GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################################\n",
    "# CLASE GAIL\n",
    "####################################################################################################################\n",
    "class GAN(keras.Model):\n",
    "    # Constructor\n",
    "    def __init__(self, discriminator, generator):\n",
    "        super().__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator=generator\n",
    "        self.i=0\n",
    "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
    "\n",
    "    # Compila el modelo GAN inicializando los optimizadores y la función de pérdida del modelo GAN\n",
    "    def compile(self,d_optimizer, loss_fn_D ):\n",
    "        super(GAN, self).compile(run_eagerly=True)\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.loss_fn_D=  loss_fn_D\n",
    "\n",
    "    # Devuelve las métricas obtenidas con el generador y discriminador\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric,self.g_loss_metric]\n",
    "\n",
    "    # Evaluación del Discriminador\n",
    "    def evaluate_D(self, X_test):\n",
    "        len_real = X_test.shape[0]\n",
    "\n",
    "        generate_observations, generate_actions, generate_next_observations, rewards, Old_Policy, Policy=self.generator.generate_fakes()\n",
    "\n",
    "        generate_a_one_hot=np.eye(env.action_space.n)[generate_actions]\n",
    "\n",
    "        dataset_gen1=np.concatenate([generate_observations,generate_a_one_hot],axis=1)\n",
    "\n",
    "        dataset_gen2= np.concatenate([dataset_gen1,generate_next_observations], axis=1)\n",
    "\n",
    "        rewards=np.array(rewards).reshape(-1, 1)\n",
    "\n",
    "        dataset_gen= np.concatenate([dataset_gen2,rewards], axis=1)\n",
    "\n",
    "\n",
    "        len_fakes=dataset_gen.shape[0]\n",
    "\n",
    "        # Compilamos el discriminador como CNN\n",
    "        self.discriminator.discriminator_net.compile(optimizer=self.d_optimizer, loss=self.loss_fn_D, metrics=['accuracy'])\n",
    "\n",
    "        # Evaluamos como CNN\n",
    "        loss_real, acc_real=self.discriminator.discriminator_net.evaluate(X_test, tf.ones((len_real,1)), batch_size=len_real, verbose=1)\n",
    "\n",
    "        loss_fake, acc_fake=self.discriminator.discriminator_net.evaluate(dataset_gen,tf.ones((len_fakes,1)), batch_size=len_fakes, verbose=1)\n",
    "\n",
    "        print('>Loss real: ')\n",
    "        print(loss_real)\n",
    "        print('>Loss fake: ')\n",
    "        print(loss_fake)\n",
    "\n",
    "\n",
    "    # Evaluación del generador\n",
    "    def evaluate_G(self):\n",
    "        # Definimos el entorno\n",
    "        env= gym.make('CartPole-v1')\n",
    "\n",
    "        # Lista donde amacenaremos la recompensa acumulada de cada episodio.\n",
    "        # NUESTRO OBJETIVO: Agente aprenda a tomar las acciones que maximicen la recompensa\n",
    "        rewards=[]\n",
    "\n",
    "        # Para cada episodio, el Agente se mueve por el Entorno mediante acciones hasta llegar a un estado final\n",
    "        # siguiendo la política que se ha aprendido en el entrenamiento de la GAN\n",
    "        for episode in range(EPISODES_EVALUATE_G):\n",
    "            truncated=False\n",
    "            terminated=False\n",
    "            R=0.0\n",
    "            reward=0.0\n",
    "\n",
    "            # Estado inicial del juego\n",
    "            obs,_=env.reset()\n",
    "\n",
    "            #Interactuamos con el Entorno hasta que lleguemos a un estado final\n",
    "            while terminated!= True and truncated!=True:\n",
    "                action, _=self.generator.get_model().predict(obs)\n",
    "                obs,reward,terminated,truncated, info=env.step(int(action))\n",
    "\n",
    "                # Incremento la recompensa del episodio i al haber ejecutado el step\n",
    "                R+=reward\n",
    "\n",
    "            rewards.append(R)\n",
    "\n",
    "            # Vemos para el episodio, su recompensa acumulada que es lo que se trata de maximizar\n",
    "            print(\"Episode  {} Total reward: {}\".format(episode,R))\n",
    "\n",
    "        # Cierro el entorno\n",
    "        env.close()\n",
    "\n",
    "        # Muestro las recompensas obtenidas en cada episodio\n",
    "        indices = range(0, EPISODES_EVALUATE_G)\n",
    "        plt.plot(indices,rewards)\n",
    "        plt.show()\n",
    "\n",
    "        return np.mean(rewards)\n",
    "\n",
    "    def train_step(self, X_train):\n",
    "\n",
    "        # 1) Generamos secuencias falsas [s,a,s',r]\n",
    "        generate_observations, generate_actions, generate_next_observations, rewards, Old_Policy, Policy=self.generator.generate_fakes()\n",
    "\n",
    "        generate_a_one_hot=np.eye(env.action_space.n)[generate_actions]\n",
    "\n",
    "\n",
    "        if generate_observations.shape[0] == generate_a_one_hot.shape[0]:\n",
    "          dataset_gen1 = np.concatenate([generate_observations, generate_a_one_hot], axis=1)\n",
    "        else:\n",
    "          generate_a_one_hot_resized = np.resize(generate_a_one_hot,generate_observations.shape)\n",
    "          dataset_gen1 = np.concatenate([generate_observations, generate_a_one_hot_resized], axis=1)\n",
    "\n",
    "        if generate_next_observations.shape[0] == generate_a_one_hot.shape[0]:\n",
    "          dataset_gen2=np.concatenate([dataset_gen1, generate_next_observations], axis=1)\n",
    "        else:\n",
    "           generate_next_observations_new= np.resize(generate_next_observations, generate_observations.shape)\n",
    "           dataset_gen2=np.concatenate([dataset_gen1, generate_next_observations_new], axis=1)\n",
    "\n",
    "        rewards=np.array(rewards).reshape(-1,1)\n",
    "\n",
    "        \n",
    "        dataset_gen=np.concatenate([dataset_gen2, rewards], axis=1)\n",
    "        \n",
    "        \n",
    "        # 2) Seleccionamos la muestra de datos generador con la que vamos a trabajar en este  batch de entrenamiento \n",
    "        #if len(dataset_gen) >= BATCH_SIZE: \n",
    "        random_indices = np.random.choice(len(dataset_gen), size=min(BATCH_SIZE,len(dataset_gen)), replace=False)\n",
    "        dataset_gen= dataset_gen[random_indices[0]]\n",
    "    \n",
    "    \n",
    "        # 3) Obtenemos las secuencias reales [s,a,s',r] de los datos de entrenamiento y las combinamos\n",
    "        dataset_gen=dataset_gen.reshape(1,-1)\n",
    "        combined_images = tf.concat([X_train, dataset_gen], axis=0)\n",
    "\n",
    "\n",
    "        # 4) Las etiquetas de las imagenes combinadas las tenemos que crear nosotros introduciendo algo de ruido con tf.random.uniform\n",
    "        labels = tf.concat( [tf.ones((BATCH_SIZE, 1)), tf.zeros((BATCH_SIZE, 1))], axis=0 )\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "\n",
    "        ##############################################################################################################################################################\n",
    "        # PASO 1:  ENTRENAMIENTO DEL DISCRIMINADOR\n",
    "        #############################################################################################################################################################\n",
    "\n",
    "\n",
    "        # Entrenamiento del discriminador con las [s,a, s', r] del agente(falsas o sintéticas) y del experto (reales) combinadas, esto es,\n",
    "        # le pasamos un conjunto que tiene tanto secuencias reales como secuencias sintéticas\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions=np.zeros((2*BATCH_SIZE,6))\n",
    "            # Predicciones obtenidas con el discriminador\n",
    "            predictions = self.discriminator.discriminator_net(combined_images)\n",
    "            # Valor de la función de pérdida al comparar las predicciones con las etiquetas reales\n",
    "            d_loss = self.loss_fn_D(labels, predictions)\n",
    "\n",
    "        # Calculo del gradiente y actualización del gradiente\n",
    "        grads = tape.gradient(d_loss, self.discriminator.getNet().trainable_weights)\n",
    "\n",
    "        self.d_optimizer.apply_gradients(\n",
    "          zip(grads, self.discriminator.getNet().trainable_weights)\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        ################################################################################################################################################################\n",
    "        # PASO 2: ENTRENAMIENTO DEL GENERADOR=POLÍTICA\n",
    "        ###############################################################################################################################################################\n",
    "\n",
    "\n",
    "        ppotrain=PPOTrain(Policy,Old_Policy,actions=generate_actions,rewards=rewards, obs=generate_observations) #       generate_observations[0])\n",
    "\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            g_loss = ppotrain.loss_fn_G()\n",
    "\n",
    "\n",
    "        g_loss = tf.cast(g_loss, dtype=tf.float32)\n",
    "\n",
    "        \n",
    "        \n",
    "        ############################################################################################################################################################\n",
    "\n",
    "        # Actualización de métricas del discriminador y generador\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        print(\"\\n\")\n",
    "        print(\"\\nd_loss=\",d_loss.numpy())\n",
    "        print(\"\\ng_loss=\",g_loss.numpy())\n",
    "\n",
    "\n",
    "\n",
    "        return {\"d_loss\": self.d_loss_metric.result(),\n",
    "                    \"g_loss\": self.g_loss_metric.result()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentación de GAIL con CartPole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción de base de datos experta con 1 trayectoria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEstados reales: \n",
      " [[ 0.00572823 -0.03831238  0.03101629  0.00900886]\n",
      " [ 0.00496198  0.15635134  0.03119646 -0.27372897]\n",
      " [ 0.00808901 -0.03920152  0.02572188  0.02862788]\n",
      " ...\n",
      " [-0.03035956 -0.1520803   0.0103268   0.24866116]\n",
      " [-0.03340117  0.04289266  0.01530002 -0.04074667]\n",
      " [-0.03254332  0.23779191  0.01448509 -0.3285633 ]]\n",
      "\tAcciones reales: \n",
      " [1 0 1 ... 1 1 0]\n",
      "\n",
      "\t Estados siguientes: \n",
      " [[ 0.00572823 -0.03831238  0.03101629  0.00900886]\n",
      " [ 0.00496198  0.15635134  0.03119646 -0.27372897]\n",
      " [ 0.00808901 -0.03920152  0.02572188  0.02862788]\n",
      " ...\n",
      " [-0.03035956 -0.1520803   0.0103268   0.24866116]\n",
      " [-0.03340117  0.04289266  0.01530002 -0.04074667]\n",
      " [-0.03254332  0.23779191  0.01448509 -0.3285633 ]]\n",
      "\n",
      "\t Recompensas: [1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "expert_observations = np.genfromtxt(\"observations_CartPole_.csv\",delimiter=\"\\t\",dtype=str)\n",
    "expert_actions = np.genfromtxt('actions_CartPole_.csv', dtype=np.int32)\n",
    "expert_next_observations = np.genfromtxt('next_observations_CartPole_.csv',delimiter=\"\\t\",dtype=str)\n",
    "expert_rewards = np.genfromtxt('rewards_CartPole_.csv', dtype=np.int32)\n",
    "expert_num_tray=np.genfromtxt('n_trayectoria_CartPole_.csv', dtype=np.int32)\n",
    "\n",
    "# Reemplazar las comas\n",
    "expert_observations = np.core.defchararray.replace(expert_observations, ',', ' ')\n",
    "\n",
    "# Reemplazar las comas\n",
    "expert_next_observations = np.core.defchararray.replace(expert_next_observations, ',', ' ')\n",
    "\n",
    "# Crear un nuevo array para almacenar los datos convertidos\n",
    "converted_observations = np.genfromtxt(expert_observations, delimiter=' ', dtype=float)\n",
    "# Crear un nuevo array para almacenar los datos convertidos\n",
    "converted_next_observations = np.genfromtxt(expert_observations, delimiter=' ', dtype=float)\n",
    "\n",
    "\n",
    "rewards=np.array(expert_rewards).reshape(-1,1)\n",
    "\n",
    "\n",
    "print(\"\\n\\tEstados reales: \\n\", converted_observations)\n",
    "print(\"\\tAcciones reales: \\n\", expert_actions)\n",
    "print(\"\\n\\t Estados siguientes: \\n\", converted_next_observations)\n",
    "print(\"\\n\\t Recompensas:\" ,expert_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "longitud_trayectoria = np.count_nonzero(expert_num_tray == 0)\n",
    "print(longitud_trayectoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos quedamos solo con la primera trayectoria\n",
    "converted_observations=converted_observations[0:longitud_trayectoria]\n",
    "expert_actions=expert_actions[0:longitud_trayectoria]\n",
    "converted_next_observations=converted_next_observations[0:longitud_trayectoria]\n",
    "expert_rewards=expert_rewards[0:longitud_trayectoria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el dataset [s,a,s',r] reales y lo dividimos en training y test\n",
    "expert_a_one_hot=np.eye(env.action_space.n)[expert_actions]\n",
    "expert_rewards = expert_rewards.reshape(-1, 1)\n",
    "\n",
    "dataset1=np.concatenate([converted_observations,expert_a_one_hot],axis=1)\n",
    "dataset2=np.concatenate([dataset1,converted_next_observations],axis=1)\n",
    "dataset=np.concatenate([dataset2,expert_rewards],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento: 400\n",
      "Nº de (ESTADOS,ACCIONES) en el conjunto de prueba: 100\n"
     ]
    }
   ],
   "source": [
    "#############################################################################\n",
    "# DIVISIÓN TRAIN Y TEST\n",
    "##############################################################################\n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test = train_test_split(dataset, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "#Imprime el número de elementos en el conjuntos de entrenamiento y prueba\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento:', len(X_train))\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de prueba:', len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:107: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "env= gym.make('CartPole-v1')\n",
    "obs,_= env.reset()\n",
    "\n",
    "# Generador\n",
    "generator=Policy_net( 'policy', env, obs)\n",
    "\n",
    "# Generamos [s,a, s', r] falsas y las políticas theta_i y theta_i+1\n",
    "observations, actions, next_observations, rewards, Old_Policy, Policy=generator.generate_fakes()\n",
    "\n",
    "# Discriminador\n",
    "discriminator=Discriminator(env, discriminator_net, converted_observations, expert_actions, converted_next_observations, expert_rewards, observations, actions, next_observations, rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan1=GAN(discriminator=discriminator,generator=generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "gan1.compile(\n",
    "    d_optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss_fn_D=loss_fn_D\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "d_loss= 2.5417097\n",
      "\n",
      "g_loss= -0.923686\n",
      "1/5 [=====>........................] - ETA: 29:45 - d_loss: 2.5417 - g_loss: -0.9237\n",
      "\n",
      "\n",
      "d_loss= 2.5498085\n",
      "\n",
      "g_loss= -0.71743166\n",
      "2/5 [===========>..................] - ETA: 22:47 - d_loss: 2.5458 - g_loss: -0.8206\n",
      "\n",
      "\n",
      "d_loss= 2.5695267\n",
      "\n",
      "g_loss= -0.7050891\n",
      "3/5 [=================>............] - ETA: 15:00 - d_loss: 2.5537 - g_loss: -0.7821\n",
      "\n",
      "\n",
      "d_loss= 2.527727\n",
      "\n",
      "g_loss= -0.8899074\n",
      "4/5 [=======================>......] - ETA: 7:30 - d_loss: 2.5472 - g_loss: -0.8090 \n",
      "\n",
      "\n",
      "d_loss= 2.545199\n",
      "\n",
      "g_loss= -1.34268\n",
      "5/5 [==============================] - 2237s 448s/step - d_loss: 2.5468 - g_loss: -0.9158\n"
     ]
    }
   ],
   "source": [
    "# Deshabilitar los mensajes de información de TensorFlow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Deshabilitar los mensajes de información de OpenAI Gym\n",
    "gym.logger.set_level(40)\n",
    "\n",
    "history=gan1.fit(X_train,\n",
    "    epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6367 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6234 - accuracy: 0.0022\n",
      ">Loss real: \n",
      "0.6366761922836304\n",
      ">Loss fake: \n",
      "0.6233932971954346\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos el Discriminador de GAIL en el TEST\n",
    "gan1.evaluate_D(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  0 Total reward: 500.0\n",
      "Episode  1 Total reward: 500.0\n",
      "Episode  2 Total reward: 500.0\n",
      "Episode  3 Total reward: 500.0\n",
      "Episode  4 Total reward: 500.0\n",
      "Episode  5 Total reward: 500.0\n",
      "Episode  6 Total reward: 500.0\n",
      "Episode  7 Total reward: 500.0\n",
      "Episode  8 Total reward: 500.0\n",
      "Episode  9 Total reward: 500.0\n",
      "Episode  10 Total reward: 500.0\n",
      "Episode  11 Total reward: 500.0\n",
      "Episode  12 Total reward: 500.0\n",
      "Episode  13 Total reward: 500.0\n",
      "Episode  14 Total reward: 500.0\n",
      "Episode  15 Total reward: 500.0\n",
      "Episode  16 Total reward: 500.0\n",
      "Episode  17 Total reward: 500.0\n",
      "Episode  18 Total reward: 500.0\n",
      "Episode  19 Total reward: 500.0\n",
      "Episode  20 Total reward: 500.0\n",
      "Episode  21 Total reward: 500.0\n",
      "Episode  22 Total reward: 500.0\n",
      "Episode  23 Total reward: 500.0\n",
      "Episode  24 Total reward: 500.0\n",
      "Episode  25 Total reward: 500.0\n",
      "Episode  26 Total reward: 500.0\n",
      "Episode  27 Total reward: 500.0\n",
      "Episode  28 Total reward: 500.0\n",
      "Episode  29 Total reward: 500.0\n",
      "Episode  30 Total reward: 500.0\n",
      "Episode  31 Total reward: 500.0\n",
      "Episode  32 Total reward: 500.0\n",
      "Episode  33 Total reward: 500.0\n",
      "Episode  34 Total reward: 500.0\n",
      "Episode  35 Total reward: 500.0\n",
      "Episode  36 Total reward: 500.0\n",
      "Episode  37 Total reward: 500.0\n",
      "Episode  38 Total reward: 500.0\n",
      "Episode  39 Total reward: 500.0\n",
      "Episode  40 Total reward: 500.0\n",
      "Episode  41 Total reward: 500.0\n",
      "Episode  42 Total reward: 500.0\n",
      "Episode  43 Total reward: 500.0\n",
      "Episode  44 Total reward: 500.0\n",
      "Episode  45 Total reward: 500.0\n",
      "Episode  46 Total reward: 500.0\n",
      "Episode  47 Total reward: 500.0\n",
      "Episode  48 Total reward: 500.0\n",
      "Episode  49 Total reward: 500.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recompensa de Media: 500.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos al Generador \n",
    "rewardMean=gan1.evaluate_G()\n",
    "print('\\nRecompensa de Media:', rewardMean, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción de base de datos experta con 2 trayectoria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEstados reales: \n",
      " [[ 0.00572823 -0.03831238  0.03101629  0.00900886]\n",
      " [ 0.00496198  0.15635134  0.03119646 -0.27372897]\n",
      " [ 0.00808901 -0.03920152  0.02572188  0.02862788]\n",
      " ...\n",
      " [-0.03035956 -0.1520803   0.0103268   0.24866116]\n",
      " [-0.03340117  0.04289266  0.01530002 -0.04074667]\n",
      " [-0.03254332  0.23779191  0.01448509 -0.3285633 ]]\n",
      "\tAcciones reales: \n",
      " [1 0 1 ... 1 1 0]\n",
      "\n",
      "\t Estados siguientes: \n",
      " [[ 0.00572823 -0.03831238  0.03101629  0.00900886]\n",
      " [ 0.00496198  0.15635134  0.03119646 -0.27372897]\n",
      " [ 0.00808901 -0.03920152  0.02572188  0.02862788]\n",
      " ...\n",
      " [-0.03035956 -0.1520803   0.0103268   0.24866116]\n",
      " [-0.03340117  0.04289266  0.01530002 -0.04074667]\n",
      " [-0.03254332  0.23779191  0.01448509 -0.3285633 ]]\n",
      "\n",
      "\t Recompensas: [1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "expert_observations = np.genfromtxt(\"observations_CartPole_.csv\",delimiter=\"\\t\",dtype=str)\n",
    "expert_actions = np.genfromtxt('actions_CartPole_.csv', dtype=np.int32)\n",
    "expert_next_observations = np.genfromtxt('next_observations_CartPole_.csv',delimiter=\"\\t\",dtype=str)\n",
    "expert_rewards = np.genfromtxt('rewards_CartPole_.csv', dtype=np.int32)\n",
    "expert_num_tray=np.genfromtxt('n_trayectoria_CartPole_.csv', dtype=np.int32)\n",
    "\n",
    "# Reemplazar las comas\n",
    "expert_observations = np.core.defchararray.replace(expert_observations, ',', ' ')\n",
    "\n",
    "# Reemplazar las comas\n",
    "expert_next_observations = np.core.defchararray.replace(expert_next_observations, ',', ' ')\n",
    "\n",
    "# Crear un nuevo array para almacenar los datos convertidos\n",
    "converted_observations = np.genfromtxt(expert_observations, delimiter=' ', dtype=float)\n",
    "# Crear un nuevo array para almacenar los datos convertidos\n",
    "converted_next_observations = np.genfromtxt(expert_observations, delimiter=' ', dtype=float)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\\tEstados reales: \\n\", converted_observations)\n",
    "print(\"\\tAcciones reales: \\n\", expert_actions)\n",
    "print(\"\\n\\t Estados siguientes: \\n\", converted_next_observations)\n",
    "print(\"\\n\\t Recompensas:\" ,expert_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "longitud_trayectoria += np.count_nonzero(expert_num_tray == 1)\n",
    "print(longitud_trayectoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos quedamos solo con la primera trayectoria\n",
    "converted_observations=converted_observations[0:longitud_trayectoria]\n",
    "expert_actions=expert_actions[0:longitud_trayectoria]\n",
    "converted_next_observations=converted_next_observations[0:longitud_trayectoria]\n",
    "expert_rewards=expert_rewards[0:longitud_trayectoria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el dataset [s,a,s',r] reales y lo dividimos en training y test\n",
    "expert_a_one_hot=np.eye(env.action_space.n)[expert_actions]\n",
    "expert_rewards = expert_rewards.reshape(-1, 1)\n",
    "\n",
    "dataset1=np.concatenate([converted_observations,expert_a_one_hot],axis=1)\n",
    "dataset2=np.concatenate([dataset1,converted_next_observations],axis=1)\n",
    "dataset=np.concatenate([dataset2,expert_rewards],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento: 800\n",
      "Nº de (ESTADOS,ACCIONES) en el conjunto de prueba: 200\n"
     ]
    }
   ],
   "source": [
    "#############################################################################\n",
    "# DIVISIÓN TRAIN Y TEST\n",
    "##############################################################################\n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test = train_test_split(dataset, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "#Imprime el número de elementos en el conjuntos de entrenamiento y prueba\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento:', len(X_train))\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de prueba:', len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "env= gym.make('CartPole-v1')\n",
    "obs,_= env.reset()\n",
    "\n",
    "# Generador\n",
    "generator=Policy_net( 'policy', env, obs)\n",
    "\n",
    "# Generamos [s,a, s', r] falsas y las políticas theta_i y theta_i+1\n",
    "observations, actions, next_observations, rewards, Old_Policy, Policy=generator.generate_fakes()\n",
    "\n",
    "# Discriminador\n",
    "discriminator=Discriminator(env, discriminator_net, converted_observations, expert_actions, converted_next_observations, expert_rewards, observations, actions, next_observations, rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan2=GAN(discriminator=discriminator,generator=generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "gan2.compile(\n",
    "    d_optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss_fn_D=loss_fn_D\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "d_loss= 2.5328155\n",
      "\n",
      "g_loss= -0.99532294\n",
      "1/9 [==>...........................] - ETA: 59:57 - d_loss: 2.5328 - g_loss: -0.9953\n",
      "\n",
      "\n",
      "d_loss= 2.5276651\n",
      "\n",
      "g_loss= -0.7143962\n",
      "2/9 [=====>........................] - ETA: 53:18 - d_loss: 2.5302 - g_loss: -0.8549\n",
      "\n",
      "\n",
      "d_loss= 2.5338128\n",
      "\n",
      "g_loss= -0.74782234\n",
      "3/9 [=========>....................] - ETA: 44:50 - d_loss: 2.5314 - g_loss: -0.8192\n",
      "\n",
      "\n",
      "d_loss= 2.4787378\n",
      "\n",
      "g_loss= -1.2698044\n",
      "4/9 [============>.................] - ETA: 37:05 - d_loss: 2.5183 - g_loss: -0.9318\n",
      "\n",
      "\n",
      "d_loss= 2.5274987\n",
      "\n",
      "g_loss= -1.0412686\n",
      "5/9 [===============>..............] - ETA: 29:33 - d_loss: 2.5201 - g_loss: -0.9537\n",
      "\n",
      "\n",
      "d_loss= 2.5560112\n",
      "\n",
      "g_loss= -1.5757942\n",
      "6/9 [===================>..........] - ETA: 22:09 - d_loss: 2.5261 - g_loss: -1.0574\n",
      "\n",
      "\n",
      "d_loss= 2.474061\n",
      "\n",
      "g_loss= -0.47336268\n",
      "7/9 [======================>.......] - ETA: 14:47 - d_loss: 2.5187 - g_loss: -0.9740\n",
      "\n",
      "\n",
      "d_loss= 2.4994695\n",
      "\n",
      "g_loss= -0.4302683\n",
      "8/9 [=========================>....] - ETA: 7:23 - d_loss: 2.5163 - g_loss: -0.9060 \n",
      "\n",
      "\n",
      "d_loss= 2.5060213\n",
      "\n",
      "g_loss= -0.7377126\n",
      "9/9 [==============================] - 3993s 443s/step - d_loss: 2.5151 - g_loss: -0.8873\n"
     ]
    }
   ],
   "source": [
    "# Deshabilitar los mensajes de información de TensorFlow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Deshabilitar los mensajes de información de OpenAI Gym\n",
    "gym.logger.set_level(40)\n",
    "\n",
    "history=gan2.fit(X_train,\n",
    "    epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6141 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6110 - accuracy: 0.0000e+00\n",
      ">Loss real: \n",
      "0.6140761375427246\n",
      ">Loss fake: \n",
      "0.61102294921875\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos el Discriminador de GAIL en el TEST\n",
    "gan2.evaluate_D(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  0 Total reward: 500.0\n",
      "Episode  1 Total reward: 500.0\n",
      "Episode  2 Total reward: 500.0\n",
      "Episode  3 Total reward: 500.0\n",
      "Episode  4 Total reward: 500.0\n",
      "Episode  5 Total reward: 500.0\n",
      "Episode  6 Total reward: 500.0\n",
      "Episode  7 Total reward: 500.0\n",
      "Episode  8 Total reward: 500.0\n",
      "Episode  9 Total reward: 500.0\n",
      "Episode  10 Total reward: 500.0\n",
      "Episode  11 Total reward: 500.0\n",
      "Episode  12 Total reward: 500.0\n",
      "Episode  13 Total reward: 500.0\n",
      "Episode  14 Total reward: 500.0\n",
      "Episode  15 Total reward: 500.0\n",
      "Episode  16 Total reward: 500.0\n",
      "Episode  17 Total reward: 500.0\n",
      "Episode  18 Total reward: 500.0\n",
      "Episode  19 Total reward: 500.0\n",
      "Episode  20 Total reward: 500.0\n",
      "Episode  21 Total reward: 500.0\n",
      "Episode  22 Total reward: 500.0\n",
      "Episode  23 Total reward: 500.0\n",
      "Episode  24 Total reward: 500.0\n",
      "Episode  25 Total reward: 500.0\n",
      "Episode  26 Total reward: 500.0\n",
      "Episode  27 Total reward: 500.0\n",
      "Episode  28 Total reward: 500.0\n",
      "Episode  29 Total reward: 500.0\n",
      "Episode  30 Total reward: 500.0\n",
      "Episode  31 Total reward: 500.0\n",
      "Episode  32 Total reward: 500.0\n",
      "Episode  33 Total reward: 500.0\n",
      "Episode  34 Total reward: 500.0\n",
      "Episode  35 Total reward: 500.0\n",
      "Episode  36 Total reward: 500.0\n",
      "Episode  37 Total reward: 500.0\n",
      "Episode  38 Total reward: 500.0\n",
      "Episode  39 Total reward: 500.0\n",
      "Episode  40 Total reward: 500.0\n",
      "Episode  41 Total reward: 500.0\n",
      "Episode  42 Total reward: 500.0\n",
      "Episode  43 Total reward: 500.0\n",
      "Episode  44 Total reward: 500.0\n",
      "Episode  45 Total reward: 500.0\n",
      "Episode  46 Total reward: 500.0\n",
      "Episode  47 Total reward: 500.0\n",
      "Episode  48 Total reward: 500.0\n",
      "Episode  49 Total reward: 500.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAeiklEQVR4nO3dfWyV9f3/8dfp3Sk3PecAlh46WpQwKAXKBGY5G2zGdhTomFMiSjoljsBkxXEzDLLpqJpY4syWiQ68i7iErYILTpkyiwhMKAgFZkVGgKDUtIdOm/a0IKW01/cPf5ztTPTHoS3n3e75SK6EXnfnc33ScJ65evXU5TiOIwAAAEPiYj0AAACA/0agAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwJyEWA/gSrS3t6umpkYpKSlyuVyxHg4AALgMjuOoqalJ6enpiov76nsk3TJQampqlJGREethAACAK1BdXa3Bgwd/5T7dMlBSUlIkfX6BHo8nxqMBAACXIxQKKSMjI/w+/lW6ZaBc/LGOx+MhUAAA6GYu5/EMHpIFAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJgTVaCUlJTI5XJFLFlZWZKk+vp63XvvvRoxYoR69eqlzMxM/exnP1NjY2PEOU6dOqXCwkL17t1bAwcO1H333acLFy503hUBAIBuLyHaA0aNGqWtW7f++wQJn5+ipqZGNTU1evzxx5Wdna2PPvpI99xzj2pqavTyyy9Lktra2lRYWCi/36/du3ertrZWd911lxITE/Xoo4920iUBAIDuzuU4jnO5O5eUlOiVV17RoUOHLmv/jRs36kc/+pHOnDmjhIQEvfHGG/r+97+vmpoapaWlSZLWrl2r5cuX61//+peSkpIu67yhUEher1eNjY3yeDyXO3wAABBD0bx/R/0MyrFjx5Senq6hQ4eqqKhIp06d+tJ9Lw7g4l2WiooKjRkzJhwnklRQUKBQKKTDhw9/6XlaWloUCoUiFgAA0HNFFSi5ublat26dtmzZojVr1ujkyZOaPHmympqavrDvJ598okceeUTz588PrwsGgxFxIin8dTAY/NLXLS0tldfrDS8ZGRnRDBsAAHQzUQXKtGnTdNtttyknJ0cFBQV6/fXX1dDQoA0bNkTsFwqFVFhYqOzsbJWUlHR4kCtWrFBjY2N4qa6u7vA5AQCAXVE/JPuffD6fhg8fruPHj4fXNTU1aerUqUpJSdGmTZuUmJgY3ub3+/Xuu+9GnOP06dPhbV/G7XbL7XZ3ZKgAAKAb6dDnoDQ3N+vEiRMaNGiQpM/vnEyZMkVJSUl69dVXlZycHLF/IBBQVVWV6urqwuvKy8vl8XiUnZ3dkaEAAIAeJKpAWbZsmXbs2KEPP/xQu3fv1i233KL4+HjNnj07HCdnzpzR888/r1AopGAwqGAwqLa2NknSlClTlJ2drTvvvFP/+Mc/9Le//U0PPPCAiouLuUMCAADCovoRz8cff6zZs2fr008/VWpqqiZNmqQ9e/YoNTVV27dv1969eyVJw4YNizju5MmTuvbaaxUfH6/NmzdrwYIFCgQC6tOnj+bMmaOHH364864IAAB0e1F9DooVfA4KAADdT5d+DgoAAEBXI1AAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgTlSBUlJSIpfLFbFkZWWFtz/zzDO68cYb5fF45HK51NDQ8IVz1NfXq6ioSB6PRz6fT3PnzlVzc3OHLwQAAPQcUd9BGTVqlGpra8PLO++8E9529uxZTZ06Vb/4xS++9PiioiIdPnxY5eXl2rx5s3bu3Kn58+df2egBAECPlBD1AQkJ8vv9l9y2ePFiSdL27dsvuf3IkSPasmWL9u3bpwkTJkiSVq9erenTp+vxxx9Xenp6tMMBAAA9UNR3UI4dO6b09HQNHTpURUVFOnXq1GUfW1FRIZ/PF44TScrPz1dcXJz27t37pce1tLQoFApFLAAAoOeKKlByc3O1bt06bdmyRWvWrNHJkyc1efJkNTU1XdbxwWBQAwcOjFiXkJCg/v37KxgMfulxpaWl8nq94SUjIyOaYQMAgG4mqkCZNm2abrvtNuXk5KigoECvv/66GhoatGHDhq4anyRpxYoVamxsDC/V1dVd+noAACC2on4G5T/5fD4NHz5cx48fv6z9/X6/6urqItZduHBB9fX1X/pciyS53W653e6ODBUAAHQjHfoclObmZp04cUKDBg26rP0DgYAaGhpUWVkZXrdt2za1t7crNze3I0MBAAA9SFR3UJYtW6YZM2ZoyJAhqqmp0cqVKxUfH6/Zs2dL+vwZk2AwGL6jUlVVpZSUFGVmZqp///4aOXKkpk6dqnnz5mnt2rVqbW3VwoULdccdd/AbPAAAICyqOygff/yxZs+erREjRmjWrFkaMGCA9uzZo9TUVEnS2rVrdf3112vevHmSpO985zu6/vrr9eqrr4bPsX79emVlZSkvL0/Tp0/XpEmT9Mwzz3TiJQEAgO7O5TiOE+tBRCsUCsnr9aqxsVEejyfWwwEAAJchmvdv/hYPAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOVEFSklJiVwuV8SSlZUV3n7u3DkVFxdrwIAB6tu3r2bOnKnTp09HnOPUqVMqLCxU7969NXDgQN133326cOFC51wNAADoERKiPWDUqFHaunXrv0+Q8O9TLFmyRH/961+1ceNGeb1eLVy4ULfeeqt27dolSWpra1NhYaH8fr92796t2tpa3XXXXUpMTNSjjz7aCZcDAAB6gqgDJSEhQX6//wvrGxsb9fzzz+uPf/yjbrrpJknSCy+8oJEjR2rPnj2aOHGi3nzzTX3wwQfaunWr0tLS9I1vfEOPPPKIli9frpKSEiUlJXX8ijrAcRx91toW0zEAAGBFr8R4uVyumLx21IFy7NgxpaenKzk5WYFAQKWlpcrMzFRlZaVaW1uVn58f3jcrK0uZmZmqqKjQxIkTVVFRoTFjxigtLS28T0FBgRYsWKDDhw/r+uuvv+RrtrS0qKWlJfx1KBSKdtiX5bPWNmX/6m9dcm4AALqbDx4uUO+kqFOhU0T1DEpubq7WrVunLVu2aM2aNTp58qQmT56spqYmBYNBJSUlyefzRRyTlpamYDAoSQoGgxFxcnH7xW1fprS0VF6vN7xkZGREM2wAANDNRJVF06ZNC/87JydHubm5GjJkiDZs2KBevXp1+uAuWrFihZYuXRr+OhQKdUmk9EqM1wcPF3T6eQEA6I56JcbH7LU7dN/G5/Np+PDhOn78uL73ve/p/PnzamhoiLiLcvr06fAzK36/X++++27EOS7+ls+lnmu5yO12y+12d2Sol8XlcsXsVhYAAPi3Dn0OSnNzs06cOKFBgwZp/PjxSkxM1FtvvRXefvToUZ06dUqBQECSFAgEVFVVpbq6uvA+5eXl8ng8ys7O7shQAABADxLV7YJly5ZpxowZGjJkiGpqarRy5UrFx8dr9uzZ8nq9mjt3rpYuXar+/fvL4/Ho3nvvVSAQ0MSJEyVJU6ZMUXZ2tu6880499thjCgaDeuCBB1RcXHxV7pAAAIDuIapA+fjjjzV79mx9+umnSk1N1aRJk7Rnzx6lpqZKkn77298qLi5OM2fOVEtLiwoKCvT73/8+fHx8fLw2b96sBQsWKBAIqE+fPpozZ44efvjhzr0qAADQrbkcx3FiPYhohUIheb1eNTY2yuPxxHo4AADgMkTz/s3f4gEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOZ0KFBWrVoll8ulxYsXh9edOHFCt9xyi1JTU+XxeDRr1iydPn064rj6+noVFRXJ4/HI5/Np7ty5am5u7shQAABAD3LFgbJv3z49/fTTysnJCa87c+aMpkyZIpfLpW3btmnXrl06f/68ZsyYofb29vB+RUVFOnz4sMrLy7V582bt3LlT8+fP79iVAACAHuOKAqW5uVlFRUV69tln1a9fv/D6Xbt26cMPP9S6des0ZswYjRkzRi+++KL279+vbdu2SZKOHDmiLVu26LnnnlNubq4mTZqk1atXq6ysTDU1NZ1zVQAAoFu7okApLi5WYWGh8vPzI9a3tLTI5XLJ7XaH1yUnJysuLk7vvPOOJKmiokI+n08TJkwI75Ofn6+4uDjt3bv3kq/X0tKiUCgUsQAAgJ4r6kApKyvTgQMHVFpa+oVtEydOVJ8+fbR8+XKdPXtWZ86c0bJly9TW1qba2lpJUjAY1MCBAyOOS0hIUP/+/RUMBi/5mqWlpfJ6veElIyMj2mEDAIBuJKpAqa6u1qJFi7R+/XolJyd/YXtqaqo2btyo1157TX379pXX61VDQ4PGjRunuLgrfx53xYoVamxsDC/V1dVXfC4AAGBfQjQ7V1ZWqq6uTuPGjQuva2tr086dO/Xkk0+qpaVFU6ZM0YkTJ/TJJ58oISFBPp9Pfr9fQ4cOlST5/X7V1dVFnPfChQuqr6+X3++/5Ou63e6IHxsBAICeLapAycvLU1VVVcS6u+++W1lZWVq+fLni4+PD66+55hpJ0rZt21RXV6cf/OAHkqRAIKCGhgZVVlZq/Pjx4X3a29uVm5vboYsBAAA9Q1SBkpKSotGjR0es69OnjwYMGBBe/8ILL2jkyJFKTU1VRUWFFi1apCVLlmjEiBGSpJEjR2rq1KmaN2+e1q5dq9bWVi1cuFB33HGH0tPTO+myAABAdxZVoFyOo0ePasWKFaqvr9e1116rX/7yl1qyZEnEPuvXr9fChQuVl5enuLg4zZw5U0888URnDwUAAHRTLsdxnFgPIlqhUEher1eNjY3yeDyxHg4AALgM0bx/87d4AACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzCFQAACAOQQKAAAwh0ABAADmECgAAMAcAgUAAJhDoAAAAHMIFAAAYA6BAgAAzOlQoKxatUoul0uLFy8OrwsGg7rzzjvl9/vVp08fjRs3Tn/+858jjquvr1dRUZE8Ho98Pp/mzp2r5ubmjgwFAAD0IFccKPv27dPTTz+tnJyciPV33XWXjh49qldffVVVVVW69dZbNWvWLB08eDC8T1FRkQ4fPqzy8nJt3rxZO3fu1Pz586/8KgAAQI9yRYHS3NysoqIiPfvss+rXr1/Ett27d+vee+/VDTfcoKFDh+qBBx6Qz+dTZWWlJOnIkSPasmWLnnvuOeXm5mrSpElavXq1ysrKVFNT0/ErAgAA3d4VBUpxcbEKCwuVn5//hW3f+ta39NJLL6m+vl7t7e0qKyvTuXPndOONN0qSKioq5PP5NGHChPAx+fn5iouL0969ey/5ei0tLQqFQhELAADouRKiPaCsrEwHDhzQvn37Lrl9w4YNuv322zVgwAAlJCSod+/e2rRpk4YNGybp82dUBg4cGDmIhAT1799fwWDwkucsLS3VQw89FO1QAQBANxXVHZTq6motWrRI69evV3Jy8iX3efDBB9XQ0KCtW7dq//79Wrp0qWbNmqWqqqorHuSKFSvU2NgYXqqrq6/4XAAAwL6o7qBUVlaqrq5O48aNC69ra2vTzp079eSTT+ro0aN68skn9f7772vUqFGSpLFjx+rvf/+7nnrqKa1du1Z+v191dXUR571w4YLq6+vl9/sv+bput1tutzvaawMAAN1UVIGSl5f3hTshd999t7KysrR8+XKdPXtWkhQXF3ljJj4+Xu3t7ZKkQCCghoYGVVZWavz48ZKkbdu2qb29Xbm5uVd8IQAAoOeIKlBSUlI0evToiHV9+vTRgAEDNHr0aLW2tmrYsGH6yU9+oscff1wDBgzQK6+8Ev51YkkaOXKkpk6dqnnz5mnt2rVqbW3VwoULdccddyg9Pb3zrgwAAHRbnfpJsomJiXr99deVmpqqGTNmKCcnR3/4wx/04osvavr06eH91q9fr6ysLOXl5Wn69OmaNGmSnnnmmc4cCgAA6MZcjuM4sR5EtEKhkLxerxobG+XxeGI9HAAAcBmief/mb/EAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGBOQqwHcCUcx5EkhUKhGI8EAABcrovv2xffx79KtwyUpqYmSVJGRkaMRwIAAKLV1NQkr9f7lfu4nMvJGGPa29tVU1OjlJQUuVyuTj13KBRSRkaGqqur5fF4OvXc+CLm++pivq8u5vvqYr6vriuZb8dx1NTUpPT0dMXFffVTJt3yDkpcXJwGDx7cpa/h8Xj4Br+KmO+ri/m+upjvq4v5vrqine//352Ti3hIFgAAmEOgAAAAcwiU/+J2u7Vy5Uq53e5YD+V/AvN9dTHfVxfzfXUx31dXV893t3xIFgAA9GzcQQEAAOYQKAAAwBwCBQAAmEOgAAAAcwiU//DUU0/p2muvVXJysnJzc/Xuu+/Gekg9ws6dOzVjxgylp6fL5XLplVdeidjuOI5+9atfadCgQerVq5fy8/N17Nix2Ay2BygtLdU3v/lNpaSkaODAgfrhD3+oo0ePRuxz7tw5FRcXa8CAAerbt69mzpyp06dPx2jE3duaNWuUk5MT/rCqQCCgN954I7ydue5aq1atksvl0uLFi8PrmPPOU1JSIpfLFbFkZWWFt3flXBMo/89LL72kpUuXauXKlTpw4IDGjh2rgoIC1dXVxXpo3d6ZM2c0duxYPfXUU5fc/thjj+mJJ57Q2rVrtXfvXvXp00cFBQU6d+7cVR5pz7Bjxw4VFxdrz549Ki8vV2trq6ZMmaIzZ86E91myZIlee+01bdy4UTt27FBNTY1uvfXWGI66+xo8eLBWrVqlyspK7d+/XzfddJNuvvlmHT58WBJz3ZX27dunp59+Wjk5ORHrmfPONWrUKNXW1oaXd955J7ytS+fageM4jnPDDTc4xcXF4a/b2tqc9PR0p7S0NIaj6nkkOZs2bQp/3d7e7vj9fufXv/51eF1DQ4PjdrudP/3pTzEYYc9TV1fnSHJ27NjhOM7n85uYmOhs3LgxvM+RI0ccSU5FRUWshtmj9OvXz3nuueeY6y7U1NTkfP3rX3fKy8ud7373u86iRYscx+H7u7OtXLnSGTt27CW3dfVccwdF0vnz51VZWan8/Pzwuri4OOXn56uioiKGI+v5Tp48qWAwGDH3Xq9Xubm5zH0naWxslCT1799fklRZWanW1taIOc/KylJmZiZz3kFtbW0qKyvTmTNnFAgEmOsuVFxcrMLCwoi5lfj+7grHjh1Tenq6hg4dqqKiIp06dUpS1891t/xjgZ3tk08+UVtbm9LS0iLWp6Wl6Z///GeMRvW/IRgMStIl5/7iNly59vZ2LV68WN/+9rc1evRoSZ/PeVJSknw+X8S+zPmVq6qqUiAQ0Llz59S3b19t2rRJ2dnZOnToEHPdBcrKynTgwAHt27fvC9v4/u5cubm5WrdunUaMGKHa2lo99NBDmjx5st5///0un2sCBejBiouL9f7770f8zBidb8SIETp06JAaGxv18ssva86cOdqxY0esh9UjVVdXa9GiRSovL1dycnKsh9PjTZs2LfzvnJwc5ebmasiQIdqwYYN69erVpa/Nj3gkXXPNNYqPj//Ck8enT5+W3++P0aj+N1ycX+a+8y1cuFCbN2/W22+/rcGDB4fX+/1+nT9/Xg0NDRH7M+dXLikpScOGDdP48eNVWlqqsWPH6ne/+x1z3QUqKytVV1encePGKSEhQQkJCdqxY4eeeOIJJSQkKC0tjTnvQj6fT8OHD9fx48e7/PubQNHn/7mMHz9eb731Vnhde3u73nrrLQUCgRiOrOe77rrr5Pf7I+Y+FApp7969zP0VchxHCxcu1KZNm7Rt2zZdd911EdvHjx+vxMTEiDk/evSoTp06xZx3kvb2drW0tDDXXSAvL09VVVU6dOhQeJkwYYKKiorC/2bOu05zc7NOnDihQYMGdf33d4cfs+0hysrKHLfb7axbt8754IMPnPnz5zs+n88JBoOxHlq319TU5Bw8eNA5ePCgI8n5zW9+4xw8eND56KOPHMdxnFWrVjk+n8/5y1/+4rz33nvOzTff7Fx33XXOZ599FuORd08LFixwvF6vs337dqe2tja8nD17NrzPPffc42RmZjrbtm1z9u/f7wQCAScQCMRw1N3X/fff7+zYscM5efKk89577zn333+/43K5nDfffNNxHOb6avjP3+JxHOa8M/385z93tm/f7pw8edLZtWuXk5+f71xzzTVOXV2d4zhdO9cEyn9YvXq1k5mZ6SQlJTk33HCDs2fPnlgPqUd4++23HUlfWObMmeM4zue/avzggw86aWlpjtvtdvLy8pyjR4/GdtDd2KXmWpLzwgsvhPf57LPPnJ/+9KdOv379nN69ezu33HKLU1tbG7tBd2M//vGPnSFDhjhJSUlOamqqk5eXF44Tx2Gur4b/DhTmvPPcfvvtzqBBg5ykpCTna1/7mnP77bc7x48fD2/vyrl2OY7jdPw+DAAAQOfhGRQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMOf/AMJiXdvmZHbnAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recompensa de Media: 500.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos al Generador \n",
    "rewardMean=gan2.evaluate_G()\n",
    "print('\\nRecompensa de Media:', rewardMean, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción de base de datos experta con 1 trayectoria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEstados reales: \n",
      " [[ 0.00572823 -0.03831238  0.03101629  0.00900886]\n",
      " [ 0.00496198  0.15635134  0.03119646 -0.27372897]\n",
      " [ 0.00808901 -0.03920152  0.02572188  0.02862788]\n",
      " ...\n",
      " [-0.03035956 -0.1520803   0.0103268   0.24866116]\n",
      " [-0.03340117  0.04289266  0.01530002 -0.04074667]\n",
      " [-0.03254332  0.23779191  0.01448509 -0.3285633 ]]\n",
      "\tAcciones reales: \n",
      " [1 0 1 ... 1 1 0]\n",
      "\n",
      "\t Estados siguientes: \n",
      " [[ 0.00572823 -0.03831238  0.03101629  0.00900886]\n",
      " [ 0.00496198  0.15635134  0.03119646 -0.27372897]\n",
      " [ 0.00808901 -0.03920152  0.02572188  0.02862788]\n",
      " ...\n",
      " [-0.03035956 -0.1520803   0.0103268   0.24866116]\n",
      " [-0.03340117  0.04289266  0.01530002 -0.04074667]\n",
      " [-0.03254332  0.23779191  0.01448509 -0.3285633 ]]\n",
      "\n",
      "\t Recompensas: [1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "expert_observations = np.genfromtxt(\"observations_CartPole_.csv\",delimiter=\"\\t\",dtype=str)\n",
    "expert_actions = np.genfromtxt('actions_CartPole_.csv', dtype=np.int32)\n",
    "expert_next_observations = np.genfromtxt('next_observations_CartPole_.csv',delimiter=\"\\t\",dtype=str)\n",
    "expert_rewards = np.genfromtxt('rewards_CartPole_.csv', dtype=np.int32)\n",
    "expert_num_tray=np.genfromtxt('n_trayectoria_CartPole_.csv', dtype=np.int32)\n",
    "\n",
    "# Reemplazar las comas\n",
    "expert_observations = np.core.defchararray.replace(expert_observations, ',', ' ')\n",
    "\n",
    "# Reemplazar las comas\n",
    "expert_next_observations = np.core.defchararray.replace(expert_next_observations, ',', ' ')\n",
    "\n",
    "# Crear un nuevo array para almacenar los datos convertidos\n",
    "converted_observations = np.genfromtxt(expert_observations, delimiter=' ', dtype=float)\n",
    "# Crear un nuevo array para almacenar los datos convertidos\n",
    "converted_next_observations = np.genfromtxt(expert_observations, delimiter=' ', dtype=float)\n",
    "\n",
    "\n",
    "rewards=np.array(expert_rewards).reshape(-1,1)\n",
    "\n",
    "\n",
    "print(\"\\n\\tEstados reales: \\n\", converted_observations)\n",
    "print(\"\\tAcciones reales: \\n\", expert_actions)\n",
    "print(\"\\n\\t Estados siguientes: \\n\", converted_next_observations)\n",
    "print(\"\\n\\t Recompensas:\" ,expert_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n"
     ]
    }
   ],
   "source": [
    "longitud_trayectoria += np.count_nonzero(expert_num_tray == 2)\n",
    "print(longitud_trayectoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos quedamos solo con la primera trayectoria\n",
    "converted_observations=converted_observations[0:longitud_trayectoria]\n",
    "expert_actions=expert_actions[0:longitud_trayectoria]\n",
    "converted_next_observations=converted_next_observations[0:longitud_trayectoria]\n",
    "expert_rewards=expert_rewards[0:longitud_trayectoria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el dataset [s,a,s',r] reales y lo dividimos en training y test\n",
    "expert_a_one_hot=np.eye(env.action_space.n)[expert_actions]\n",
    "expert_rewards = expert_rewards.reshape(-1, 1)\n",
    "\n",
    "dataset1=np.concatenate([converted_observations,expert_a_one_hot],axis=1)\n",
    "dataset2=np.concatenate([dataset1,converted_next_observations],axis=1)\n",
    "dataset=np.concatenate([dataset2,expert_rewards],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento: 1200\n",
      "Nº de (ESTADOS,ACCIONES) en el conjunto de prueba: 300\n"
     ]
    }
   ],
   "source": [
    "#############################################################################\n",
    "# DIVISIÓN TRAIN Y TEST\n",
    "##############################################################################\n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test = train_test_split(dataset, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "#Imprime el número de elementos en el conjuntos de entrenamiento y prueba\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento:', len(X_train))\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de prueba:', len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "env= gym.make('CartPole-v1')\n",
    "obs,_= env.reset()\n",
    "\n",
    "# Generador\n",
    "generator=Policy_net( 'policy', env, obs)\n",
    "\n",
    "# Generamos [s,a, s', r] falsas y las políticas theta_i y theta_i+1\n",
    "observations, actions, next_observations, rewards, Old_Policy, Policy=generator.generate_fakes()\n",
    "\n",
    "# Discriminador\n",
    "discriminator=Discriminator(env, discriminator_net, converted_observations, expert_actions, converted_next_observations, expert_rewards, observations, actions, next_observations, rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan3=GAN(discriminator=discriminator,generator=generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "gan3.compile(\n",
    "    d_optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss_fn_D=loss_fn_D\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "d_loss= 2.508256\n",
      "\n",
      "g_loss= -1.0001738\n",
      " 1/14 [=>............................] - ETA: 1:33:05 - d_loss: 2.5083 - g_loss: -1.0002\n",
      "\n",
      "\n",
      "d_loss= 2.5618472\n",
      "\n",
      "g_loss= -0.60384005\n",
      " 2/14 [===>..........................] - ETA: 1:27:23 - d_loss: 2.5351 - g_loss: -0.8020\n",
      "\n",
      "\n",
      "d_loss= 2.543202\n",
      "\n",
      "g_loss= -0.5255664\n",
      " 3/14 [=====>........................] - ETA: 1:19:16 - d_loss: 2.5378 - g_loss: -0.7099\n",
      "\n",
      "\n",
      "d_loss= 2.4777832\n",
      "\n",
      "g_loss= -0.53420806\n",
      " 4/14 [=======>......................] - ETA: 1:12:39 - d_loss: 2.5228 - g_loss: -0.6659\n",
      "\n",
      "\n",
      "d_loss= 2.5061386\n",
      "\n",
      "g_loss= -0.8661372\n",
      " 5/14 [=========>....................] - ETA: 1:05:28 - d_loss: 2.5194 - g_loss: -0.7060\n",
      "\n",
      "\n",
      "d_loss= 2.5075858\n",
      "\n",
      "g_loss= -1.5282884\n",
      " 6/14 [===========>..................] - ETA: 58:05 - d_loss: 2.5175 - g_loss: -0.8430  \n",
      "\n",
      "\n",
      "d_loss= 2.508922\n",
      "\n",
      "g_loss= -0.15607238\n",
      " 7/14 [==============>...............] - ETA: 50:47 - d_loss: 2.5162 - g_loss: -0.7449\n",
      "\n",
      "\n",
      "d_loss= 2.502104\n",
      "\n",
      "g_loss= -1.0714557\n",
      " 8/14 [================>.............] - ETA: 43:35 - d_loss: 2.5145 - g_loss: -0.7857\n",
      "\n",
      "\n",
      "d_loss= 2.4812276\n",
      "\n",
      "g_loss= -0.81262183\n",
      " 9/14 [==================>...........] - ETA: 36:14 - d_loss: 2.5108 - g_loss: -0.7887\n",
      "\n",
      "\n",
      "d_loss= 2.4722419\n",
      "\n",
      "g_loss= -0.29444665\n",
      "10/14 [====================>.........] - ETA: 28:59 - d_loss: 2.5069 - g_loss: -0.7393\n",
      "\n",
      "\n",
      "d_loss= 2.5228152\n",
      "\n",
      "g_loss= -1.2313771\n",
      "11/14 [======================>.......] - ETA: 21:45 - d_loss: 2.5084 - g_loss: -0.7840\n",
      "\n",
      "\n",
      "d_loss= 2.460022\n",
      "\n",
      "g_loss= -0.6938109\n",
      "12/14 [========================>.....] - ETA: 14:30 - d_loss: 2.5043 - g_loss: -0.7765\n",
      "\n",
      "\n",
      "d_loss= 2.4761777\n",
      "\n",
      "g_loss= -0.2647742\n",
      "13/14 [==========================>...] - ETA: 7:14 - d_loss: 2.5022 - g_loss: -0.7371 \n",
      "\n",
      "\n",
      "d_loss= 2.4278984\n",
      "\n",
      "g_loss= -1.4124594\n",
      "14/14 [==============================] - 6076s 434s/step - d_loss: 2.4969 - g_loss: -0.7854\n"
     ]
    }
   ],
   "source": [
    "# Deshabilitar los mensajes de información de TensorFlow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Deshabilitar los mensajes de información de OpenAI Gym\n",
    "gym.logger.set_level(40)\n",
    "\n",
    "history=gan3.fit(X_train,\n",
    "    epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5812 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4905 - accuracy: 0.0000e+00\n",
      ">Loss real: \n",
      "0.5812050700187683\n",
      ">Loss fake: \n",
      "0.49050667881965637\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos el Discriminador de GAIL en el TEST\n",
    "gan3.evaluate_D(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  0 Total reward: 500.0\n",
      "Episode  1 Total reward: 500.0\n",
      "Episode  2 Total reward: 500.0\n",
      "Episode  3 Total reward: 500.0\n",
      "Episode  4 Total reward: 500.0\n",
      "Episode  5 Total reward: 500.0\n",
      "Episode  6 Total reward: 500.0\n",
      "Episode  7 Total reward: 500.0\n",
      "Episode  8 Total reward: 500.0\n",
      "Episode  9 Total reward: 500.0\n",
      "Episode  10 Total reward: 500.0\n",
      "Episode  11 Total reward: 500.0\n",
      "Episode  12 Total reward: 500.0\n",
      "Episode  13 Total reward: 500.0\n",
      "Episode  14 Total reward: 500.0\n",
      "Episode  15 Total reward: 500.0\n",
      "Episode  16 Total reward: 500.0\n",
      "Episode  17 Total reward: 500.0\n",
      "Episode  18 Total reward: 500.0\n",
      "Episode  19 Total reward: 500.0\n",
      "Episode  20 Total reward: 500.0\n",
      "Episode  21 Total reward: 500.0\n",
      "Episode  22 Total reward: 500.0\n",
      "Episode  23 Total reward: 500.0\n",
      "Episode  24 Total reward: 500.0\n",
      "Episode  25 Total reward: 500.0\n",
      "Episode  26 Total reward: 500.0\n",
      "Episode  27 Total reward: 500.0\n",
      "Episode  28 Total reward: 500.0\n",
      "Episode  29 Total reward: 500.0\n",
      "Episode  30 Total reward: 500.0\n",
      "Episode  31 Total reward: 500.0\n",
      "Episode  32 Total reward: 500.0\n",
      "Episode  33 Total reward: 500.0\n",
      "Episode  34 Total reward: 500.0\n",
      "Episode  35 Total reward: 500.0\n",
      "Episode  36 Total reward: 500.0\n",
      "Episode  37 Total reward: 500.0\n",
      "Episode  38 Total reward: 500.0\n",
      "Episode  39 Total reward: 500.0\n",
      "Episode  40 Total reward: 500.0\n",
      "Episode  41 Total reward: 500.0\n",
      "Episode  42 Total reward: 500.0\n",
      "Episode  43 Total reward: 500.0\n",
      "Episode  44 Total reward: 500.0\n",
      "Episode  45 Total reward: 500.0\n",
      "Episode  46 Total reward: 500.0\n",
      "Episode  47 Total reward: 500.0\n",
      "Episode  48 Total reward: 500.0\n",
      "Episode  49 Total reward: 500.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recompensa de Media: 500.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos al Generador \n",
    "rewardMean=gan3.evaluate_G()\n",
    "print('\\nRecompensa de Media:', rewardMean, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción de base de datos experta con 4 trayectoria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEstados reales: \n",
      " [[ 0.00572823 -0.03831238  0.03101629  0.00900886]\n",
      " [ 0.00496198  0.15635134  0.03119646 -0.27372897]\n",
      " [ 0.00808901 -0.03920152  0.02572188  0.02862788]\n",
      " ...\n",
      " [-0.03035956 -0.1520803   0.0103268   0.24866116]\n",
      " [-0.03340117  0.04289266  0.01530002 -0.04074667]\n",
      " [-0.03254332  0.23779191  0.01448509 -0.3285633 ]]\n",
      "\tAcciones reales: \n",
      " [1 0 1 ... 1 1 0]\n",
      "\n",
      "\t Estados siguientes: \n",
      " [[ 0.00572823 -0.03831238  0.03101629  0.00900886]\n",
      " [ 0.00496198  0.15635134  0.03119646 -0.27372897]\n",
      " [ 0.00808901 -0.03920152  0.02572188  0.02862788]\n",
      " ...\n",
      " [-0.03035956 -0.1520803   0.0103268   0.24866116]\n",
      " [-0.03340117  0.04289266  0.01530002 -0.04074667]\n",
      " [-0.03254332  0.23779191  0.01448509 -0.3285633 ]]\n",
      "\n",
      "\t Recompensas: [1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "expert_observations = np.genfromtxt(\"observations_CartPole_.csv\",delimiter=\"\\t\",dtype=str)\n",
    "expert_actions = np.genfromtxt('actions_CartPole_.csv', dtype=np.int32)\n",
    "expert_next_observations = np.genfromtxt('next_observations_CartPole_.csv',delimiter=\"\\t\",dtype=str)\n",
    "expert_rewards = np.genfromtxt('rewards_CartPole_.csv', dtype=np.int32)\n",
    "expert_num_tray=np.genfromtxt('n_trayectoria_CartPole_.csv', dtype=np.int32)\n",
    "\n",
    "# Reemplazar las comas\n",
    "expert_observations = np.core.defchararray.replace(expert_observations, ',', ' ')\n",
    "\n",
    "# Reemplazar las comas\n",
    "expert_next_observations = np.core.defchararray.replace(expert_next_observations, ',', ' ')\n",
    "\n",
    "# Crear un nuevo array para almacenar los datos convertidos\n",
    "converted_observations = np.genfromtxt(expert_observations, delimiter=' ', dtype=float)\n",
    "# Crear un nuevo array para almacenar los datos convertidos\n",
    "converted_next_observations = np.genfromtxt(expert_observations, delimiter=' ', dtype=float)\n",
    "\n",
    "\n",
    "rewards=np.array(expert_rewards).reshape(-1,1)\n",
    "\n",
    "\n",
    "print(\"\\n\\tEstados reales: \\n\", converted_observations)\n",
    "print(\"\\tAcciones reales: \\n\", expert_actions)\n",
    "print(\"\\n\\t Estados siguientes: \\n\", converted_next_observations)\n",
    "print(\"\\n\\t Recompensas:\" ,expert_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "longitud_trayectoria += np.count_nonzero(expert_num_tray == 3)\n",
    "print(longitud_trayectoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos quedamos solo con la primera trayectoria\n",
    "converted_observations=converted_observations[0:longitud_trayectoria]\n",
    "expert_actions=expert_actions[0:longitud_trayectoria]\n",
    "converted_next_observations=converted_next_observations[0:longitud_trayectoria]\n",
    "expert_rewards=expert_rewards[0:longitud_trayectoria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el dataset [s,a,s',r] reales y lo dividimos en training y test\n",
    "expert_a_one_hot=np.eye(env.action_space.n)[expert_actions]\n",
    "expert_rewards = expert_rewards.reshape(-1, 1)\n",
    "\n",
    "dataset1=np.concatenate([converted_observations,expert_a_one_hot],axis=1)\n",
    "dataset2=np.concatenate([dataset1,converted_next_observations],axis=1)\n",
    "dataset=np.concatenate([dataset2,expert_rewards],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento: 1600\n",
      "Nº de (ESTADOS,ACCIONES) en el conjunto de prueba: 400\n"
     ]
    }
   ],
   "source": [
    "#############################################################################\n",
    "# DIVISIÓN TRAIN Y TEST\n",
    "##############################################################################\n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test = train_test_split(dataset, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "#Imprime el número de elementos en el conjuntos de entrenamiento y prueba\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento:', len(X_train))\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de prueba:', len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "env= gym.make('CartPole-v1')\n",
    "obs,_= env.reset()\n",
    "\n",
    "# Generador\n",
    "generator=Policy_net( 'policy', env, obs)\n",
    "\n",
    "# Generamos [s,a, s', r] falsas y las políticas theta_i y theta_i+1\n",
    "observations, actions, next_observations, rewards, Old_Policy, Policy=generator.generate_fakes()\n",
    "\n",
    "# Discriminador\n",
    "discriminator=Discriminator(env, discriminator_net, converted_observations, expert_actions, converted_next_observations, expert_rewards, observations, actions, next_observations, rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan4=GAN(discriminator=discriminator,generator=generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "gan4.compile(\n",
    "    d_optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss_fn_D=loss_fn_D\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "d_loss= 2.4652963\n",
      "\n",
      "g_loss= -1.6609634\n",
      " 1/18 [>.............................] - ETA: 2:01:54 - d_loss: 2.4653 - g_loss: -1.6610\n",
      "\n",
      "\n",
      "d_loss= 2.466508\n",
      "\n",
      "g_loss= -0.70675635\n",
      " 2/18 [==>...........................] - ETA: 1:56:51 - d_loss: 2.4659 - g_loss: -1.1839\n",
      "\n",
      "\n",
      "d_loss= 2.433167\n",
      "\n",
      "g_loss= -0.995834\n",
      " 3/18 [====>.........................] - ETA: 1:49:03 - d_loss: 2.4550 - g_loss: -1.1212\n",
      "\n",
      "\n",
      "d_loss= 2.4485803\n",
      "\n",
      "g_loss= -0.6981693\n",
      " 4/18 [=====>........................] - ETA: 1:41:41 - d_loss: 2.4534 - g_loss: -1.0154\n",
      "\n",
      "\n",
      "d_loss= 2.5028334\n",
      "\n",
      "g_loss= -1.6127505\n",
      " 5/18 [=======>......................] - ETA: 1:34:13 - d_loss: 2.4633 - g_loss: -1.1349\n",
      "\n",
      "\n",
      "d_loss= 2.402663\n",
      "\n",
      "g_loss= -0.7419017\n",
      " 6/18 [=========>....................] - ETA: 1:26:51 - d_loss: 2.4532 - g_loss: -1.0694\n",
      "\n",
      "\n",
      "d_loss= 2.4733095\n",
      "\n",
      "g_loss= -1.1649255\n",
      " 7/18 [==========>...................] - ETA: 1:19:52 - d_loss: 2.4561 - g_loss: -1.0830\n",
      "\n",
      "\n",
      "d_loss= 2.4399676\n",
      "\n",
      "g_loss= -0.8824468\n",
      " 8/18 [============>.................] - ETA: 1:12:29 - d_loss: 2.4540 - g_loss: -1.0580\n",
      "\n",
      "\n",
      "d_loss= 2.5168989\n",
      "\n",
      "g_loss= -0.9639048\n",
      " 9/18 [==============>...............] - ETA: 1:05:14 - d_loss: 2.4610 - g_loss: -1.0475\n",
      "\n",
      "\n",
      "d_loss= 2.4817357\n",
      "\n",
      "g_loss= -1.4378766\n",
      "10/18 [===============>..............] - ETA: 57:52 - d_loss: 2.4631 - g_loss: -1.0866  \n",
      "\n",
      "\n",
      "d_loss= 2.4547927\n",
      "\n",
      "g_loss= -1.2283751\n",
      "11/18 [=================>............] - ETA: 50:39 - d_loss: 2.4623 - g_loss: -1.0994\n",
      "\n",
      "\n",
      "d_loss= 2.4592073\n",
      "\n",
      "g_loss= -1.6290953\n",
      "12/18 [===================>..........] - ETA: 43:38 - d_loss: 2.4621 - g_loss: -1.1436\n",
      "\n",
      "\n",
      "d_loss= 2.4704666\n",
      "\n",
      "g_loss= -0.9856863\n",
      "13/18 [====================>.........] - ETA: 36:24 - d_loss: 2.4627 - g_loss: -1.1314\n",
      "\n",
      "\n",
      "d_loss= 2.4026685\n",
      "\n",
      "g_loss= -0.46019337\n",
      "14/18 [======================>.......] - ETA: 29:06 - d_loss: 2.4584 - g_loss: -1.0835\n",
      "\n",
      "\n",
      "d_loss= 2.467628\n",
      "\n",
      "g_loss= -1.0050954\n",
      "15/18 [========================>.....] - ETA: 21:49 - d_loss: 2.4590 - g_loss: -1.0783\n",
      "\n",
      "\n",
      "d_loss= 2.4552786\n",
      "\n",
      "g_loss= -1.4703364\n",
      "16/18 [=========================>....] - ETA: 14:31 - d_loss: 2.4588 - g_loss: -1.1028\n",
      "\n",
      "\n",
      "d_loss= 2.4220965\n",
      "\n",
      "g_loss= -1.6542088\n",
      "17/18 [===========================>..] - ETA: 7:15 - d_loss: 2.4567 - g_loss: -1.1352 \n",
      "\n",
      "\n",
      "d_loss= 2.3887959\n",
      "\n",
      "g_loss= -0.84412116\n",
      "18/18 [==============================] - 7838s 436s/step - d_loss: 2.4529 - g_loss: -1.1190\n"
     ]
    }
   ],
   "source": [
    "# Deshabilitar los mensajes de información de TensorFlow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Deshabilitar los mensajes de información de OpenAI Gym\n",
    "gym.logger.set_level(40)\n",
    "\n",
    "history=gan4.fit(X_train,\n",
    "    epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5317 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5122 - accuracy: 0.0000e+00\n",
      ">Loss real: \n",
      "0.5317344069480896\n",
      ">Loss fake: \n",
      "0.5121617913246155\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos el Discriminador de GAIL en el TEST\n",
    "gan4.evaluate_D(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  0 Total reward: 500.0\n",
      "Episode  1 Total reward: 500.0\n",
      "Episode  2 Total reward: 500.0\n",
      "Episode  3 Total reward: 500.0\n",
      "Episode  4 Total reward: 500.0\n",
      "Episode  5 Total reward: 500.0\n",
      "Episode  6 Total reward: 500.0\n",
      "Episode  7 Total reward: 500.0\n",
      "Episode  8 Total reward: 500.0\n",
      "Episode  9 Total reward: 500.0\n",
      "Episode  10 Total reward: 500.0\n",
      "Episode  11 Total reward: 500.0\n",
      "Episode  12 Total reward: 500.0\n",
      "Episode  13 Total reward: 500.0\n",
      "Episode  14 Total reward: 500.0\n",
      "Episode  15 Total reward: 500.0\n",
      "Episode  16 Total reward: 500.0\n",
      "Episode  17 Total reward: 500.0\n",
      "Episode  18 Total reward: 500.0\n",
      "Episode  19 Total reward: 500.0\n",
      "Episode  20 Total reward: 500.0\n",
      "Episode  21 Total reward: 500.0\n",
      "Episode  22 Total reward: 500.0\n",
      "Episode  23 Total reward: 500.0\n",
      "Episode  24 Total reward: 500.0\n",
      "Episode  25 Total reward: 500.0\n",
      "Episode  26 Total reward: 500.0\n",
      "Episode  27 Total reward: 500.0\n",
      "Episode  28 Total reward: 500.0\n",
      "Episode  29 Total reward: 500.0\n",
      "Episode  30 Total reward: 500.0\n",
      "Episode  31 Total reward: 500.0\n",
      "Episode  32 Total reward: 500.0\n",
      "Episode  33 Total reward: 500.0\n",
      "Episode  34 Total reward: 500.0\n",
      "Episode  35 Total reward: 500.0\n",
      "Episode  36 Total reward: 500.0\n",
      "Episode  37 Total reward: 500.0\n",
      "Episode  38 Total reward: 500.0\n",
      "Episode  39 Total reward: 500.0\n",
      "Episode  40 Total reward: 500.0\n",
      "Episode  41 Total reward: 500.0\n",
      "Episode  42 Total reward: 500.0\n",
      "Episode  43 Total reward: 500.0\n",
      "Episode  44 Total reward: 500.0\n",
      "Episode  45 Total reward: 500.0\n",
      "Episode  46 Total reward: 500.0\n",
      "Episode  47 Total reward: 500.0\n",
      "Episode  48 Total reward: 500.0\n",
      "Episode  49 Total reward: 500.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recompensa de Media: 500.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos al Generador \n",
    "rewardMean=gan4.evaluate_G()\n",
    "print('\\nRecompensa de Media:', rewardMean, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción de base de datos experta con 5 trayectoria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEstados reales: \n",
      " [[ 0.00572823 -0.03831238  0.03101629  0.00900886]\n",
      " [ 0.00496198  0.15635134  0.03119646 -0.27372897]\n",
      " [ 0.00808901 -0.03920152  0.02572188  0.02862788]\n",
      " ...\n",
      " [-0.03035956 -0.1520803   0.0103268   0.24866116]\n",
      " [-0.03340117  0.04289266  0.01530002 -0.04074667]\n",
      " [-0.03254332  0.23779191  0.01448509 -0.3285633 ]]\n",
      "\tAcciones reales: \n",
      " [1 0 1 ... 1 1 0]\n",
      "\n",
      "\t Estados siguientes: \n",
      " [[ 0.00572823 -0.03831238  0.03101629  0.00900886]\n",
      " [ 0.00496198  0.15635134  0.03119646 -0.27372897]\n",
      " [ 0.00808901 -0.03920152  0.02572188  0.02862788]\n",
      " ...\n",
      " [-0.03035956 -0.1520803   0.0103268   0.24866116]\n",
      " [-0.03340117  0.04289266  0.01530002 -0.04074667]\n",
      " [-0.03254332  0.23779191  0.01448509 -0.3285633 ]]\n",
      "\n",
      "\t Recompensas: [1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "expert_observations = np.genfromtxt(\"observations_CartPole_.csv\",delimiter=\"\\t\",dtype=str)\n",
    "expert_actions = np.genfromtxt('actions_CartPole_.csv', dtype=np.int32)\n",
    "expert_next_observations = np.genfromtxt('next_observations_CartPole_.csv',delimiter=\"\\t\",dtype=str)\n",
    "expert_rewards = np.genfromtxt('rewards_CartPole_.csv', dtype=np.int32)\n",
    "expert_num_tray=np.genfromtxt('n_trayectoria_CartPole_.csv', dtype=np.int32)\n",
    "\n",
    "# Reemplazar las comas\n",
    "expert_observations = np.core.defchararray.replace(expert_observations, ',', ' ')\n",
    "\n",
    "# Reemplazar las comas\n",
    "expert_next_observations = np.core.defchararray.replace(expert_next_observations, ',', ' ')\n",
    "\n",
    "# Crear un nuevo array para almacenar los datos convertidos\n",
    "converted_observations = np.genfromtxt(expert_observations, delimiter=' ', dtype=float)\n",
    "# Crear un nuevo array para almacenar los datos convertidos\n",
    "converted_next_observations = np.genfromtxt(expert_observations, delimiter=' ', dtype=float)\n",
    "\n",
    "\n",
    "rewards=np.array(expert_rewards).reshape(-1,1)\n",
    "\n",
    "\n",
    "print(\"\\n\\tEstados reales: \\n\", converted_observations)\n",
    "print(\"\\tAcciones reales: \\n\", expert_actions)\n",
    "print(\"\\n\\t Estados siguientes: \\n\", converted_next_observations)\n",
    "print(\"\\n\\t Recompensas:\" ,expert_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n"
     ]
    }
   ],
   "source": [
    "longitud_trayectoria += np.count_nonzero(expert_num_tray == 4)\n",
    "print(longitud_trayectoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos quedamos solo con la primera trayectoria\n",
    "converted_observations=converted_observations[0:longitud_trayectoria]\n",
    "expert_actions=expert_actions[0:longitud_trayectoria]\n",
    "converted_next_observations=converted_next_observations[0:longitud_trayectoria]\n",
    "expert_rewards=expert_rewards[0:longitud_trayectoria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el dataset [s,a,s',r] reales y lo dividimos en training y test\n",
    "expert_a_one_hot=np.eye(env.action_space.n)[expert_actions]\n",
    "expert_rewards = expert_rewards.reshape(-1, 1)\n",
    "\n",
    "dataset1=np.concatenate([converted_observations,expert_a_one_hot],axis=1)\n",
    "dataset2=np.concatenate([dataset1,converted_next_observations],axis=1)\n",
    "dataset=np.concatenate([dataset2,expert_rewards],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento: 2000\n",
      "Nº de (ESTADOS,ACCIONES) en el conjunto de prueba: 500\n"
     ]
    }
   ],
   "source": [
    "#############################################################################\n",
    "# DIVISIÓN TRAIN Y TEST\n",
    "##############################################################################\n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test = train_test_split(dataset, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "#Imprime el número de elementos en el conjuntos de entrenamiento y prueba\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento:', len(X_train))\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de prueba:', len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "env= gym.make('CartPole-v1')\n",
    "obs,_= env.reset()\n",
    "\n",
    "# Generador\n",
    "generator=Policy_net( 'policy', env, obs)\n",
    "\n",
    "# Generamos [s,a, s', r] falsas y las políticas theta_i y theta_i+1\n",
    "observations, actions, next_observations, rewards, Old_Policy, Policy=generator.generate_fakes()\n",
    "\n",
    "# Discriminador\n",
    "discriminator=Discriminator(env, discriminator_net, converted_observations, expert_actions, converted_next_observations, expert_rewards, observations, actions, next_observations, rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan5=GAN(discriminator=discriminator,generator=generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "gan5.compile(\n",
    "    d_optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss_fn_D=loss_fn_D\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "d_loss= 2.4451404\n",
      "\n",
      "g_loss= -0.46894056\n",
      " 1/23 [>.............................] - ETA: 2:39:01 - d_loss: 2.4451 - g_loss: -0.4689\n",
      "\n",
      "\n",
      "d_loss= 2.4088318\n",
      "\n",
      "g_loss= -1.4385024\n",
      " 2/23 [=>............................] - ETA: 2:29:04 - d_loss: 2.4270 - g_loss: -0.9537\n",
      "\n",
      "\n",
      "d_loss= 2.4522262\n",
      "\n",
      "g_loss= -0.4545961\n",
      " 3/23 [==>...........................] - ETA: 2:24:15 - d_loss: 2.4354 - g_loss: -0.7873\n",
      "\n",
      "\n",
      "d_loss= 2.4112628\n",
      "\n",
      "g_loss= -0.4263614\n",
      " 4/23 [====>.........................] - ETA: 2:16:49 - d_loss: 2.4294 - g_loss: -0.6971\n",
      "\n",
      "\n",
      "d_loss= 2.4202702\n",
      "\n",
      "g_loss= -0.5941934\n",
      " 5/23 [=====>........................] - ETA: 2:09:42 - d_loss: 2.4275 - g_loss: -0.6765\n",
      "\n",
      "\n",
      "d_loss= 2.4055822\n",
      "\n",
      "g_loss= -0.8841197\n",
      " 6/23 [======>.......................] - ETA: 2:02:22 - d_loss: 2.4239 - g_loss: -0.7111\n",
      "\n",
      "\n",
      "d_loss= 2.4199872\n",
      "\n",
      "g_loss= -0.6483916\n",
      " 7/23 [========>.....................] - ETA: 1:55:43 - d_loss: 2.4233 - g_loss: -0.7022\n",
      "\n",
      "\n",
      "d_loss= 2.4243279\n",
      "\n",
      "g_loss= -0.7948768\n",
      " 8/23 [=========>....................] - ETA: 1:48:56 - d_loss: 2.4235 - g_loss: -0.7137\n",
      "\n",
      "\n",
      "d_loss= 2.3790727\n",
      "\n",
      "g_loss= -1.2755426\n",
      " 9/23 [==========>...................] - ETA: 1:41:48 - d_loss: 2.4185 - g_loss: -0.7762\n",
      "\n",
      "\n",
      "d_loss= 2.3916132\n",
      "\n",
      "g_loss= -0.798314\n",
      "10/23 [============>.................] - ETA: 1:34:39 - d_loss: 2.4158 - g_loss: -0.7784\n",
      "\n",
      "\n",
      "d_loss= 2.382288\n",
      "\n",
      "g_loss= -1.4195067\n",
      "11/23 [=============>................] - ETA: 1:27:26 - d_loss: 2.4128 - g_loss: -0.8367\n",
      "\n",
      "\n",
      "d_loss= 2.3904514\n",
      "\n",
      "g_loss= -0.91612494\n",
      "12/23 [==============>...............] - ETA: 1:20:11 - d_loss: 2.4109 - g_loss: -0.8433\n",
      "\n",
      "\n",
      "d_loss= 2.4306276\n",
      "\n",
      "g_loss= -1.5334666\n",
      "13/23 [===============>..............] - ETA: 1:12:54 - d_loss: 2.4124 - g_loss: -0.8964\n",
      "\n",
      "\n",
      "d_loss= 2.3572528\n",
      "\n",
      "g_loss= -0.5476612\n",
      "14/23 [=================>............] - ETA: 1:05:30 - d_loss: 2.4085 - g_loss: -0.8715\n",
      "\n",
      "\n",
      "d_loss= 2.3633194\n",
      "\n",
      "g_loss= -0.7868009\n",
      "15/23 [==================>...........] - ETA: 58:12 - d_loss: 2.4055 - g_loss: -0.8658  \n",
      "\n",
      "\n",
      "d_loss= 2.394784\n",
      "\n",
      "g_loss= -1.639217\n",
      "16/23 [===================>..........] - ETA: 50:53 - d_loss: 2.4048 - g_loss: -0.9142\n",
      "\n",
      "\n",
      "d_loss= 2.3819149\n",
      "\n",
      "g_loss= -0.48507395\n",
      "17/23 [=====================>........] - ETA: 43:37 - d_loss: 2.4035 - g_loss: -0.8889\n",
      "\n",
      "\n",
      "d_loss= 2.4114747\n",
      "\n",
      "g_loss= -1.3163676\n",
      "18/23 [======================>.......] - ETA: 36:21 - d_loss: 2.4039 - g_loss: -0.9127\n",
      "\n",
      "\n",
      "d_loss= 2.339845\n",
      "\n",
      "g_loss= -0.79005474\n",
      "19/23 [=======================>......] - ETA: 29:04 - d_loss: 2.4005 - g_loss: -0.9062\n",
      "\n",
      "\n",
      "d_loss= 2.3099658\n",
      "\n",
      "g_loss= -1.2334598\n",
      "20/23 [=========================>....] - ETA: 21:47 - d_loss: 2.3960 - g_loss: -0.9226\n",
      "\n",
      "\n",
      "d_loss= 2.4120936\n",
      "\n",
      "g_loss= -1.4495041\n",
      "21/23 [==========================>...] - ETA: 14:31 - d_loss: 2.3968 - g_loss: -0.9477\n",
      "\n",
      "\n",
      "d_loss= 2.3916664\n",
      "\n",
      "g_loss= -0.64049006\n",
      "22/23 [===========================>..] - ETA: 7:15 - d_loss: 2.3965 - g_loss: -0.9337 \n",
      "\n",
      "\n",
      "d_loss= 2.3328578\n",
      "\n",
      "g_loss= -0.50571495\n",
      "23/23 [==============================] - 10016s 436s/step - d_loss: 2.3938 - g_loss: -0.9151\n"
     ]
    }
   ],
   "source": [
    "# Deshabilitar los mensajes de información de TensorFlow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Deshabilitar los mensajes de información de OpenAI Gym\n",
    "gym.logger.set_level(40)\n",
    "\n",
    "history=gan5.fit(X_train,\n",
    "    epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4665 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4607 - accuracy: 0.0000e+00\n",
      ">Loss real: \n",
      "0.46651142835617065\n",
      ">Loss fake: \n",
      "0.4606764316558838\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos el Discriminador de GAIL en el TEST\n",
    "gan5.evaluate_D(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  0 Total reward: 500.0\n",
      "Episode  1 Total reward: 500.0\n",
      "Episode  2 Total reward: 500.0\n",
      "Episode  3 Total reward: 500.0\n",
      "Episode  4 Total reward: 500.0\n",
      "Episode  5 Total reward: 500.0\n",
      "Episode  6 Total reward: 500.0\n",
      "Episode  7 Total reward: 500.0\n",
      "Episode  8 Total reward: 500.0\n",
      "Episode  9 Total reward: 500.0\n",
      "Episode  10 Total reward: 500.0\n",
      "Episode  11 Total reward: 500.0\n",
      "Episode  12 Total reward: 500.0\n",
      "Episode  13 Total reward: 500.0\n",
      "Episode  14 Total reward: 500.0\n",
      "Episode  15 Total reward: 500.0\n",
      "Episode  16 Total reward: 500.0\n",
      "Episode  17 Total reward: 500.0\n",
      "Episode  18 Total reward: 500.0\n",
      "Episode  19 Total reward: 500.0\n",
      "Episode  20 Total reward: 500.0\n",
      "Episode  21 Total reward: 500.0\n",
      "Episode  22 Total reward: 500.0\n",
      "Episode  23 Total reward: 500.0\n",
      "Episode  24 Total reward: 500.0\n",
      "Episode  25 Total reward: 500.0\n",
      "Episode  26 Total reward: 500.0\n",
      "Episode  27 Total reward: 500.0\n",
      "Episode  28 Total reward: 500.0\n",
      "Episode  29 Total reward: 500.0\n",
      "Episode  30 Total reward: 500.0\n",
      "Episode  31 Total reward: 500.0\n",
      "Episode  32 Total reward: 500.0\n",
      "Episode  33 Total reward: 500.0\n",
      "Episode  34 Total reward: 500.0\n",
      "Episode  35 Total reward: 500.0\n",
      "Episode  36 Total reward: 500.0\n",
      "Episode  37 Total reward: 500.0\n",
      "Episode  38 Total reward: 500.0\n",
      "Episode  39 Total reward: 500.0\n",
      "Episode  40 Total reward: 500.0\n",
      "Episode  41 Total reward: 500.0\n",
      "Episode  42 Total reward: 500.0\n",
      "Episode  43 Total reward: 500.0\n",
      "Episode  44 Total reward: 500.0\n",
      "Episode  45 Total reward: 500.0\n",
      "Episode  46 Total reward: 500.0\n",
      "Episode  47 Total reward: 500.0\n",
      "Episode  48 Total reward: 500.0\n",
      "Episode  49 Total reward: 500.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recompensa de Media: 500.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos al Generador \n",
    "rewardMean=gan5.evaluate_G()\n",
    "print('\\nRecompensa de Media:', rewardMean, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción de base de datos experta con 1 trayectoria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEstados reales: \n",
      " [[ 0.00572823 -0.03831238  0.03101629  0.00900886]\n",
      " [ 0.00496198  0.15635134  0.03119646 -0.27372897]\n",
      " [ 0.00808901 -0.03920152  0.02572188  0.02862788]\n",
      " ...\n",
      " [-0.03035956 -0.1520803   0.0103268   0.24866116]\n",
      " [-0.03340117  0.04289266  0.01530002 -0.04074667]\n",
      " [-0.03254332  0.23779191  0.01448509 -0.3285633 ]]\n",
      "\tAcciones reales: \n",
      " [1 0 1 ... 1 1 0]\n",
      "\n",
      "\t Estados siguientes: \n",
      " [[ 0.00572823 -0.03831238  0.03101629  0.00900886]\n",
      " [ 0.00496198  0.15635134  0.03119646 -0.27372897]\n",
      " [ 0.00808901 -0.03920152  0.02572188  0.02862788]\n",
      " ...\n",
      " [-0.03035956 -0.1520803   0.0103268   0.24866116]\n",
      " [-0.03340117  0.04289266  0.01530002 -0.04074667]\n",
      " [-0.03254332  0.23779191  0.01448509 -0.3285633 ]]\n",
      "\n",
      "\t Recompensas: [1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "expert_observations = np.genfromtxt(\"observations_CartPole_.csv\",delimiter=\"\\t\",dtype=str)\n",
    "expert_actions = np.genfromtxt('actions_CartPole_.csv', dtype=np.int32)\n",
    "expert_next_observations = np.genfromtxt('next_observations_CartPole_.csv',delimiter=\"\\t\",dtype=str)\n",
    "expert_rewards = np.genfromtxt('rewards_CartPole_.csv', dtype=np.int32)\n",
    "expert_num_tray=np.genfromtxt('n_trayectoria_CartPole_.csv', dtype=np.int32)\n",
    "\n",
    "# Reemplazar las comas\n",
    "expert_observations = np.core.defchararray.replace(expert_observations, ',', ' ')\n",
    "\n",
    "# Reemplazar las comas\n",
    "expert_next_observations = np.core.defchararray.replace(expert_next_observations, ',', ' ')\n",
    "\n",
    "# Crear un nuevo array para almacenar los datos convertidos\n",
    "converted_observations = np.genfromtxt(expert_observations, delimiter=' ', dtype=float)\n",
    "# Crear un nuevo array para almacenar los datos convertidos\n",
    "converted_next_observations = np.genfromtxt(expert_observations, delimiter=' ', dtype=float)\n",
    "\n",
    "\n",
    "rewards=np.array(expert_rewards).reshape(-1,1)\n",
    "\n",
    "\n",
    "print(\"\\n\\tEstados reales: \\n\", converted_observations)\n",
    "print(\"\\tAcciones reales: \\n\", expert_actions)\n",
    "print(\"\\n\\t Estados siguientes: \\n\", converted_next_observations)\n",
    "print(\"\\n\\t Recompensas:\" ,expert_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    }
   ],
   "source": [
    "longitud_trayectoria += np.count_nonzero(expert_num_tray == 5)\n",
    "print(longitud_trayectoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos quedamos solo con la primera trayectoria\n",
    "converted_observations=converted_observations[0:longitud_trayectoria]\n",
    "expert_actions=expert_actions[0:longitud_trayectoria]\n",
    "converted_next_observations=converted_next_observations[0:longitud_trayectoria]\n",
    "expert_rewards=expert_rewards[0:longitud_trayectoria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el dataset [s,a,s',r] reales y lo dividimos en training y test\n",
    "expert_a_one_hot=np.eye(env.action_space.n)[expert_actions]\n",
    "expert_rewards = expert_rewards.reshape(-1, 1)\n",
    "\n",
    "dataset1=np.concatenate([converted_observations,expert_a_one_hot],axis=1)\n",
    "dataset2=np.concatenate([dataset1,converted_next_observations],axis=1)\n",
    "dataset=np.concatenate([dataset2,expert_rewards],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento: 2400\n",
      "Nº de (ESTADOS,ACCIONES) en el conjunto de prueba: 600\n"
     ]
    }
   ],
   "source": [
    "#############################################################################\n",
    "# DIVISIÓN TRAIN Y TEST\n",
    "##############################################################################\n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test = train_test_split(dataset, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "#Imprime el número de elementos en el conjuntos de entrenamiento y prueba\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento:', len(X_train))\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de prueba:', len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "env= gym.make('CartPole-v1')\n",
    "obs,_= env.reset()\n",
    "\n",
    "# Generador\n",
    "generator=Policy_net( 'policy', env, obs)\n",
    "\n",
    "# Generamos [s,a, s', r] falsas y las políticas theta_i y theta_i+1\n",
    "observations, actions, next_observations, rewards, Old_Policy, Policy=generator.generate_fakes()\n",
    "\n",
    "# Discriminador\n",
    "discriminator=Discriminator(env, discriminator_net, converted_observations, expert_actions, converted_next_observations, expert_rewards, observations, actions, next_observations, rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan6=GAN(discriminator=discriminator,generator=generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "gan6.compile(\n",
    "    d_optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss_fn_D=loss_fn_D\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "d_loss= 2.3719418\n",
      "\n",
      "g_loss= -1.294208\n",
      " 1/27 [>.............................] - ETA: 3:06:26 - d_loss: 2.3719 - g_loss: -1.2942\n",
      "\n",
      "\n",
      "d_loss= 2.3445318\n",
      "\n",
      "g_loss= -0.3907235\n",
      " 2/27 [=>............................] - ETA: 3:00:36 - d_loss: 2.3582 - g_loss: -0.8425\n",
      "\n",
      "\n",
      "d_loss= 2.4356823\n",
      "\n",
      "g_loss= -0.44539598\n",
      " 3/27 [==>...........................] - ETA: 2:52:57 - d_loss: 2.3841 - g_loss: -0.7101\n",
      "\n",
      "\n",
      "d_loss= 2.3197966\n",
      "\n",
      "g_loss= -1.4367797\n",
      " 4/27 [===>..........................] - ETA: 2:45:33 - d_loss: 2.3680 - g_loss: -0.8918\n",
      "\n",
      "\n",
      "d_loss= 2.3597517\n",
      "\n",
      "g_loss= -1.3791081\n",
      " 5/27 [====>.........................] - ETA: 2:38:41 - d_loss: 2.3663 - g_loss: -0.9892\n",
      "\n",
      "\n",
      "d_loss= 2.359806\n",
      "\n",
      "g_loss= -0.95503277\n",
      " 6/27 [=====>........................] - ETA: 2:34:15 - d_loss: 2.3653 - g_loss: -0.9835\n",
      "\n",
      "\n",
      "d_loss= 2.3376777\n",
      "\n",
      "g_loss= -0.67699385\n",
      " 7/27 [======>.......................] - ETA: 2:26:36 - d_loss: 2.3613 - g_loss: -0.9397\n",
      "\n",
      "\n",
      "d_loss= 2.345596\n",
      "\n",
      "g_loss= -0.68493694\n",
      " 8/27 [=======>......................] - ETA: 2:19:22 - d_loss: 2.3593 - g_loss: -0.9079\n",
      "\n",
      "\n",
      "d_loss= 2.34346\n",
      "\n",
      "g_loss= -1.5736567\n",
      " 9/27 [=========>....................] - ETA: 2:12:16 - d_loss: 2.3576 - g_loss: -0.9819\n",
      "\n",
      "\n",
      "d_loss= 2.3647506\n",
      "\n",
      "g_loss= -0.9111431\n",
      "10/27 [==========>...................] - ETA: 2:05:05 - d_loss: 2.3583 - g_loss: -0.9748\n",
      "\n",
      "\n",
      "d_loss= 2.306394\n",
      "\n",
      "g_loss= -1.0681157\n",
      "11/27 [===========>..................] - ETA: 1:57:22 - d_loss: 2.3536 - g_loss: -0.9833\n",
      "\n",
      "\n",
      "d_loss= 2.3250005\n",
      "\n",
      "g_loss= -1.1285033\n",
      "12/27 [============>.................] - ETA: 1:50:07 - d_loss: 2.3512 - g_loss: -0.9954\n",
      "\n",
      "\n",
      "d_loss= 2.3219771\n",
      "\n",
      "g_loss= -1.6177145\n",
      "13/27 [=============>................] - ETA: 1:42:42 - d_loss: 2.3490 - g_loss: -1.0433\n",
      "\n",
      "\n",
      "d_loss= 2.346912\n",
      "\n",
      "g_loss= -1.0168388\n",
      "14/27 [==============>...............] - ETA: 1:35:33 - d_loss: 2.3488 - g_loss: -1.0414\n",
      "\n",
      "\n",
      "d_loss= 2.3090742\n",
      "\n",
      "g_loss= -0.51203614\n",
      "15/27 [===============>..............] - ETA: 1:28:06 - d_loss: 2.3462 - g_loss: -1.0061\n",
      "\n",
      "\n",
      "d_loss= 2.3431969\n",
      "\n",
      "g_loss= -1.5691174\n",
      "16/27 [================>.............] - ETA: 1:20:38 - d_loss: 2.3460 - g_loss: -1.0413\n",
      "\n",
      "\n",
      "d_loss= 2.3168924\n",
      "\n",
      "g_loss= -0.47764626\n",
      "17/27 [=================>............] - ETA: 1:13:13 - d_loss: 2.3443 - g_loss: -1.0081\n",
      "\n",
      "\n",
      "d_loss= 2.3016832\n",
      "\n",
      "g_loss= -1.0983312\n",
      "18/27 [===================>..........] - ETA: 1:05:51 - d_loss: 2.3419 - g_loss: -1.0131\n",
      "\n",
      "\n",
      "d_loss= 2.3682654\n",
      "\n",
      "g_loss= -0.5108279\n",
      "19/27 [====================>.........] - ETA: 58:32 - d_loss: 2.3433 - g_loss: -0.9867  \n",
      "\n",
      "\n",
      "d_loss= 2.3445654\n",
      "\n",
      "g_loss= -0.34472984\n",
      "20/27 [=====================>........] - ETA: 51:10 - d_loss: 2.3433 - g_loss: -0.9546\n",
      "\n",
      "\n",
      "d_loss= 2.3169937\n",
      "\n",
      "g_loss= -1.1360652\n",
      "21/27 [======================>.......] - ETA: 43:53 - d_loss: 2.3421 - g_loss: -0.9632\n",
      "\n",
      "\n",
      "d_loss= 2.2885382\n",
      "\n",
      "g_loss= -1.3003838\n",
      "22/27 [=======================>......] - ETA: 36:33 - d_loss: 2.3397 - g_loss: -0.9786\n",
      "\n",
      "\n",
      "d_loss= 2.2961965\n",
      "\n",
      "g_loss= -1.3844209\n",
      "23/27 [========================>.....] - ETA: 29:13 - d_loss: 2.3378 - g_loss: -0.9962\n",
      "\n",
      "\n",
      "d_loss= 2.272236\n",
      "\n",
      "g_loss= -1.0616037\n",
      "24/27 [=========================>....] - ETA: 21:54 - d_loss: 2.3350 - g_loss: -0.9989\n",
      "\n",
      "\n",
      "d_loss= 2.3335907\n",
      "\n",
      "g_loss= -1.6237624\n",
      "25/27 [==========================>...] - ETA: 14:36 - d_loss: 2.3350 - g_loss: -1.0239\n",
      "\n",
      "\n",
      "d_loss= 2.2884562\n",
      "\n",
      "g_loss= -0.86752284\n",
      "26/27 [===========================>..] - ETA: 7:18 - d_loss: 2.3332 - g_loss: -1.0179 \n",
      "\n",
      "\n",
      "d_loss= 2.315715\n",
      "\n",
      "g_loss= -1.2811772\n",
      "27/27 [==============================] - 11815s 438s/step - d_loss: 2.3325 - g_loss: -1.0277\n"
     ]
    }
   ],
   "source": [
    "# Deshabilitar los mensajes de información de TensorFlow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Deshabilitar los mensajes de información de OpenAI Gym\n",
    "gym.logger.set_level(40)\n",
    "\n",
    "history=gan6.fit(X_train,\n",
    "    epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3841 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3532 - accuracy: 0.0000e+00\n",
      ">Loss real: \n",
      "0.38411906361579895\n",
      ">Loss fake: \n",
      "0.3531522750854492\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos el Discriminador de GAIL en el TEST\n",
    "gan6.evaluate_D(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  0 Total reward: 500.0\n",
      "Episode  1 Total reward: 500.0\n",
      "Episode  2 Total reward: 500.0\n",
      "Episode  3 Total reward: 500.0\n",
      "Episode  4 Total reward: 500.0\n",
      "Episode  5 Total reward: 500.0\n",
      "Episode  6 Total reward: 500.0\n",
      "Episode  7 Total reward: 500.0\n",
      "Episode  8 Total reward: 500.0\n",
      "Episode  9 Total reward: 500.0\n",
      "Episode  10 Total reward: 500.0\n",
      "Episode  11 Total reward: 500.0\n",
      "Episode  12 Total reward: 500.0\n",
      "Episode  13 Total reward: 500.0\n",
      "Episode  14 Total reward: 500.0\n",
      "Episode  15 Total reward: 500.0\n",
      "Episode  16 Total reward: 500.0\n",
      "Episode  17 Total reward: 500.0\n",
      "Episode  18 Total reward: 500.0\n",
      "Episode  19 Total reward: 500.0\n",
      "Episode  20 Total reward: 500.0\n",
      "Episode  21 Total reward: 500.0\n",
      "Episode  22 Total reward: 500.0\n",
      "Episode  23 Total reward: 500.0\n",
      "Episode  24 Total reward: 500.0\n",
      "Episode  25 Total reward: 500.0\n",
      "Episode  26 Total reward: 500.0\n",
      "Episode  27 Total reward: 500.0\n",
      "Episode  28 Total reward: 500.0\n",
      "Episode  29 Total reward: 500.0\n",
      "Episode  30 Total reward: 500.0\n",
      "Episode  31 Total reward: 500.0\n",
      "Episode  32 Total reward: 500.0\n",
      "Episode  33 Total reward: 500.0\n",
      "Episode  34 Total reward: 500.0\n",
      "Episode  35 Total reward: 500.0\n",
      "Episode  36 Total reward: 500.0\n",
      "Episode  37 Total reward: 500.0\n",
      "Episode  38 Total reward: 500.0\n",
      "Episode  39 Total reward: 500.0\n",
      "Episode  40 Total reward: 500.0\n",
      "Episode  41 Total reward: 500.0\n",
      "Episode  42 Total reward: 500.0\n",
      "Episode  43 Total reward: 500.0\n",
      "Episode  44 Total reward: 500.0\n",
      "Episode  45 Total reward: 500.0\n",
      "Episode  46 Total reward: 500.0\n",
      "Episode  47 Total reward: 500.0\n",
      "Episode  48 Total reward: 500.0\n",
      "Episode  49 Total reward: 500.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recompensa de Media: 500.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos al Generador \n",
    "rewardMean=gan6.evaluate_G()\n",
    "print('\\nRecompensa de Media:', rewardMean, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción de base de datos experta con 7 trayectoria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEstados reales: \n",
      " [[ 0.00572823 -0.03831238  0.03101629  0.00900886]\n",
      " [ 0.00496198  0.15635134  0.03119646 -0.27372897]\n",
      " [ 0.00808901 -0.03920152  0.02572188  0.02862788]\n",
      " ...\n",
      " [-0.03035956 -0.1520803   0.0103268   0.24866116]\n",
      " [-0.03340117  0.04289266  0.01530002 -0.04074667]\n",
      " [-0.03254332  0.23779191  0.01448509 -0.3285633 ]]\n",
      "\tAcciones reales: \n",
      " [1 0 1 ... 1 1 0]\n",
      "\n",
      "\t Estados siguientes: \n",
      " [[ 0.00572823 -0.03831238  0.03101629  0.00900886]\n",
      " [ 0.00496198  0.15635134  0.03119646 -0.27372897]\n",
      " [ 0.00808901 -0.03920152  0.02572188  0.02862788]\n",
      " ...\n",
      " [-0.03035956 -0.1520803   0.0103268   0.24866116]\n",
      " [-0.03340117  0.04289266  0.01530002 -0.04074667]\n",
      " [-0.03254332  0.23779191  0.01448509 -0.3285633 ]]\n",
      "\n",
      "\t Recompensas: [1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "expert_observations = np.genfromtxt(\"observations_CartPole_.csv\",delimiter=\"\\t\",dtype=str)\n",
    "expert_actions = np.genfromtxt('actions_CartPole_.csv', dtype=np.int32)\n",
    "expert_next_observations = np.genfromtxt('next_observations_CartPole_.csv',delimiter=\"\\t\",dtype=str)\n",
    "expert_rewards = np.genfromtxt('rewards_CartPole_.csv', dtype=np.int32)\n",
    "expert_num_tray=np.genfromtxt('n_trayectoria_CartPole_.csv', dtype=np.int32)\n",
    "\n",
    "# Reemplazar las comas\n",
    "expert_observations = np.core.defchararray.replace(expert_observations, ',', ' ')\n",
    "\n",
    "# Reemplazar las comas\n",
    "expert_next_observations = np.core.defchararray.replace(expert_next_observations, ',', ' ')\n",
    "\n",
    "# Crear un nuevo array para almacenar los datos convertidos\n",
    "converted_observations = np.genfromtxt(expert_observations, delimiter=' ', dtype=float)\n",
    "# Crear un nuevo array para almacenar los datos convertidos\n",
    "converted_next_observations = np.genfromtxt(expert_observations, delimiter=' ', dtype=float)\n",
    "\n",
    "\n",
    "rewards=np.array(expert_rewards).reshape(-1,1)\n",
    "\n",
    "\n",
    "print(\"\\n\\tEstados reales: \\n\", converted_observations)\n",
    "print(\"\\tAcciones reales: \\n\", expert_actions)\n",
    "print(\"\\n\\t Estados siguientes: \\n\", converted_next_observations)\n",
    "print(\"\\n\\t Recompensas:\" ,expert_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500\n"
     ]
    }
   ],
   "source": [
    "longitud_trayectoria += np.count_nonzero(expert_num_tray == 6)\n",
    "print(longitud_trayectoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos quedamos solo con la primera trayectoria\n",
    "converted_observations=converted_observations[0:longitud_trayectoria]\n",
    "expert_actions=expert_actions[0:longitud_trayectoria]\n",
    "converted_next_observations=converted_next_observations[0:longitud_trayectoria]\n",
    "expert_rewards=expert_rewards[0:longitud_trayectoria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el dataset [s,a,s',r] reales y lo dividimos en training y test\n",
    "expert_a_one_hot=np.eye(env.action_space.n)[expert_actions]\n",
    "expert_rewards = expert_rewards.reshape(-1, 1)\n",
    "\n",
    "dataset1=np.concatenate([converted_observations,expert_a_one_hot],axis=1)\n",
    "dataset2=np.concatenate([dataset1,converted_next_observations],axis=1)\n",
    "dataset=np.concatenate([dataset2,expert_rewards],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento: 2800\n",
      "Nº de (ESTADOS,ACCIONES) en el conjunto de prueba: 700\n"
     ]
    }
   ],
   "source": [
    "#############################################################################\n",
    "# DIVISIÓN TRAIN Y TEST\n",
    "##############################################################################\n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test = train_test_split(dataset, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "#Imprime el número de elementos en el conjuntos de entrenamiento y prueba\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento:', len(X_train))\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de prueba:', len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "env= gym.make('CartPole-v1')\n",
    "obs,_= env.reset()\n",
    "\n",
    "# Generador\n",
    "generator=Policy_net( 'policy', env, obs)\n",
    "\n",
    "# Generamos [s,a, s', r] falsas y las políticas theta_i y theta_i+1\n",
    "observations, actions, next_observations, rewards, Old_Policy, Policy=generator.generate_fakes()\n",
    "\n",
    "# Discriminador\n",
    "discriminator=Discriminator(env, discriminator_net, converted_observations, expert_actions, converted_next_observations, expert_rewards, observations, actions, next_observations, rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan7=GAN(discriminator=discriminator,generator=generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "gan7.compile(\n",
    "    d_optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss_fn_D=loss_fn_D\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "d_loss= 2.2627785\n",
      "\n",
      "g_loss= -1.2081658\n",
      " 1/32 [..............................] - ETA: 3:43:30 - d_loss: 2.2628 - g_loss: -1.2082\n",
      "\n",
      "\n",
      "d_loss= 2.245974\n",
      "\n",
      "g_loss= -0.40965778\n",
      " 2/32 [>.............................] - ETA: 3:36:05 - d_loss: 2.2544 - g_loss: -0.8089\n",
      "\n",
      "\n",
      "d_loss= 2.2837458\n",
      "\n",
      "g_loss= -1.6632388\n",
      " 3/32 [=>............................] - ETA: 3:28:59 - d_loss: 2.2642 - g_loss: -1.0937\n",
      "\n",
      "\n",
      "d_loss= 2.268205\n",
      "\n",
      "g_loss= -1.4190702\n",
      " 4/32 [==>...........................] - ETA: 3:23:08 - d_loss: 2.2652 - g_loss: -1.1750\n",
      "\n",
      "\n",
      "d_loss= 2.2479057\n",
      "\n",
      "g_loss= -0.88088745\n",
      " 5/32 [===>..........................] - ETA: 3:14:55 - d_loss: 2.2617 - g_loss: -1.1162\n",
      "\n",
      "\n",
      "d_loss= 2.2348933\n",
      "\n",
      "g_loss= -1.2928873\n",
      " 6/32 [====>.........................] - ETA: 3:07:25 - d_loss: 2.2573 - g_loss: -1.1457\n",
      "\n",
      "\n",
      "d_loss= 2.2288628\n",
      "\n",
      "g_loss= -1.367751\n",
      " 7/32 [=====>........................] - ETA: 3:00:17 - d_loss: 2.2532 - g_loss: -1.1774\n",
      "\n",
      "\n",
      "d_loss= 2.245161\n",
      "\n",
      "g_loss= -0.9371078\n",
      " 8/32 [======>.......................] - ETA: 2:53:42 - d_loss: 2.2522 - g_loss: -1.1473\n",
      "\n",
      "\n",
      "d_loss= 2.2851424\n",
      "\n",
      "g_loss= -0.7413322\n",
      " 9/32 [=======>......................] - ETA: 2:46:12 - d_loss: 2.2559 - g_loss: -1.1022\n",
      "\n",
      "\n",
      "d_loss= 2.3160276\n",
      "\n",
      "g_loss= -1.568154\n",
      "10/32 [========>.....................] - ETA: 2:38:43 - d_loss: 2.2619 - g_loss: -1.1488\n",
      "\n",
      "\n",
      "d_loss= 2.207734\n",
      "\n",
      "g_loss= -0.4760437\n",
      "11/32 [=========>....................] - ETA: 2:31:16 - d_loss: 2.2569 - g_loss: -1.0877\n",
      "\n",
      "\n",
      "d_loss= 2.251774\n",
      "\n",
      "g_loss= -1.3151042\n",
      "12/32 [==========>...................] - ETA: 2:23:50 - d_loss: 2.2565 - g_loss: -1.1066\n",
      "\n",
      "\n",
      "d_loss= 2.215783\n",
      "\n",
      "g_loss= -0.9707567\n",
      "13/32 [===========>..................] - ETA: 2:16:44 - d_loss: 2.2534 - g_loss: -1.0962\n",
      "\n",
      "\n",
      "d_loss= 2.2997928\n",
      "\n",
      "g_loss= -1.5722791\n",
      "14/32 [============>.................] - ETA: 2:09:42 - d_loss: 2.2567 - g_loss: -1.1302\n",
      "\n",
      "\n",
      "d_loss= 2.2121203\n",
      "\n",
      "g_loss= -1.5683235\n",
      "15/32 [=============>................] - ETA: 2:02:29 - d_loss: 2.2537 - g_loss: -1.1594\n",
      "\n",
      "\n",
      "d_loss= 2.2696543\n",
      "\n",
      "g_loss= -0.60021067\n",
      "16/32 [==============>...............] - ETA: 1:55:21 - d_loss: 2.2547 - g_loss: -1.1244\n",
      "\n",
      "\n",
      "d_loss= 2.194845\n",
      "\n",
      "g_loss= -1.1986527\n",
      "17/32 [==============>...............] - ETA: 1:48:09 - d_loss: 2.2512 - g_loss: -1.1288\n",
      "\n",
      "\n",
      "d_loss= 2.2478056\n",
      "\n",
      "g_loss= -0.9791222\n",
      "18/32 [===============>..............] - ETA: 1:40:59 - d_loss: 2.2510 - g_loss: -1.1205\n",
      "\n",
      "\n",
      "d_loss= 2.2496464\n",
      "\n",
      "g_loss= -1.2776477\n",
      "19/32 [================>.............] - ETA: 1:33:43 - d_loss: 2.2509 - g_loss: -1.1288\n",
      "\n",
      "\n",
      "d_loss= 2.2241898\n",
      "\n",
      "g_loss= -0.87129754\n",
      "20/32 [=================>............] - ETA: 1:26:30 - d_loss: 2.2496 - g_loss: -1.1159\n",
      "\n",
      "\n",
      "d_loss= 2.224532\n",
      "\n",
      "g_loss= -0.94992787\n",
      "21/32 [==================>...........] - ETA: 1:19:20 - d_loss: 2.2484 - g_loss: -1.1080\n",
      "\n",
      "\n",
      "d_loss= 2.1497333\n",
      "\n",
      "g_loss= -1.0604299\n",
      "22/32 [===================>..........] - ETA: 1:12:05 - d_loss: 2.2439 - g_loss: -1.1058\n",
      "\n",
      "\n",
      "d_loss= 2.185042\n",
      "\n",
      "g_loss= -0.39053056\n",
      "23/32 [====================>.........] - ETA: 1:04:51 - d_loss: 2.2414 - g_loss: -1.0747\n",
      "\n",
      "\n",
      "d_loss= 2.2307053\n",
      "\n",
      "g_loss= -0.5917254\n",
      "24/32 [=====================>........] - ETA: 57:38 - d_loss: 2.2409 - g_loss: -1.0546  \n",
      "\n",
      "\n",
      "d_loss= 2.21772\n",
      "\n",
      "g_loss= -1.5646499\n",
      "25/32 [======================>.......] - ETA: 50:25 - d_loss: 2.2400 - g_loss: -1.0750\n",
      "\n",
      "\n",
      "d_loss= 2.21964\n",
      "\n",
      "g_loss= -1.5339625\n",
      "26/32 [=======================>......] - ETA: 43:12 - d_loss: 2.2392 - g_loss: -1.0927\n",
      "\n",
      "\n",
      "d_loss= 2.1837764\n",
      "\n",
      "g_loss= -1.068163\n",
      "27/32 [========================>.....] - ETA: 35:59 - d_loss: 2.2372 - g_loss: -1.0917\n",
      "\n",
      "\n",
      "d_loss= 2.2525961\n",
      "\n",
      "g_loss= -1.1319722\n",
      "28/32 [=========================>....] - ETA: 28:47 - d_loss: 2.2377 - g_loss: -1.0932\n",
      "\n",
      "\n",
      "d_loss= 2.1962304\n",
      "\n",
      "g_loss= -1.4990292\n",
      "29/32 [==========================>...] - ETA: 21:35 - d_loss: 2.2363 - g_loss: -1.1072\n",
      "\n",
      "\n",
      "d_loss= 2.1786141\n",
      "\n",
      "g_loss= -1.4936079\n",
      "30/32 [===========================>..] - ETA: 14:23 - d_loss: 2.2344 - g_loss: -1.1201\n",
      "\n",
      "\n",
      "d_loss= 2.2211108\n",
      "\n",
      "g_loss= -0.9561572\n",
      "31/32 [============================>.] - ETA: 7:11 - d_loss: 2.2339 - g_loss: -1.1148 \n",
      "\n",
      "\n",
      "d_loss= 2.1726747\n",
      "\n",
      "g_loss= -0.6255949\n",
      "32/32 [==============================] - 13807s 431s/step - d_loss: 2.2320 - g_loss: -1.0995\n"
     ]
    }
   ],
   "source": [
    "# Deshabilitar los mensajes de información de TensorFlow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Deshabilitar los mensajes de información de OpenAI Gym\n",
    "gym.logger.set_level(40)\n",
    "\n",
    "history=gan7.fit(X_train,\n",
    "    epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2909 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3447 - accuracy: 0.0000e+00\n",
      ">Loss real: \n",
      "0.29089611768722534\n",
      ">Loss fake: \n",
      "0.3447364866733551\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos el Discriminador de GAIL en el TEST\n",
    "gan7.evaluate_D(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  0 Total reward: 500.0\n",
      "Episode  1 Total reward: 500.0\n",
      "Episode  2 Total reward: 500.0\n",
      "Episode  3 Total reward: 500.0\n",
      "Episode  4 Total reward: 500.0\n",
      "Episode  5 Total reward: 500.0\n",
      "Episode  6 Total reward: 500.0\n",
      "Episode  7 Total reward: 500.0\n",
      "Episode  8 Total reward: 500.0\n",
      "Episode  9 Total reward: 500.0\n",
      "Episode  10 Total reward: 500.0\n",
      "Episode  11 Total reward: 500.0\n",
      "Episode  12 Total reward: 500.0\n",
      "Episode  13 Total reward: 500.0\n",
      "Episode  14 Total reward: 500.0\n",
      "Episode  15 Total reward: 500.0\n",
      "Episode  16 Total reward: 500.0\n",
      "Episode  17 Total reward: 500.0\n",
      "Episode  18 Total reward: 500.0\n",
      "Episode  19 Total reward: 500.0\n",
      "Episode  20 Total reward: 500.0\n",
      "Episode  21 Total reward: 500.0\n",
      "Episode  22 Total reward: 500.0\n",
      "Episode  23 Total reward: 500.0\n",
      "Episode  24 Total reward: 500.0\n",
      "Episode  25 Total reward: 500.0\n",
      "Episode  26 Total reward: 500.0\n",
      "Episode  27 Total reward: 500.0\n",
      "Episode  28 Total reward: 500.0\n",
      "Episode  29 Total reward: 500.0\n",
      "Episode  30 Total reward: 500.0\n",
      "Episode  31 Total reward: 500.0\n",
      "Episode  32 Total reward: 500.0\n",
      "Episode  33 Total reward: 500.0\n",
      "Episode  34 Total reward: 500.0\n",
      "Episode  35 Total reward: 500.0\n",
      "Episode  36 Total reward: 500.0\n",
      "Episode  37 Total reward: 500.0\n",
      "Episode  38 Total reward: 500.0\n",
      "Episode  39 Total reward: 500.0\n",
      "Episode  40 Total reward: 500.0\n",
      "Episode  41 Total reward: 500.0\n",
      "Episode  42 Total reward: 500.0\n",
      "Episode  43 Total reward: 500.0\n",
      "Episode  44 Total reward: 500.0\n",
      "Episode  45 Total reward: 500.0\n",
      "Episode  46 Total reward: 500.0\n",
      "Episode  47 Total reward: 500.0\n",
      "Episode  48 Total reward: 500.0\n",
      "Episode  49 Total reward: 500.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recompensa de Media: 500.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos al Generador \n",
    "rewardMean=gan7.evaluate_G()\n",
    "print('\\nRecompensa de Media:', rewardMean, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción de base de datos experta con 8 trayectoria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEstados reales: \n",
      " [[ 0.00572823 -0.03831238  0.03101629  0.00900886]\n",
      " [ 0.00496198  0.15635134  0.03119646 -0.27372897]\n",
      " [ 0.00808901 -0.03920152  0.02572188  0.02862788]\n",
      " ...\n",
      " [-0.03035956 -0.1520803   0.0103268   0.24866116]\n",
      " [-0.03340117  0.04289266  0.01530002 -0.04074667]\n",
      " [-0.03254332  0.23779191  0.01448509 -0.3285633 ]]\n",
      "\tAcciones reales: \n",
      " [1 0 1 ... 1 1 0]\n",
      "\n",
      "\t Estados siguientes: \n",
      " [[ 0.00572823 -0.03831238  0.03101629  0.00900886]\n",
      " [ 0.00496198  0.15635134  0.03119646 -0.27372897]\n",
      " [ 0.00808901 -0.03920152  0.02572188  0.02862788]\n",
      " ...\n",
      " [-0.03035956 -0.1520803   0.0103268   0.24866116]\n",
      " [-0.03340117  0.04289266  0.01530002 -0.04074667]\n",
      " [-0.03254332  0.23779191  0.01448509 -0.3285633 ]]\n",
      "\n",
      "\t Recompensas: [1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "expert_observations = np.genfromtxt(\"observations_CartPole_.csv\",delimiter=\"\\t\",dtype=str)\n",
    "expert_actions = np.genfromtxt('actions_CartPole_.csv', dtype=np.int32)\n",
    "expert_next_observations = np.genfromtxt('next_observations_CartPole_.csv',delimiter=\"\\t\",dtype=str)\n",
    "expert_rewards = np.genfromtxt('rewards_CartPole_.csv', dtype=np.int32)\n",
    "expert_num_tray=np.genfromtxt('n_trayectoria_CartPole_.csv', dtype=np.int32)\n",
    "\n",
    "# Reemplazar las comas\n",
    "expert_observations = np.core.defchararray.replace(expert_observations, ',', ' ')\n",
    "\n",
    "# Reemplazar las comas\n",
    "expert_next_observations = np.core.defchararray.replace(expert_next_observations, ',', ' ')\n",
    "\n",
    "# Crear un nuevo array para almacenar los datos convertidos\n",
    "converted_observations = np.genfromtxt(expert_observations, delimiter=' ', dtype=float)\n",
    "# Crear un nuevo array para almacenar los datos convertidos\n",
    "converted_next_observations = np.genfromtxt(expert_observations, delimiter=' ', dtype=float)\n",
    "\n",
    "\n",
    "rewards=np.array(expert_rewards).reshape(-1,1)\n",
    "\n",
    "\n",
    "print(\"\\n\\tEstados reales: \\n\", converted_observations)\n",
    "print(\"\\tAcciones reales: \\n\", expert_actions)\n",
    "print(\"\\n\\t Estados siguientes: \\n\", converted_next_observations)\n",
    "print(\"\\n\\t Recompensas:\" ,expert_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    }
   ],
   "source": [
    "longitud_trayectoria += np.count_nonzero(expert_num_tray == 7)\n",
    "print(longitud_trayectoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos quedamos solo con la primera trayectoria\n",
    "converted_observations=converted_observations[0:longitud_trayectoria]\n",
    "expert_actions=expert_actions[0:longitud_trayectoria]\n",
    "converted_next_observations=converted_next_observations[0:longitud_trayectoria]\n",
    "expert_rewards=expert_rewards[0:longitud_trayectoria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el dataset [s,a,s',r] reales y lo dividimos en training y test\n",
    "expert_a_one_hot=np.eye(env.action_space.n)[expert_actions]\n",
    "expert_rewards = expert_rewards.reshape(-1, 1)\n",
    "\n",
    "dataset1=np.concatenate([converted_observations,expert_a_one_hot],axis=1)\n",
    "dataset2=np.concatenate([dataset1,converted_next_observations],axis=1)\n",
    "dataset=np.concatenate([dataset2,expert_rewards],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento: 3200\n",
      "Nº de (ESTADOS,ACCIONES) en el conjunto de prueba: 800\n"
     ]
    }
   ],
   "source": [
    "#############################################################################\n",
    "# DIVISIÓN TRAIN Y TEST\n",
    "##############################################################################\n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test = train_test_split(dataset, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "#Imprime el número de elementos en el conjuntos de entrenamiento y prueba\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento:', len(X_train))\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de prueba:', len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "env= gym.make('CartPole-v1')\n",
    "obs,_= env.reset()\n",
    "\n",
    "# Generador\n",
    "generator=Policy_net( 'policy', env, obs)\n",
    "\n",
    "# Generamos [s,a, s', r] falsas y las políticas theta_i y theta_i+1\n",
    "observations, actions, next_observations, rewards, Old_Policy, Policy=generator.generate_fakes()\n",
    "\n",
    "# Discriminador\n",
    "discriminator=Discriminator(env, discriminator_net, converted_observations, expert_actions, converted_next_observations, expert_rewards, observations, actions, next_observations, rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan8=GAN(discriminator=discriminator,generator=generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "gan8.compile(\n",
    "    d_optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss_fn_D=loss_fn_D\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "d_loss= 2.1697774\n",
      "\n",
      "g_loss= -1.5597289\n",
      " 1/36 [..............................] - ETA: 4:10:34 - d_loss: 2.1698 - g_loss: -1.5597\n",
      "\n",
      "\n",
      "d_loss= 2.1399043\n",
      "\n",
      "g_loss= -0.35017142\n",
      " 2/36 [>.............................] - ETA: 4:06:15 - d_loss: 2.1548 - g_loss: -0.9550\n",
      "\n",
      "\n",
      "d_loss= 2.1626096\n",
      "\n",
      "g_loss= -1.0183012\n",
      " 3/36 [=>............................] - ETA: 3:58:29 - d_loss: 2.1574 - g_loss: -0.9761\n",
      "\n",
      "\n",
      "d_loss= 2.2157388\n",
      "\n",
      "g_loss= -0.73820883\n",
      " 4/36 [==>...........................] - ETA: 3:52:57 - d_loss: 2.1720 - g_loss: -0.9166\n",
      "\n",
      "\n",
      "d_loss= 2.1666217\n",
      "\n",
      "g_loss= -1.483122\n",
      " 5/36 [===>..........................] - ETA: 3:44:42 - d_loss: 2.1709 - g_loss: -1.0299\n",
      "\n",
      "\n",
      "d_loss= 2.1323433\n",
      "\n",
      "g_loss= -0.5879846\n",
      " 6/36 [====>.........................] - ETA: 3:36:37 - d_loss: 2.1645 - g_loss: -0.9563\n",
      "\n",
      "\n",
      "d_loss= 2.1971912\n",
      "\n",
      "g_loss= -0.7611923\n",
      " 7/36 [====>.........................] - ETA: 3:29:12 - d_loss: 2.1692 - g_loss: -0.9284\n",
      "\n",
      "\n",
      "d_loss= 2.173633\n",
      "\n",
      "g_loss= -0.5420405\n",
      " 8/36 [=====>........................] - ETA: 3:22:00 - d_loss: 2.1697 - g_loss: -0.8801\n",
      "\n",
      "\n",
      "d_loss= 2.133335\n",
      "\n",
      "g_loss= -1.0228686\n",
      " 9/36 [======>.......................] - ETA: 3:14:54 - d_loss: 2.1657 - g_loss: -0.8960\n",
      "\n",
      "\n",
      "d_loss= 2.1309495\n",
      "\n",
      "g_loss= -1.5634849\n",
      "10/36 [=======>......................] - ETA: 3:07:59 - d_loss: 2.1622 - g_loss: -0.9627\n",
      "\n",
      "\n",
      "d_loss= 2.176223\n",
      "\n",
      "g_loss= -0.32871684\n",
      "11/36 [========>.....................] - ETA: 3:01:49 - d_loss: 2.1635 - g_loss: -0.9051\n",
      "\n",
      "\n",
      "d_loss= 2.1471536\n",
      "\n",
      "g_loss= -0.9584531\n",
      "12/36 [=========>....................] - ETA: 2:55:36 - d_loss: 2.1621 - g_loss: -0.9095\n",
      "\n",
      "\n",
      "d_loss= 2.1611786\n",
      "\n",
      "g_loss= -0.7199179\n",
      "13/36 [=========>....................] - ETA: 2:49:06 - d_loss: 2.1621 - g_loss: -0.8949\n",
      "\n",
      "\n",
      "d_loss= 2.1658843\n",
      "\n",
      "g_loss= -1.0482764\n",
      "14/36 [==========>...................] - ETA: 2:42:33 - d_loss: 2.1623 - g_loss: -0.9059\n",
      "\n",
      "\n",
      "d_loss= 2.12685\n",
      "\n",
      "g_loss= -0.5800897\n",
      "15/36 [===========>..................] - ETA: 2:35:46 - d_loss: 2.1600 - g_loss: -0.8842\n",
      "\n",
      "\n",
      "d_loss= 2.1680515\n",
      "\n",
      "g_loss= -0.80608743\n",
      "16/36 [============>.................] - ETA: 2:28:41 - d_loss: 2.1605 - g_loss: -0.8793\n",
      "\n",
      "\n",
      "d_loss= 2.1443417\n",
      "\n",
      "g_loss= -1.6255102\n",
      "17/36 [=============>................] - ETA: 2:21:38 - d_loss: 2.1595 - g_loss: -0.9232\n",
      "\n",
      "\n",
      "d_loss= 2.1239781\n",
      "\n",
      "g_loss= -0.44879624\n",
      "18/36 [==============>...............] - ETA: 2:14:24 - d_loss: 2.1575 - g_loss: -0.8968\n",
      "\n",
      "\n",
      "d_loss= 2.138583\n",
      "\n",
      "g_loss= -0.41159496\n",
      "19/36 [==============>...............] - ETA: 2:07:06 - d_loss: 2.1565 - g_loss: -0.8713\n",
      "\n",
      "\n",
      "d_loss= 2.1876886\n",
      "\n",
      "g_loss= -1.5237064\n",
      "20/36 [===============>..............] - ETA: 1:59:56 - d_loss: 2.1581 - g_loss: -0.9039\n",
      "\n",
      "\n",
      "d_loss= 2.1193557\n",
      "\n",
      "g_loss= -1.5515462\n",
      "21/36 [================>.............] - ETA: 1:52:35 - d_loss: 2.1563 - g_loss: -0.9348\n",
      "\n",
      "\n",
      "d_loss= 2.1433818\n",
      "\n",
      "g_loss= -0.5170047\n",
      "22/36 [=================>............] - ETA: 1:45:14 - d_loss: 2.1557 - g_loss: -0.9158\n",
      "\n",
      "\n",
      "d_loss= 2.2079396\n",
      "\n",
      "g_loss= -0.40856555\n",
      "23/36 [==================>...........] - ETA: 1:37:48 - d_loss: 2.1579 - g_loss: -0.8937\n",
      "\n",
      "\n",
      "d_loss= 2.0946949\n",
      "\n",
      "g_loss= -0.89833105\n",
      "24/36 [===================>..........] - ETA: 1:30:21 - d_loss: 2.1553 - g_loss: -0.8939\n",
      "\n",
      "\n",
      "d_loss= 2.1575553\n",
      "\n",
      "g_loss= -1.4522952\n",
      "25/36 [===================>..........] - ETA: 1:22:55 - d_loss: 2.1554 - g_loss: -0.9162\n",
      "\n",
      "\n",
      "d_loss= 2.1490211\n",
      "\n",
      "g_loss= -0.99889016\n",
      "26/36 [====================>.........] - ETA: 1:15:31 - d_loss: 2.1552 - g_loss: -0.9194\n",
      "\n",
      "\n",
      "d_loss= 2.1620271\n",
      "\n",
      "g_loss= -0.93574756\n",
      "27/36 [=====================>........] - ETA: 1:07:59 - d_loss: 2.1554 - g_loss: -0.9200\n",
      "\n",
      "\n",
      "d_loss= 2.1305737\n",
      "\n",
      "g_loss= -1.5400357\n",
      "28/36 [======================>.......] - ETA: 1:00:28 - d_loss: 2.1545 - g_loss: -0.9422\n",
      "\n",
      "\n",
      "d_loss= 2.0861297\n",
      "\n",
      "g_loss= -1.2530702\n",
      "29/36 [=======================>......] - ETA: 52:56 - d_loss: 2.1522 - g_loss: -0.9529  \n",
      "\n",
      "\n",
      "d_loss= 2.1370475\n",
      "\n",
      "g_loss= -1.5395324\n",
      "30/36 [========================>.....] - ETA: 45:24 - d_loss: 2.1517 - g_loss: -0.9724\n",
      "\n",
      "\n",
      "d_loss= 2.1114063\n",
      "\n",
      "g_loss= -0.67850065\n",
      "31/36 [========================>.....] - ETA: 37:51 - d_loss: 2.1504 - g_loss: -0.9630\n",
      "\n",
      "\n",
      "d_loss= 2.10041\n",
      "\n",
      "g_loss= -0.9943178\n",
      "32/36 [=========================>....] - ETA: 30:18 - d_loss: 2.1488 - g_loss: -0.9639\n",
      "\n",
      "\n",
      "d_loss= 2.1920521\n",
      "\n",
      "g_loss= -0.880011\n",
      "33/36 [==========================>...] - ETA: 22:45 - d_loss: 2.1501 - g_loss: -0.9614\n",
      "\n",
      "\n",
      "d_loss= 2.17302\n",
      "\n",
      "g_loss= -0.6461826\n",
      "34/36 [===========================>..] - ETA: 15:10 - d_loss: 2.1508 - g_loss: -0.9521\n",
      "\n",
      "\n",
      "d_loss= 2.1352913\n",
      "\n",
      "g_loss= -1.1240283\n",
      "35/36 [============================>.] - ETA: 7:34 - d_loss: 2.1503 - g_loss: -0.9570 \n",
      "\n",
      "\n",
      "d_loss= 2.0892463\n",
      "\n",
      "g_loss= -1.5654277\n",
      "36/36 [==============================] - 16319s 454s/step - d_loss: 2.1486 - g_loss: -0.9739\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "d_loss= 1.9028171# Deshabilitar los mensajes de información de TensorFlow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Deshabilitar los mensajes de información de OpenAI Gym\n",
    "gym.logger.set_level(40)\n",
    "\n",
    "history=gan8.fit(X_train,\n",
    "    epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1944 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2767 - accuracy: 0.0000e+00\n",
      ">Loss real: \n",
      "0.19435139000415802\n",
      ">Loss fake: \n",
      "0.276705265045166\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos el Discriminador de GAIL en el TEST\n",
    "gan8.evaluate_D(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  0 Total reward: 500.0\n",
      "Episode  1 Total reward: 500.0\n",
      "Episode  2 Total reward: 500.0\n",
      "Episode  3 Total reward: 500.0\n",
      "Episode  4 Total reward: 500.0\n",
      "Episode  5 Total reward: 500.0\n",
      "Episode  6 Total reward: 500.0\n",
      "Episode  7 Total reward: 500.0\n",
      "Episode  8 Total reward: 500.0\n",
      "Episode  9 Total reward: 500.0\n",
      "Episode  10 Total reward: 500.0\n",
      "Episode  11 Total reward: 500.0\n",
      "Episode  12 Total reward: 500.0\n",
      "Episode  13 Total reward: 500.0\n",
      "Episode  14 Total reward: 500.0\n",
      "Episode  15 Total reward: 500.0\n",
      "Episode  16 Total reward: 500.0\n",
      "Episode  17 Total reward: 500.0\n",
      "Episode  18 Total reward: 500.0\n",
      "Episode  19 Total reward: 500.0\n",
      "Episode  20 Total reward: 500.0\n",
      "Episode  21 Total reward: 500.0\n",
      "Episode  22 Total reward: 500.0\n",
      "Episode  23 Total reward: 500.0\n",
      "Episode  24 Total reward: 500.0\n",
      "Episode  25 Total reward: 500.0\n",
      "Episode  26 Total reward: 500.0\n",
      "Episode  27 Total reward: 500.0\n",
      "Episode  28 Total reward: 500.0\n",
      "Episode  29 Total reward: 500.0\n",
      "Episode  30 Total reward: 500.0\n",
      "Episode  31 Total reward: 500.0\n",
      "Episode  32 Total reward: 500.0\n",
      "Episode  33 Total reward: 500.0\n",
      "Episode  34 Total reward: 500.0\n",
      "Episode  35 Total reward: 500.0\n",
      "Episode  36 Total reward: 500.0\n",
      "Episode  37 Total reward: 500.0\n",
      "Episode  38 Total reward: 500.0\n",
      "Episode  39 Total reward: 500.0\n",
      "Episode  40 Total reward: 500.0\n",
      "Episode  41 Total reward: 500.0\n",
      "Episode  42 Total reward: 500.0\n",
      "Episode  43 Total reward: 500.0\n",
      "Episode  44 Total reward: 500.0\n",
      "Episode  45 Total reward: 500.0\n",
      "Episode  46 Total reward: 500.0\n",
      "Episode  47 Total reward: 500.0\n",
      "Episode  48 Total reward: 500.0\n",
      "Episode  49 Total reward: 500.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recompensa de Media: 500.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos al Generador \n",
    "rewardMean=gan8.evaluate_G()\n",
    "print('\\nRecompensa de Media:', rewardMean, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción de base de datos experta con 9 trayectoria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEstados reales: \n",
      " [[ 0.00572823 -0.03831238  0.03101629  0.00900886]\n",
      " [ 0.00496198  0.15635134  0.03119646 -0.27372897]\n",
      " [ 0.00808901 -0.03920152  0.02572188  0.02862788]\n",
      " ...\n",
      " [-0.03035956 -0.1520803   0.0103268   0.24866116]\n",
      " [-0.03340117  0.04289266  0.01530002 -0.04074667]\n",
      " [-0.03254332  0.23779191  0.01448509 -0.3285633 ]]\n",
      "\tAcciones reales: \n",
      " [1 0 1 ... 1 1 0]\n",
      "\n",
      "\t Estados siguientes: \n",
      " [[ 0.00572823 -0.03831238  0.03101629  0.00900886]\n",
      " [ 0.00496198  0.15635134  0.03119646 -0.27372897]\n",
      " [ 0.00808901 -0.03920152  0.02572188  0.02862788]\n",
      " ...\n",
      " [-0.03035956 -0.1520803   0.0103268   0.24866116]\n",
      " [-0.03340117  0.04289266  0.01530002 -0.04074667]\n",
      " [-0.03254332  0.23779191  0.01448509 -0.3285633 ]]\n",
      "\n",
      "\t Recompensas: [1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "expert_observations = np.genfromtxt(\"observations_CartPole_.csv\",delimiter=\"\\t\",dtype=str)\n",
    "expert_actions = np.genfromtxt('actions_CartPole_.csv', dtype=np.int32)\n",
    "expert_next_observations = np.genfromtxt('next_observations_CartPole_.csv',delimiter=\"\\t\",dtype=str)\n",
    "expert_rewards = np.genfromtxt('rewards_CartPole_.csv', dtype=np.int32)\n",
    "expert_num_tray=np.genfromtxt('n_trayectoria_CartPole_.csv', dtype=np.int32)\n",
    "\n",
    "# Reemplazar las comas\n",
    "expert_observations = np.core.defchararray.replace(expert_observations, ',', ' ')\n",
    "\n",
    "# Reemplazar las comas\n",
    "expert_next_observations = np.core.defchararray.replace(expert_next_observations, ',', ' ')\n",
    "\n",
    "# Crear un nuevo array para almacenar los datos convertidos\n",
    "converted_observations = np.genfromtxt(expert_observations, delimiter=' ', dtype=float)\n",
    "# Crear un nuevo array para almacenar los datos convertidos\n",
    "converted_next_observations = np.genfromtxt(expert_observations, delimiter=' ', dtype=float)\n",
    "\n",
    "\n",
    "rewards=np.array(expert_rewards).reshape(-1,1)\n",
    "\n",
    "\n",
    "print(\"\\n\\tEstados reales: \\n\", converted_observations)\n",
    "print(\"\\tAcciones reales: \\n\", expert_actions)\n",
    "print(\"\\n\\t Estados siguientes: \\n\", converted_next_observations)\n",
    "print(\"\\n\\t Recompensas:\" ,expert_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500\n"
     ]
    }
   ],
   "source": [
    "longitud_trayectoria += np.count_nonzero(expert_num_tray == 8)\n",
    "print(longitud_trayectoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos quedamos solo con la primera trayectoria\n",
    "converted_observations=converted_observations[0:longitud_trayectoria]\n",
    "expert_actions=expert_actions[0:longitud_trayectoria]\n",
    "converted_next_observations=converted_next_observations[0:longitud_trayectoria]\n",
    "expert_rewards=expert_rewards[0:longitud_trayectoria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el dataset [s,a,s',r] reales y lo dividimos en training y test\n",
    "expert_a_one_hot=np.eye(env.action_space.n)[expert_actions]\n",
    "expert_rewards = expert_rewards.reshape(-1, 1)\n",
    "\n",
    "dataset1=np.concatenate([converted_observations,expert_a_one_hot],axis=1)\n",
    "dataset2=np.concatenate([dataset1,converted_next_observations],axis=1)\n",
    "dataset=np.concatenate([dataset2,expert_rewards],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento: 3600\n",
      "Nº de (ESTADOS,ACCIONES) en el conjunto de prueba: 900\n"
     ]
    }
   ],
   "source": [
    "#############################################################################\n",
    "# DIVISIÓN TRAIN Y TEST\n",
    "##############################################################################\n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test = train_test_split(dataset, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "#Imprime el número de elementos en el conjuntos de entrenamiento y prueba\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento:', len(X_train))\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de prueba:', len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "env= gym.make('CartPole-v1')\n",
    "obs,_= env.reset()\n",
    "\n",
    "# Generador\n",
    "generator=Policy_net( 'policy', env, obs)\n",
    "\n",
    "# Generamos [s,a, s', r] falsas y las políticas theta_i y theta_i+1\n",
    "observations, actions, next_observations, rewards, Old_Policy, Policy=generator.generate_fakes()\n",
    "\n",
    "# Discriminador\n",
    "discriminator=Discriminator(env, discriminator_net, converted_observations, expert_actions, converted_next_observations, expert_rewards, observations, actions, next_observations, rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan9=GAN(discriminator=discriminator,generator=generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "gan9.compile(\n",
    "    d_optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss_fn_D=loss_fn_D\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "d_loss= 2.101496\n",
      "\n",
      "g_loss= -1.5698965\n",
      " 1/40 [..............................] - ETA: 4:40:48 - d_loss: 2.1015 - g_loss: -1.5699\n",
      "\n",
      "\n",
      "d_loss= 2.0969992\n",
      "\n",
      "g_loss= -1.5865163\n",
      " 2/40 [>.............................] - ETA: 4:31:32 - d_loss: 2.0992 - g_loss: -1.5782\n",
      "\n",
      "\n",
      "d_loss= 2.104494\n",
      "\n",
      "g_loss= -0.40111595\n",
      " 3/40 [=>............................] - ETA: 4:25:11 - d_loss: 2.1010 - g_loss: -1.1858\n",
      "\n",
      "\n",
      "d_loss= 2.0349522\n",
      "\n",
      "g_loss= -0.3887611\n",
      " 4/40 [==>...........................] - ETA: 4:18:39 - d_loss: 2.0845 - g_loss: -0.9866\n",
      "\n",
      "\n",
      "d_loss= 2.0286617\n",
      "\n",
      "g_loss= -0.46036655\n",
      " 5/40 [==>...........................] - ETA: 4:11:23 - d_loss: 2.0733 - g_loss: -0.8813\n",
      "\n",
      "\n",
      "d_loss= 2.090818\n",
      "\n",
      "g_loss= -0.46212015\n",
      " 6/40 [===>..........................] - ETA: 4:05:35 - d_loss: 2.0762 - g_loss: -0.8115\n",
      "\n",
      "\n",
      "d_loss= 2.1079206\n",
      "\n",
      "g_loss= -0.84285665\n",
      " 7/40 [====>.........................] - ETA: 3:58:06 - d_loss: 2.0808 - g_loss: -0.8159\n",
      "\n",
      "\n",
      "d_loss= 2.0476854\n",
      "\n",
      "g_loss= -1.0931921\n",
      " 8/40 [=====>........................] - ETA: 3:51:50 - d_loss: 2.0766 - g_loss: -0.8506\n",
      "\n",
      "\n",
      "d_loss= 2.0372944\n",
      "\n",
      "g_loss= -1.3648947\n",
      " 9/40 [=====>........................] - ETA: 3:45:29 - d_loss: 2.0723 - g_loss: -0.9077\n",
      "\n",
      "\n",
      "d_loss= 2.0774992\n",
      "\n",
      "g_loss= -1.5488328\n",
      "10/40 [======>.......................] - ETA: 3:38:28 - d_loss: 2.0728 - g_loss: -0.9719\n",
      "\n",
      "\n",
      "d_loss= 2.0515149\n",
      "\n",
      "g_loss= -1.0432906\n",
      "11/40 [=======>......................] - ETA: 3:31:22 - d_loss: 2.0708 - g_loss: -0.9783\n",
      "\n",
      "\n",
      "d_loss= 2.1141222\n",
      "\n",
      "g_loss= -1.3677001\n",
      "12/40 [========>.....................] - ETA: 3:23:59 - d_loss: 2.0745 - g_loss: -1.0108\n",
      "\n",
      "\n",
      "d_loss= 2.0993068\n",
      "\n",
      "g_loss= -0.42526487\n",
      "13/40 [========>.....................] - ETA: 3:16:28 - d_loss: 2.0764 - g_loss: -0.9658\n",
      "\n",
      "\n",
      "d_loss= 2.0635233\n",
      "\n",
      "g_loss= -1.614988\n",
      "14/40 [=========>....................] - ETA: 3:08:56 - d_loss: 2.0754 - g_loss: -1.0121\n",
      "\n",
      "\n",
      "d_loss= 2.060589\n",
      "\n",
      "g_loss= -0.7138483\n",
      "15/40 [==========>...................] - ETA: 3:01:40 - d_loss: 2.0745 - g_loss: -0.9922\n",
      "\n",
      "\n",
      "d_loss= 2.0543783\n",
      "\n",
      "g_loss= -0.845215\n",
      "16/40 [===========>..................] - ETA: 2:54:31 - d_loss: 2.0732 - g_loss: -0.9831\n",
      "\n",
      "\n",
      "d_loss= 2.0600545\n",
      "\n",
      "g_loss= -1.3322208\n",
      "17/40 [===========>..................] - ETA: 2:47:16 - d_loss: 2.0724 - g_loss: -1.0036\n",
      "\n",
      "\n",
      "d_loss= 2.1072898\n",
      "\n",
      "g_loss= -0.5227203\n",
      "18/40 [============>.................] - ETA: 2:40:22 - d_loss: 2.0744 - g_loss: -0.9769\n",
      "\n",
      "\n",
      "d_loss= 2.0233624\n",
      "\n",
      "g_loss= -1.5640719\n",
      "19/40 [=============>................] - ETA: 2:33:09 - d_loss: 2.0717 - g_loss: -1.0078\n",
      "\n",
      "\n",
      "d_loss= 2.0349085\n",
      "\n",
      "g_loss= -1.2828935\n",
      "20/40 [==============>...............] - ETA: 2:25:49 - d_loss: 2.0698 - g_loss: -1.0215\n",
      "\n",
      "\n",
      "d_loss= 2.0209663\n",
      "\n",
      "g_loss= -0.70737565\n",
      "21/40 [==============>...............] - ETA: 2:18:35 - d_loss: 2.0675 - g_loss: -1.0066\n",
      "\n",
      "\n",
      "d_loss= 2.0505416\n",
      "\n",
      "g_loss= -0.73228335\n",
      "22/40 [===============>..............] - ETA: 2:11:21 - d_loss: 2.0667 - g_loss: -0.9941\n",
      "\n",
      "\n",
      "d_loss= 2.052491\n",
      "\n",
      "g_loss= -0.6486097\n",
      "23/40 [================>.............] - ETA: 2:04:03 - d_loss: 2.0661 - g_loss: -0.9791\n",
      "\n",
      "\n",
      "d_loss= 2.082284\n",
      "\n",
      "g_loss= -1.5595667\n",
      "24/40 [=================>............] - ETA: 1:56:51 - d_loss: 2.0668 - g_loss: -1.0033\n",
      "\n",
      "\n",
      "d_loss= 2.0359333\n",
      "\n",
      "g_loss= -1.2824173\n",
      "25/40 [=================>............] - ETA: 1:49:32 - d_loss: 2.0656 - g_loss: -1.0144\n",
      "\n",
      "\n",
      "d_loss= 2.0615582\n",
      "\n",
      "g_loss= -1.1069442\n",
      "26/40 [==================>...........] - ETA: 1:42:10 - d_loss: 2.0654 - g_loss: -1.0180\n",
      "\n",
      "\n",
      "d_loss= 2.0181983\n",
      "\n",
      "g_loss= -0.80452037\n",
      "27/40 [===================>..........] - ETA: 1:34:52 - d_loss: 2.0637 - g_loss: -1.0101\n",
      "\n",
      "\n",
      "d_loss= 1.9887295\n",
      "\n",
      "g_loss= -0.45030773\n",
      "28/40 [====================>.........] - ETA: 1:27:35 - d_loss: 2.0610 - g_loss: -0.9901\n",
      "\n",
      "\n",
      "d_loss= 2.0206606\n",
      "\n",
      "g_loss= -1.3030667\n",
      "29/40 [====================>.........] - ETA: 1:20:14 - d_loss: 2.0596 - g_loss: -1.0009\n",
      "\n",
      "\n",
      "d_loss= 1.9740933\n",
      "\n",
      "g_loss= -0.6703548\n",
      "30/40 [=====================>........] - ETA: 1:12:54 - d_loss: 2.0567 - g_loss: -0.9899\n",
      "\n",
      "\n",
      "d_loss= 2.014513\n",
      "\n",
      "g_loss= -1.5838664\n",
      "31/40 [======================>.......] - ETA: 1:05:36 - d_loss: 2.0554 - g_loss: -1.0090\n",
      "\n",
      "\n",
      "d_loss= 2.0364125\n",
      "\n",
      "g_loss= -1.2525249\n",
      "32/40 [=======================>......] - ETA: 58:19 - d_loss: 2.0548 - g_loss: -1.0166  \n",
      "\n",
      "\n",
      "d_loss= 2.0192792\n",
      "\n",
      "g_loss= -1.3276261\n",
      "33/40 [=======================>......] - ETA: 51:01 - d_loss: 2.0537 - g_loss: -1.0261\n",
      "\n",
      "\n",
      "d_loss= 2.0387557\n",
      "\n",
      "g_loss= -1.526291\n",
      "34/40 [========================>.....] - ETA: 43:45 - d_loss: 2.0533 - g_loss: -1.0408\n",
      "\n",
      "\n",
      "d_loss= 2.0538082\n",
      "\n",
      "g_loss= -0.5370432\n",
      "35/40 [=========================>....] - ETA: 36:27 - d_loss: 2.0533 - g_loss: -1.0264\n",
      "\n",
      "\n",
      "d_loss= 2.0241377\n",
      "\n",
      "g_loss= -0.55525064\n",
      "36/40 [==========================>...] - ETA: 29:10 - d_loss: 2.0525 - g_loss: -1.0133\n",
      "\n",
      "\n",
      "d_loss= 2.0218415\n",
      "\n",
      "g_loss= -1.4747176\n",
      "37/40 [==========================>...] - ETA: 21:52 - d_loss: 2.0517 - g_loss: -1.0258\n",
      "\n",
      "\n",
      "d_loss= 2.021101\n",
      "\n",
      "g_loss= -1.2772828\n",
      "38/40 [===========================>..] - ETA: 14:35 - d_loss: 2.0508 - g_loss: -1.0324\n",
      "\n",
      "\n",
      "d_loss= 2.010447\n",
      "\n",
      "g_loss= -0.20700246\n",
      "39/40 [============================>.] - ETA: 7:18 - d_loss: 2.0498 - g_loss: -1.0112 \n",
      "\n",
      "\n",
      "d_loss= 2.0005124\n",
      "\n",
      "g_loss= -1.1074135\n",
      "40/40 [==============================] - 17524s 438s/step - d_loss: 2.0486 - g_loss: -1.0136\n"
     ]
    }
   ],
   "source": [
    "# Deshabilitar los mensajes de información de TensorFlow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Deshabilitar los mensajes de información de OpenAI Gym\n",
    "gym.logger.set_level(40)\n",
    "\n",
    "history=gan9.fit(X_train,\n",
    "    epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1110 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1083 - accuracy: 0.0000e+00\n",
      ">Loss real: \n",
      "0.1109808161854744\n",
      ">Loss fake: \n",
      "0.10825882852077484\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos el Discriminador de GAIL en el TEST\n",
    "gan9.evaluate_D(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  0 Total reward: 500.0\n",
      "Episode  1 Total reward: 500.0\n",
      "Episode  2 Total reward: 500.0\n",
      "Episode  3 Total reward: 500.0\n",
      "Episode  4 Total reward: 500.0\n",
      "Episode  5 Total reward: 500.0\n",
      "Episode  6 Total reward: 500.0\n",
      "Episode  7 Total reward: 500.0\n",
      "Episode  8 Total reward: 500.0\n",
      "Episode  9 Total reward: 500.0\n",
      "Episode  10 Total reward: 500.0\n",
      "Episode  11 Total reward: 500.0\n",
      "Episode  12 Total reward: 500.0\n",
      "Episode  13 Total reward: 500.0\n",
      "Episode  14 Total reward: 500.0\n",
      "Episode  15 Total reward: 500.0\n",
      "Episode  16 Total reward: 500.0\n",
      "Episode  17 Total reward: 500.0\n",
      "Episode  18 Total reward: 500.0\n",
      "Episode  19 Total reward: 500.0\n",
      "Episode  20 Total reward: 500.0\n",
      "Episode  21 Total reward: 500.0\n",
      "Episode  22 Total reward: 500.0\n",
      "Episode  23 Total reward: 500.0\n",
      "Episode  24 Total reward: 500.0\n",
      "Episode  25 Total reward: 500.0\n",
      "Episode  26 Total reward: 500.0\n",
      "Episode  27 Total reward: 500.0\n",
      "Episode  28 Total reward: 500.0\n",
      "Episode  29 Total reward: 500.0\n",
      "Episode  30 Total reward: 500.0\n",
      "Episode  31 Total reward: 500.0\n",
      "Episode  32 Total reward: 500.0\n",
      "Episode  33 Total reward: 500.0\n",
      "Episode  34 Total reward: 500.0\n",
      "Episode  35 Total reward: 500.0\n",
      "Episode  36 Total reward: 500.0\n",
      "Episode  37 Total reward: 500.0\n",
      "Episode  38 Total reward: 500.0\n",
      "Episode  39 Total reward: 500.0\n",
      "Episode  40 Total reward: 500.0\n",
      "Episode  41 Total reward: 500.0\n",
      "Episode  42 Total reward: 500.0\n",
      "Episode  43 Total reward: 500.0\n",
      "Episode  44 Total reward: 500.0\n",
      "Episode  45 Total reward: 500.0\n",
      "Episode  46 Total reward: 500.0\n",
      "Episode  47 Total reward: 500.0\n",
      "Episode  48 Total reward: 500.0\n",
      "Episode  49 Total reward: 500.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recompensa de Media: 500.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos al Generador \n",
    "rewardMean=gan9.evaluate_G()\n",
    "print('\\nRecompensa de Media:', rewardMean, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción de base de datos experta con 10 trayectoria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEstados reales: \n",
      " [[ 0.00572823 -0.03831238  0.03101629  0.00900886]\n",
      " [ 0.00496198  0.15635134  0.03119646 -0.27372897]\n",
      " [ 0.00808901 -0.03920152  0.02572188  0.02862788]\n",
      " ...\n",
      " [-0.03035956 -0.1520803   0.0103268   0.24866116]\n",
      " [-0.03340117  0.04289266  0.01530002 -0.04074667]\n",
      " [-0.03254332  0.23779191  0.01448509 -0.3285633 ]]\n",
      "\tAcciones reales: \n",
      " [1 0 1 ... 1 1 0]\n",
      "\n",
      "\t Estados siguientes: \n",
      " [[ 0.00572823 -0.03831238  0.03101629  0.00900886]\n",
      " [ 0.00496198  0.15635134  0.03119646 -0.27372897]\n",
      " [ 0.00808901 -0.03920152  0.02572188  0.02862788]\n",
      " ...\n",
      " [-0.03035956 -0.1520803   0.0103268   0.24866116]\n",
      " [-0.03340117  0.04289266  0.01530002 -0.04074667]\n",
      " [-0.03254332  0.23779191  0.01448509 -0.3285633 ]]\n",
      "\n",
      "\t Recompensas: [1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "expert_observations = np.genfromtxt(\"observations_CartPole_.csv\",delimiter=\"\\t\",dtype=str)\n",
    "expert_actions = np.genfromtxt('actions_CartPole_.csv', dtype=np.int32)\n",
    "expert_next_observations = np.genfromtxt('next_observations_CartPole_.csv',delimiter=\"\\t\",dtype=str)\n",
    "expert_rewards = np.genfromtxt('rewards_CartPole_.csv', dtype=np.int32)\n",
    "expert_num_tray=np.genfromtxt('n_trayectoria_CartPole_.csv', dtype=np.int32)\n",
    "\n",
    "# Reemplazar las comas\n",
    "expert_observations = np.core.defchararray.replace(expert_observations, ',', ' ')\n",
    "\n",
    "# Reemplazar las comas\n",
    "expert_next_observations = np.core.defchararray.replace(expert_next_observations, ',', ' ')\n",
    "\n",
    "# Crear un nuevo array para almacenar los datos convertidos\n",
    "converted_observations = np.genfromtxt(expert_observations, delimiter=' ', dtype=float)\n",
    "# Crear un nuevo array para almacenar los datos convertidos\n",
    "converted_next_observations = np.genfromtxt(expert_observations, delimiter=' ', dtype=float)\n",
    "\n",
    "\n",
    "rewards=np.array(expert_rewards).reshape(-1,1)\n",
    "\n",
    "\n",
    "print(\"\\n\\tEstados reales: \\n\", converted_observations)\n",
    "print(\"\\tAcciones reales: \\n\", expert_actions)\n",
    "print(\"\\n\\t Estados siguientes: \\n\", converted_next_observations)\n",
    "print(\"\\n\\t Recompensas:\" ,expert_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "longitud_trayectoria += np.count_nonzero(expert_num_tray == 9)\n",
    "print(longitud_trayectoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos quedamos solo con la primera trayectoria\n",
    "converted_observations=converted_observations[0:longitud_trayectoria]\n",
    "expert_actions=expert_actions[0:longitud_trayectoria]\n",
    "converted_next_observations=converted_next_observations[0:longitud_trayectoria]\n",
    "expert_rewards=expert_rewards[0:longitud_trayectoria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el dataset [s,a,s',r] reales y lo dividimos en training y test\n",
    "expert_a_one_hot=np.eye(env.action_space.n)[expert_actions]\n",
    "expert_rewards = expert_rewards.reshape(-1, 1)\n",
    "\n",
    "dataset1=np.concatenate([converted_observations,expert_a_one_hot],axis=1)\n",
    "dataset2=np.concatenate([dataset1,converted_next_observations],axis=1)\n",
    "dataset=np.concatenate([dataset2,expert_rewards],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento: 4000\n",
      "Nº de (ESTADOS,ACCIONES) en el conjunto de prueba: 1000\n"
     ]
    }
   ],
   "source": [
    "#############################################################################\n",
    "# DIVISIÓN TRAIN Y TEST\n",
    "##############################################################################\n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test = train_test_split(dataset, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "#Imprime el número de elementos en el conjuntos de entrenamiento y prueba\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de entrenamiento:', len(X_train))\n",
    "print('Nº de (ESTADOS,ACCIONES) en el conjunto de prueba:', len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "env= gym.make('CartPole-v1')\n",
    "obs,_= env.reset()\n",
    "\n",
    "# Generador\n",
    "generator=Policy_net( 'policy', env, obs)\n",
    "\n",
    "# Generamos [s,a, s', r] falsas y las políticas theta_i y theta_i+1\n",
    "observations, actions, next_observations, rewards, Old_Policy, Policy=generator.generate_fakes()\n",
    "\n",
    "# Discriminador\n",
    "discriminator=Discriminator(env, discriminator_net, converted_observations, expert_actions, converted_next_observations, expert_rewards, observations, actions, next_observations, rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan10=GAN(discriminator=discriminator,generator=generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "gan10.compile(\n",
    "    d_optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss_fn_D=loss_fn_D\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "d_loss= 1.9897084\n",
      "\n",
      "g_loss= -0.4210099\n",
      " 1/45 [..............................] - ETA: 5:41:15 - d_loss: 1.9897 - g_loss: -0.4210\n",
      "\n",
      "\n",
      "d_loss= 2.0296123\n",
      "\n",
      "g_loss= -1.571722\n",
      " 2/45 [>.............................] - ETA: 5:32:48 - d_loss: 2.0097 - g_loss: -0.9964\n",
      "\n",
      "\n",
      "d_loss= 1.9736164\n",
      "\n",
      "g_loss= -1.0454295\n",
      " 3/45 [=>............................] - ETA: 5:26:33 - d_loss: 1.9976 - g_loss: -1.0127\n",
      "\n",
      "\n",
      "d_loss= 2.0160303\n",
      "\n",
      "g_loss= -0.5066986\n",
      " 4/45 [=>............................] - ETA: 5:17:00 - d_loss: 2.0022 - g_loss: -0.8862\n",
      "\n",
      "\n",
      "d_loss= 1.936535\n",
      "\n",
      "g_loss= -0.6647836\n",
      " 5/45 [==>...........................] - ETA: 5:08:06 - d_loss: 1.9891 - g_loss: -0.8419\n",
      "\n",
      "\n",
      "d_loss= 2.011438\n",
      "\n",
      "g_loss= -1.5812024\n",
      " 6/45 [===>..........................] - ETA: 5:00:16 - d_loss: 1.9928 - g_loss: -0.9651\n",
      "\n",
      "\n",
      "d_loss= 2.010145\n",
      "\n",
      "g_loss= -0.56545055\n",
      " 7/45 [===>..........................] - ETA: 4:51:48 - d_loss: 1.9953 - g_loss: -0.9080\n",
      "\n",
      "\n",
      "d_loss= 2.0258663\n",
      "\n",
      "g_loss= -1.6217943\n",
      " 8/45 [====>.........................] - ETA: 4:43:52 - d_loss: 1.9991 - g_loss: -0.9973\n",
      "\n",
      "\n",
      "d_loss= 1.9931337\n",
      "\n",
      "g_loss= -1.5384058\n",
      " 9/45 [=====>........................] - ETA: 4:35:58 - d_loss: 1.9985 - g_loss: -1.0574\n",
      "\n",
      "\n",
      "d_loss= 1.9925576\n",
      "\n",
      "g_loss= -1.5815396\n",
      "10/45 [=====>........................] - ETA: 4:27:25 - d_loss: 1.9979 - g_loss: -1.1098\n",
      "\n",
      "\n",
      "d_loss= 1.9890542\n",
      "\n",
      "g_loss= -0.5517307\n",
      "11/45 [======>.......................] - ETA: 4:18:56 - d_loss: 1.9971 - g_loss: -1.0591\n",
      "\n",
      "\n",
      "d_loss= 2.0202115\n",
      "\n",
      "g_loss= -0.4014394\n",
      "12/45 [=======>......................] - ETA: 4:10:38 - d_loss: 1.9990 - g_loss: -1.0043\n",
      "\n",
      "\n",
      "d_loss= 1.9935913\n",
      "\n",
      "g_loss= -0.6085942\n",
      "13/45 [=======>......................] - ETA: 4:02:35 - d_loss: 1.9986 - g_loss: -0.9738\n",
      "\n",
      "\n",
      "d_loss= 1.9630189\n",
      "\n",
      "g_loss= -0.8269462\n",
      "14/45 [========>.....................] - ETA: 3:55:09 - d_loss: 1.9960 - g_loss: -0.9633\n",
      "\n",
      "\n",
      "d_loss= 2.0156875\n",
      "\n",
      "g_loss= -0.57150334\n",
      "15/45 [=========>....................] - ETA: 3:47:18 - d_loss: 1.9973 - g_loss: -0.9372\n",
      "\n",
      "\n",
      "d_loss= 1.9764539\n",
      "\n",
      "g_loss= -0.51747805\n",
      "16/45 [=========>....................] - ETA: 3:39:27 - d_loss: 1.9960 - g_loss: -0.9110\n",
      "\n",
      "\n",
      "d_loss= 1.9987234\n",
      "\n",
      "g_loss= -0.9481991\n",
      "17/45 [==========>...................] - ETA: 3:31:52 - d_loss: 1.9962 - g_loss: -0.9132\n",
      "\n",
      "\n",
      "d_loss= 1.9783156\n",
      "\n",
      "g_loss= -1.6231\n",
      "18/45 [===========>..................] - ETA: 3:24:03 - d_loss: 1.9952 - g_loss: -0.9526\n",
      "\n",
      "\n",
      "d_loss= 1.9864368\n",
      "\n",
      "g_loss= -1.6118987\n",
      "19/45 [===========>..................] - ETA: 3:16:13 - d_loss: 1.9947 - g_loss: -0.9873\n",
      "\n",
      "\n",
      "d_loss= 2.008276\n",
      "\n",
      "g_loss= -0.7609999\n",
      "20/45 [============>.................] - ETA: 3:08:36 - d_loss: 1.9954 - g_loss: -0.9760\n",
      "\n",
      "\n",
      "d_loss= 1.9839641\n",
      "\n",
      "g_loss= -1.6125492\n",
      "21/45 [=============>................] - ETA: 3:01:06 - d_loss: 1.9949 - g_loss: -1.0063\n",
      "\n",
      "\n",
      "d_loss= 1.9832006\n",
      "\n",
      "g_loss= -0.5236198\n",
      "22/45 [=============>................] - ETA: 2:53:25 - d_loss: 1.9943 - g_loss: -0.9844\n",
      "\n",
      "\n",
      "d_loss= 1.976782\n",
      "\n",
      "g_loss= -0.42600703\n",
      "23/45 [==============>...............] - ETA: 2:45:44 - d_loss: 1.9936 - g_loss: -0.9601\n",
      "\n",
      "\n",
      "d_loss= 2.033043\n",
      "\n",
      "g_loss= -0.8594491\n",
      "24/45 [===============>..............] - ETA: 2:37:57 - d_loss: 1.9952 - g_loss: -0.9559\n",
      "\n",
      "\n",
      "d_loss= 2.007878\n",
      "\n",
      "g_loss= -1.2362604\n",
      "25/45 [===============>..............] - ETA: 2:30:23 - d_loss: 1.9957 - g_loss: -0.9671\n",
      "\n",
      "\n",
      "d_loss= 1.9637096\n",
      "\n",
      "g_loss= -0.40387046\n",
      "26/45 [================>.............] - ETA: 2:22:45 - d_loss: 1.9945 - g_loss: -0.9454\n",
      "\n",
      "\n",
      "d_loss= 1.9553263\n",
      "\n",
      "g_loss= -1.3714465\n",
      "27/45 [=================>............] - ETA: 2:15:09 - d_loss: 1.9930 - g_loss: -0.9612\n",
      "\n",
      "\n",
      "d_loss= 1.9424424\n",
      "\n",
      "g_loss= -1.3676155\n",
      "28/45 [=================>............] - ETA: 2:07:34 - d_loss: 1.9912 - g_loss: -0.9757\n",
      "\n",
      "\n",
      "d_loss= 2.00384\n",
      "\n",
      "g_loss= -1.5849541\n",
      "29/45 [==================>...........] - ETA: 2:00:03 - d_loss: 1.9917 - g_loss: -0.9967\n",
      "\n",
      "\n",
      "d_loss= 1.9843346\n",
      "\n",
      "g_loss= -0.956064\n",
      "30/45 [===================>..........] - ETA: 1:52:29 - d_loss: 1.9914 - g_loss: -0.9954\n",
      "\n",
      "\n",
      "d_loss= 1.9429015\n",
      "\n",
      "g_loss= -0.3885385\n",
      "31/45 [===================>..........] - ETA: 1:44:59 - d_loss: 1.9899 - g_loss: -0.9758\n",
      "\n",
      "\n",
      "d_loss= 1.9248365\n",
      "\n",
      "g_loss= -1.0325769\n",
      "32/45 [====================>.........] - ETA: 1:37:28 - d_loss: 1.9878 - g_loss: -0.9776\n",
      "\n",
      "\n",
      "d_loss= 1.987159\n",
      "\n",
      "g_loss= -1.5856911\n",
      "33/45 [=====================>........] - ETA: 1:29:56 - d_loss: 1.9878 - g_loss: -0.9960\n",
      "\n",
      "\n",
      "d_loss= 1.980796\n",
      "\n",
      "g_loss= -0.32411104\n",
      "34/45 [=====================>........] - ETA: 1:22:24 - d_loss: 1.9876 - g_loss: -0.9763\n",
      "\n",
      "\n",
      "d_loss= 1.9713349\n",
      "\n",
      "g_loss= -1.5342453\n",
      "35/45 [======================>.......] - ETA: 1:14:54 - d_loss: 1.9871 - g_loss: -0.9922\n",
      "\n",
      "\n",
      "d_loss= 1.9613962\n",
      "\n",
      "g_loss= -1.1079412\n",
      "36/45 [=======================>......] - ETA: 1:07:24 - d_loss: 1.9864 - g_loss: -0.9954\n",
      "\n",
      "\n",
      "d_loss= 1.9994235\n",
      "\n",
      "g_loss= -1.3475902\n",
      "37/45 [=======================>......] - ETA: 59:54 - d_loss: 1.9868 - g_loss: -1.0049  \n",
      "\n",
      "\n",
      "d_loss= 1.966439\n",
      "\n",
      "g_loss= -1.3855102\n",
      "38/45 [========================>.....] - ETA: 52:23 - d_loss: 1.9862 - g_loss: -1.0149\n",
      "\n",
      "\n",
      "d_loss= 1.9560773\n",
      "\n",
      "g_loss= -1.518347\n",
      "39/45 [=========================>....] - ETA: 44:52 - d_loss: 1.9855 - g_loss: -1.0279\n",
      "\n",
      "\n",
      "d_loss= 1.9116726\n",
      "\n",
      "g_loss= -0.36310533\n",
      "40/45 [=========================>....] - ETA: 37:23 - d_loss: 1.9836 - g_loss: -1.0112\n",
      "\n",
      "\n",
      "d_loss= 1.9717784\n",
      "\n",
      "g_loss= -1.0622164\n",
      "41/45 [==========================>...] - ETA: 29:54 - d_loss: 1.9833 - g_loss: -1.0125\n",
      "\n",
      "\n",
      "d_loss= 1.9564345\n",
      "\n",
      "g_loss= -1.5672464\n",
      "42/45 [===========================>..] - ETA: 22:25 - d_loss: 1.9827 - g_loss: -1.0257\n",
      "\n",
      "\n",
      "d_loss= 1.9558032\n",
      "\n",
      "g_loss= -0.7436793\n",
      "43/45 [===========================>..] - ETA: 14:56 - d_loss: 1.9821 - g_loss: -1.0191\n",
      "\n",
      "\n",
      "d_loss= 1.9586734\n",
      "\n",
      "g_loss= -0.5728746\n",
      "44/45 [============================>.] - ETA: 7:28 - d_loss: 1.9815 - g_loss: -1.0090 \n",
      "\n",
      "\n",
      "d_loss= 1.940346\n",
      "\n",
      "g_loss= -1.2420486\n",
      "45/45 [==============================] - 20195s 448s/step - d_loss: 1.9806 - g_loss: -1.0142\n"
     ]
    }
   ],
   "source": [
    "# Deshabilitar los mensajes de información de TensorFlow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Deshabilitar los mensajes de información de OpenAI Gym\n",
    "gym.logger.set_level(40)\n",
    "\n",
    "history=gan10.fit(X_train,\n",
    "    epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de GAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0510 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0541 - accuracy: 0.0000e+00\n",
      ">Loss real: \n",
      "0.051025740802288055\n",
      ">Loss fake: \n",
      "0.05410065874457359\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos el Discriminador de GAIL en el TEST\n",
    "gan10.evaluate_D(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  0 Total reward: 500.0\n",
      "Episode  1 Total reward: 500.0\n",
      "Episode  2 Total reward: 500.0\n",
      "Episode  3 Total reward: 500.0\n",
      "Episode  4 Total reward: 500.0\n",
      "Episode  5 Total reward: 500.0\n",
      "Episode  6 Total reward: 500.0\n",
      "Episode  7 Total reward: 500.0\n",
      "Episode  8 Total reward: 500.0\n",
      "Episode  9 Total reward: 500.0\n",
      "Episode  10 Total reward: 500.0\n",
      "Episode  11 Total reward: 500.0\n",
      "Episode  12 Total reward: 500.0\n",
      "Episode  13 Total reward: 500.0\n",
      "Episode  14 Total reward: 500.0\n",
      "Episode  15 Total reward: 500.0\n",
      "Episode  16 Total reward: 500.0\n",
      "Episode  17 Total reward: 500.0\n",
      "Episode  18 Total reward: 500.0\n",
      "Episode  19 Total reward: 500.0\n",
      "Episode  20 Total reward: 500.0\n",
      "Episode  21 Total reward: 500.0\n",
      "Episode  22 Total reward: 500.0\n",
      "Episode  23 Total reward: 500.0\n",
      "Episode  24 Total reward: 500.0\n",
      "Episode  25 Total reward: 500.0\n",
      "Episode  26 Total reward: 500.0\n",
      "Episode  27 Total reward: 500.0\n",
      "Episode  28 Total reward: 500.0\n",
      "Episode  29 Total reward: 500.0\n",
      "Episode  30 Total reward: 500.0\n",
      "Episode  31 Total reward: 500.0\n",
      "Episode  32 Total reward: 500.0\n",
      "Episode  33 Total reward: 500.0\n",
      "Episode  34 Total reward: 500.0\n",
      "Episode  35 Total reward: 500.0\n",
      "Episode  36 Total reward: 500.0\n",
      "Episode  37 Total reward: 500.0\n",
      "Episode  38 Total reward: 500.0\n",
      "Episode  39 Total reward: 500.0\n",
      "Episode  40 Total reward: 500.0\n",
      "Episode  41 Total reward: 500.0\n",
      "Episode  42 Total reward: 500.0\n",
      "Episode  43 Total reward: 500.0\n",
      "Episode  44 Total reward: 500.0\n",
      "Episode  45 Total reward: 500.0\n",
      "Episode  46 Total reward: 500.0\n",
      "Episode  47 Total reward: 500.0\n",
      "Episode  48 Total reward: 500.0\n",
      "Episode  49 Total reward: 500.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recompensa de Media: 500.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos al Generador \n",
    "rewardMean=gan10.evaluate_G()\n",
    "print('\\nRecompensa de Media:', rewardMean, '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
